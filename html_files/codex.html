<!DOCTYPE html>
<!-- saved from url=(0031)https://www.lesswrong.com/codex -->
<html lang="en" class=" oqfngf idc0_345"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="preload" as="style" href="./codex_files/allStyles"><link rel="stylesheet" type="text/css" href="./codex_files/icon"><link rel="stylesheet" type="text/css" href="./codex_files/reset-min.css"><link rel="stylesheet" type="text/css" href="./codex_files/css"><link rel="stylesheet" type="text/css" href="./codex_files/jvr1gjm.css"><script type="text/javascript" async="" src="./codex_files/linkid.js"></script><script type="text/javascript" async="" src="./codex_files/js"></script><script type="text/javascript" async="" src="./codex_files/analytics.js"></script><script type="text/javascript" async="" src="./codex_files/recaptcha__en.js" crossorigin="anonymous" integrity="sha384-VQkqyzWECBbjdnrmLsMeQdf0TTXr6rfxgJXnIIszVBecGcFa03Tl4VBO4n2inOOm"></script><script async="" src="./codex_files/gtm.js"></script><script>window.publicInstanceSettings = {"forumType":"LessWrong","title":"LessWrong","siteNameWithArticle":"LessWrong","sentry":{"url":"https://1ab1949fc8d04608b43132f37bb2a1b0@sentry.io/1301611","environment":"production","release":"69f0f3c5d57b596e8249571383f8a280eff9bb23"},"debug":false,"aboutPostId":"bJ2haLkcGeLtTWaD5","faqPostId":"2rWKkWuPrgTMpLRbp","expectedDatabaseId":"production","tagline":"A community blog devoted to refining the art of rationality","faviconUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico","forumSettings":{"headerTitle":"LESSWRONG","shortForumTitle":"LW","tabTitle":"LessWrong"},"analytics":{"environment":"lesswrong.com"},"testServer":false,"fmCrosspost":{"siteName":"the EA Forum","baseUrl":"https://forum.effectivealtruism.org/"}}</script><script defer="" src="./codex_files/bundle.js"></script><title>The Codex - LessWrong</title><meta data-react-helmet="true" name="viewport" content="width=device-width, initial-scale=1"><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" name="twitter:image:src" content="https://res.cloudinary.com/lesswrong-2-0/image/upload/v1654295382/new_mississippi_river_fjdmww.jpg"><meta data-react-helmet="true" property="og:type" content="article"><meta data-react-helmet="true" property="og:image" content="https://res.cloudinary.com/lesswrong-2-0/image/upload/v1654295382/new_mississippi_river_fjdmww.jpg"><meta data-react-helmet="true" http-equiv="Accept-CH" content="DPR, Viewport-Width, Width"><link data-react-helmet="true" rel="shortcut icon" href="https://res.cloudinary.com/lesswrong-2-0/image/upload/v1497915096/favicon_lncumn.ico"><link data-react-helmet="true" rel="alternate" type="application/rss+xml" href="https://www.lesswrong.com/feed.xml">
<script>var tabId = "qHyimZdt3B2RFNRQ7"</script>
<script> var publicSettings = {"siteImage":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1654295382/new_mississippi_river_fjdmww.jpg","intercomAppId":"wtb8z7sj","googleTagManager":{"apiKey":"GTM-TRC765W"},"reCaptcha":{"apiKey":"6LfFgqEUAAAAAHKdMgzGO-1BRBhHw1x6_8Ly1cXc"},"googleMaps":{"apiKey":"AIzaSyA3C48rl26gynG3qIuNuS-3Bh_Zz9jFXkY"},"algolia":{"appId":"Z0GR6EXQHD","searchKey":"0b1d20b957917dbb5e1c2f3ad1d04ee2","autoSyncIndexes":false,"indexPrefix":"test_"},"ckEditor":{"uploadUrl":"https://39669.cke-cs.com/easyimage/upload/","webSocketUrl":"39669.cke-cs.com/ws"},"logRocket":{"apiKey":"mtnxzn/lesswrong","sampleDensity":5},"hasEvents":true,"hideUnreviewedAuthorComments":false,"cloudinary":{"cloudName":"lesswrong-2-0","uploadPresetGridImage":"tz0mgw2s","uploadPresetBanner":"navcjwf7"},"forum":{"numberOfDays":10,"numberOfWeeks":4,"numberOfMonths":4,"numberOfYears":4,"postInterval":30,"maxPostsPerDay":5},"locale":"en-US","legacyRouteAcronym":"lw","logoUrl":"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1498011194/LessWrong_Logo_skglnw.svg","maxDocumentsPerRequest":5000,"commentInterval":15,"timeDecayFactor":1.15,"mapbox":{"apiKey":"pk.eyJ1IjoiaGFicnlrYSIsImEiOiJjaWxvcnhidzgwOGlodHJrbmJ2bmVmdjRtIn0.inr-_5rWOOslGQxY8iDFOA"},"petrov":{"afterTime":1664247600000,"beforeTime":1664161200000,"petrovServerUrl":"https://forum.effectivealtruism.org/graphql","petrovPostId":"KTEciTeFwL2tTujZk","petrovGamePostId":"KTEciTeFwL2tTujZk"},"gatherTownMessage":"Schelling social hours on Tues 1pm and Thurs 6pm PT","gardenOpenToPublic":false,"frontpageScoreBonus":0,"stripe":{"publicKey":"pk_live_51HtKAwA2QvoATZCZiy9f2nc6hA52YS1BE81cFu9FEV1IKar0Bwx6hIpxxxYHnhaxO9KM7kRYofZId3sUUI7Q0NeO00tGni3Wza"},"defaultModeratorComments":[{"label":"Option A","id":"FfMok764BCY6ScqWm"},{"label":"Option B","id":"yMHoNoYZdk5cKa3wQ"}],"gatherTownUserTrackingIsBroken":true,"annualReview":{"announcementPostPath":"/posts/qCc7tm29Guhz6mtf7/the-lesswrong-2021-review-intellectual-circle-expansion","votingResultsPostId":"TSaJ9Zcvc3KWh3bjX","start":"2022-12-01T18:00:00Z","nominationPhaseEnd":"2022-12-15T08:00:00Z","reviewPhaseEnd":"2023-01-16T08:00:00Z","votingPhaseEnd":"2022-02-01T08:00:00Z","end":"2023-02-07T12:00:00Z"},"enableGoodHeartProject":false,"moderationEmail":"team@lesswrong.com","defaultVisibilityTags":[{"tagId":"Ng8Gice9KNkncxqcj","tagName":"Rationality","filterMode":10},{"tagId":"3uE2pXvbcnS9nnZRE","tagName":"World Modeling","filterMode":10}]}</script><script>window.themeOptions = {"name":"dark"}</script><style id="jss-insertion-point"></style><style data-jss="" data-meta="MuiSvgIcon">
.MuiSvgIcon-root {
  fill: currentColor;
  width: 1em;
  height: 1em;
  display: inline-block;
  font-size: 24px;
  transition: fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;
  user-select: none;
  flex-shrink: 0;
}
.MuiSvgIcon-colorPrimary {
  color: #5f9b65;
}
.MuiSvgIcon-colorSecondary {
  color: #5f9b65;
}
.MuiSvgIcon-colorAction {
  color: #fff;
}
.MuiSvgIcon-colorError {
  color: #bf360c;
}
.MuiSvgIcon-colorDisabled {
  color: rgba(255, 255, 255, 0.3);
}
.MuiSvgIcon-fontSizeInherit {
  font-size: inherit;
}
.MuiSvgIcon-fontSizeSmall {
  font-size: 20px;
}
.MuiSvgIcon-fontSizeLarge {
  font-size: 36px;
}
</style><style data-jss="" data-meta="MuiTouchRipple">
.MuiTouchRipple-root {
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  display: block;
  z-index: 0;
  position: absolute;
  overflow: hidden;
  border-radius: inherit;
  pointer-events: none;
}
.MuiTouchRipple-ripple {
  top: 0;
  left: 0;
  width: 50px;
  height: 50px;
  opacity: 0;
  position: absolute;
}
.MuiTouchRipple-rippleVisible {
  opacity: 0.3;
  transform: scale(1);
  animation: mui-ripple-enter 550ms cubic-bezier(0.4, 0, 0.2, 1);
}
.MuiTouchRipple-ripplePulsate {
  animation-duration: 200ms;
}
.MuiTouchRipple-child {
  width: 100%;
  height: 100%;
  opacity: 1;
  display: block;
  border-radius: 50%;
  background-color: currentColor;
}
.MuiTouchRipple-childLeaving {
  opacity: 0;
  animation: mui-ripple-exit 550ms cubic-bezier(0.4, 0, 0.2, 1);
}
.MuiTouchRipple-childPulsate {
  top: 0;
  left: 0;
  position: absolute;
  animation: mui-ripple-pulsate 2500ms cubic-bezier(0.4, 0, 0.2, 1) 200ms infinite;
}
@-webkit-keyframes mui-ripple-enter {
  0% {
    opacity: 0.1;
    transform: scale(0);
  }
  100% {
    opacity: 0.3;
    transform: scale(1);
  }
}
@-webkit-keyframes mui-ripple-exit {
  0% {
    opacity: 1;
  }
  100% {
    opacity: 0;
  }
}
@-webkit-keyframes mui-ripple-pulsate {
  0% {
    transform: scale(1);
  }
  50% {
    transform: scale(0.92);
  }
  100% {
    transform: scale(1);
  }
}
</style><style data-jss="" data-meta="MuiButtonBase">
.MuiButtonBase-root {
  color: inherit;
  border: 0;
  margin: 0;
  cursor: pointer;
  display: inline-flex;
  outline: none;
  padding: 0;
  position: relative;
  align-items: center;
  user-select: none;
  border-radius: 0;
  vertical-align: middle;
  justify-content: center;
  -moz-appearance: none;
  text-decoration: none;
  background-color: transparent;
  -webkit-appearance: none;
  -webkit-tap-highlight-color: transparent;
}
.MuiButtonBase-root::-moz-focus-inner {
  border-style: none;
}
.MuiButtonBase-root.MuiButtonBase-disabled {
  cursor: default;
  pointer-events: none;
}
</style><style data-jss="" data-meta="MuiToolbar">
.MuiToolbar-root {
  display: flex;
  position: relative;
  align-items: center;
}
.MuiToolbar-gutters {
  padding-left: 16px;
  padding-right: 16px;
}
@media (min-width:600px) {
  .MuiToolbar-gutters {
    padding-left: 24px;
    padding-right: 24px;
  }
}
.MuiToolbar-regular {
  min-height: 56px;
}
@media (min-width:0px) and (orientation: landscape) {
  .MuiToolbar-regular {
    min-height: 48px;
  }
}
@media (min-width:600px) {
  .MuiToolbar-regular {
    min-height: 64px;
  }
}
.MuiToolbar-dense {
  min-height: 48px;
}
</style><style data-jss="" data-meta="MuiIconButton">
.MuiIconButton-root {
  flex: 0 0 auto;
  color: #fff;
  padding: 12px;
  overflow: visible;
  font-size: 1.5rem;
  text-align: center;
  transition: background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;
  border-radius: 50%;
}
.MuiIconButton-root:hover {
  background-color: rgba(255, 255, 255, 0.1);
}
.MuiIconButton-root.MuiIconButton-disabled {
  color: rgba(255, 255, 255, 0.3);
}
@media (hover: none) {
  .MuiIconButton-root:hover {
    background-color: transparent;
  }
}
.MuiIconButton-root:hover.MuiIconButton-disabled {
  background-color: transparent;
}
.MuiIconButton-colorInherit {
  color: inherit;
}
.MuiIconButton-colorPrimary {
  color: #5f9b65;
}
.MuiIconButton-colorPrimary:hover {
  background-color: rgba(95, 155, 101, 0.1);
}
@media (hover: none) {
  .MuiIconButton-colorPrimary:hover {
    background-color: transparent;
  }
}
.MuiIconButton-colorSecondary {
  color: #5f9b65;
}
.MuiIconButton-colorSecondary:hover {
  background-color: rgba(95, 155, 101, 0.1);
}
@media (hover: none) {
  .MuiIconButton-colorSecondary:hover {
    background-color: transparent;
  }
}
.MuiIconButton-label {
  width: 100%;
  display: flex;
  align-items: inherit;
  justify-content: inherit;
}
</style><style data-jss="" data-meta="MuiSnackbar">
.MuiSnackbar-root {
  left: 0;
  right: 0;
  z-index: 1400;
  display: flex;
  position: fixed;
  align-items: center;
  justify-content: center;
}
.MuiSnackbar-anchorOriginTopCenter {
  top: 0;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginTopCenter {
    left: 50%;
    right: auto;
    transform: translateX(-50%);
  }
}
.MuiSnackbar-anchorOriginBottomCenter {
  bottom: 0;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginBottomCenter {
    left: 50%;
    right: auto;
    transform: translateX(-50%);
  }
}
.MuiSnackbar-anchorOriginTopRight {
  top: 0;
  justify-content: flex-end;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginTopRight {
    top: 24px;
    left: auto;
    right: 24px;
  }
}
.MuiSnackbar-anchorOriginBottomRight {
  bottom: 0;
  justify-content: flex-end;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginBottomRight {
    left: auto;
    right: 24px;
    bottom: 24px;
  }
}
.MuiSnackbar-anchorOriginTopLeft {
  top: 0;
  justify-content: flex-start;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginTopLeft {
    top: 24px;
    left: 24px;
    right: auto;
  }
}
.MuiSnackbar-anchorOriginBottomLeft {
  bottom: 0;
  justify-content: flex-start;
}
@media (min-width:960px) {
  .MuiSnackbar-anchorOriginBottomLeft {
    left: 24px;
    right: auto;
    bottom: 24px;
  }
}
</style><style data-jss="" data-meta="MuiButton">
.MuiButton-root {
  color: rgba(255,255,255,0.87);
  padding: 8px 16px;
  font-size: 0.875rem;
  min-width: 64px;
  box-sizing: border-box;
  min-height: 36px;
  transition: background-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,box-shadow 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,border 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;
  font-weight: 500;
  font-family: GreekFallback,Calibri,"Gill Sans","Gill Sans MT",Myriad Pro,Myriad,"Liberation Sans","Nimbus Sans L",Tahoma,Geneva,"Helvetica Neue",Helvetica,Arial,sans-serif;
  line-height: 1.4em;
  border-radius: 4px;
  text-transform: uppercase;
}
.MuiButton-root:hover {
  text-decoration: none;
  background-color: rgba(255, 255, 255, 0.1);
}
.MuiButton-root.MuiButton-disabled {
  color: rgba(255, 255, 255, 0.3);
}
@media (hover: none) {
  .MuiButton-root:hover {
    background-color: transparent;
  }
}
.MuiButton-root:hover.MuiButton-disabled {
  background-color: transparent;
}
.MuiButton-label {
  width: 100%;
  display: inherit;
  align-items: inherit;
  justify-content: inherit;
}
.MuiButton-textPrimary {
  color: #5f9b65;
}
.MuiButton-textPrimary:hover {
  background-color: rgba(95, 155, 101, 0.1);
}
@media (hover: none) {
  .MuiButton-textPrimary:hover {
    background-color: transparent;
  }
}
.MuiButton-textSecondary {
  color: #5f9b65;
}
.MuiButton-textSecondary:hover {
  background-color: rgba(95, 155, 101, 0.1);
}
@media (hover: none) {
  .MuiButton-textSecondary:hover {
    background-color: transparent;
  }
}
.MuiButton-outlined {
  border: 1px solid rgba(255, 255, 255, 0.23);
}
.MuiButton-outlinedPrimary {
  border: 1px solid rgba(95, 155, 101, 0.5);
}
.MuiButton-outlinedPrimary:hover {
  border: 1px solid #5f9b65;
}
.MuiButton-outlinedPrimary.MuiButton-disabled {
  border: 1px solid rgba(255, 255, 255, 0.3);
}
.MuiButton-outlinedSecondary {
  border: 1px solid rgba(95, 155, 101, 0.5);
}
.MuiButton-outlinedSecondary:hover {
  border: 1px solid #5f9b65;
}
.MuiButton-outlinedSecondary.MuiButton-disabled {
  border: 1px solid rgba(255, 255, 255, 0.3);
}
.MuiButton-contained {
  color: #fff;
  box-shadow: 0px 1px 5px 0px rgba(255,255,255,0.2),0px 2px 2px 0px rgba(255,255,255,0.14),0px 3px 1px -2px rgba(255,255,255,0.12);
  background-color: #505050;
}
.MuiButton-contained.MuiButton-focusVisible {
  box-shadow: 0px 3px 5px -1px rgba(255,255,255,0.2),0px 6px 10px 0px rgba(255,255,255,0.14),0px 1px 18px 0px rgba(255,255,255,0.12);
}
.MuiButton-contained:active {
  box-shadow: 0px 5px 5px -3px rgba(255,255,255,0.2),0px 8px 10px 1px rgba(255,255,255,0.14),0px 3px 14px 2px rgba(255,255,255,0.12);
}
.MuiButton-contained.MuiButton-disabled {
  color: rgba(255, 255, 255, 0.3);
  box-shadow: none;
  background-color: rgba(255, 255, 255, 0.12);
}
.MuiButton-contained:hover {
  background-color: #616161;
}
@media (hover: none) {
  .MuiButton-contained:hover {
    background-color: #505050;
  }
}
.MuiButton-contained:hover.MuiButton-disabled {
  background-color: rgba(255, 255, 255, 0.12);
}
.MuiButton-containedPrimary {
  color: #000000;
  background-color: #5f9b65;
}
.MuiButton-containedPrimary:hover {
  background-color: #426c46;
}
@media (hover: none) {
  .MuiButton-containedPrimary:hover {
    background-color: #5f9b65;
  }
}
.MuiButton-containedSecondary {
  color: #000000;
  background-color: #5f9b65;
}
.MuiButton-containedSecondary:hover {
  background-color: #426c46;
}
@media (hover: none) {
  .MuiButton-containedSecondary:hover {
    background-color: #5f9b65;
  }
}
.MuiButton-fab {
  width: 56px;
  height: 56px;
  padding: 0;
  min-width: 0;
  box-shadow: 0px 3px 5px -1px rgba(255,255,255,0.2),0px 6px 10px 0px rgba(255,255,255,0.14),0px 1px 18px 0px rgba(255,255,255,0.12);
  border-radius: 50%;
}
.MuiButton-fab:active {
  box-shadow: 0px 7px 8px -4px rgba(255,255,255,0.2),0px 12px 17px 2px rgba(255,255,255,0.14),0px 5px 22px 4px rgba(255,255,255,0.12);
}
.MuiButton-extendedFab {
  width: auto;
  height: 48px;
  padding: 0 16px;
  min-width: 48px;
  border-radius: 24px;
}
.MuiButton-colorInherit {
  color: inherit;
}
.MuiButton-mini {
  width: 40px;
  height: 40px;
}
.MuiButton-sizeSmall {
  padding: 7px 8px;
  min-width: 64px;
  font-size: 0.8125rem;
  min-height: 32px;
}
.MuiButton-sizeLarge {
  padding: 8px 24px;
  min-width: 112px;
  font-size: 0.9375rem;
  min-height: 40px;
}
.MuiButton-fullWidth {
  width: 100%;
}
</style><style data-jss="" data-meta="MuiModal">
.MuiModal-root {
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  z-index: 1300;
  position: fixed;
}
.MuiModal-hidden {
  visibility: hidden;
}
</style><style data-jss="" data-meta="MuiBadge">
.MuiBadge-root {
  display: inline-flex;
  position: relative;
  vertical-align: middle;
}
.MuiBadge-badge {
  top: -11px;
  right: -11px;
  width: 22px;
  height: 22px;
  display: flex;
  z-index: 1;
  position: absolute;
  flex-wrap: wrap;
  font-size: 0.75rem;
  align-items: center;
  font-family: GreekFallback,Calibri,"Gill Sans","Gill Sans MT",Myriad Pro,Myriad,"Liberation Sans","Nimbus Sans L",Tahoma,Geneva,"Helvetica Neue",Helvetica,Arial,sans-serif;
  align-content: center;
  border-radius: 50%;
  flex-direction: row;
  justify-content: center;
}
.MuiBadge-colorPrimary {
  color: #000000;
  background-color: #5f9b65;
}
.MuiBadge-colorSecondary {
  color: #000000;
  background-color: #5f9b65;
}
.MuiBadge-colorError {
  color: #000000;
  background-color: #bf360c;
}
</style><style data-jss="" data-meta="MuiDrawer">
.MuiDrawer-docked {
  flex: 0 0 auto;
}
.MuiDrawer-paper {
  top: 0;
  flex: 1 0 auto;
  height: 100%;
  display: flex;
  z-index: 1200;
  outline: none;
  position: fixed;
  overflow-y: auto;
  flex-direction: column;
  -webkit-overflow-scrolling: touch;
}
.MuiDrawer-paperAnchorLeft {
  left: 0;
  right: auto;
}
.MuiDrawer-paperAnchorRight {
  left: auto;
  right: 0;
}
.MuiDrawer-paperAnchorTop {
  top: 0;
  left: 0;
  right: 0;
  bottom: auto;
  height: auto;
  max-height: 100%;
}
.MuiDrawer-paperAnchorBottom {
  top: auto;
  left: 0;
  right: 0;
  bottom: 0;
  height: auto;
  max-height: 100%;
}
.MuiDrawer-paperAnchorDockedLeft {
  border-right: 1px solid rgba(255, 255, 255, 0.12);
}
.MuiDrawer-paperAnchorDockedTop {
  border-bottom: 1px solid rgba(255, 255, 255, 0.12);
}
.MuiDrawer-paperAnchorDockedRight {
  border-left: 1px solid rgba(255, 255, 255, 0.12);
}
.MuiDrawer-paperAnchorDockedBottom {
  border-top: 1px solid rgba(255, 255, 255, 0.12);
}
</style><style data-jss="">
.jss103 {
  top: 0;
  left: 0;
  bottom: 0;
  z-index: 1199;
  position: fixed;
}
.jss104 {
  right: auto;
}
.jss105 {
  left: auto;
  right: 0;
}
.jss106 {
  right: 0;
  bottom: auto;
}
.jss107 {
  top: auto;
  right: 0;
  bottom: 0;
}
</style><link id="main-styles" rel="stylesheet" type="text/css" onerror="window.missingMainStylesheet=true" href="./codex_files/allStyles"><script async="" src="./codex_files/wtb8z7sj"></script><style>@font-face {
	font-family: "wticons";
	src: url("data:font/woff2;charset=utf-8;base64,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") format("woff2");
}

.wticons {
	line-height: 1;
}

.wticons:before {
	font-family: wticons !important;
	font-style: normal;
	font-weight: normal !important;
	vertical-align: top;
}

.wticon-account:before {
	content: "\f101";
}
.wticon-add:before {
	content: "\f102";
}
.wticon-cardResizeDrag:before {
	content: "\f103";
}
.wticon-casual:before {
	content: "\f104";
}
.wticon-check:before {
	content: "\f105";
}
.wticon-checkSmall:before {
	content: "\f106";
}
.wticon-chevron:before {
	content: "\f107";
}
.wticon-copy:before {
	content: "\f108";
}
.wticon-copySmall:before {
	content: "\f109";
}
.wticon-dismiss:before {
	content: "\f10a";
}
.wticon-downChevron:before {
	content: "\f10b";
}
.wticon-error:before {
	content: "\f10c";
}
.wticon-expand:before {
	content: "\f10d";
}
.wticon-feedback:before {
	content: "\f10e";
}
.wticon-filledDownArrow:before {
	content: "\f10f";
}
.wticon-find:before {
	content: "\f110";
}
.wticon-formal:before {
	content: "\f111";
}
.wticon-gift:before {
	content: "\f112";
}
.wticon-grayLogo:before {
	content: "\f113";
}
.wticon-ignore:before {
	content: "\f114";
}
.wticon-info:before {
	content: "\f115";
}
.wticon-leftChevron:before {
	content: "\f116";
}
.wticon-logo:before {
	content: "\f117";
}
.wticon-love:before {
	content: "\f118";
}
.wticon-noRecommendations:before {
	content: "\f119";
}
.wticon-paragraphRewrite:before {
	content: "\f11a";
}
.wticon-paste:before {
	content: "\f11b";
}
.wticon-pin:before {
	content: "\f11c";
}
.wticon-premium:before {
	content: "\f11d";
}
.wticon-premiumDetail:before {
	content: "\f11e";
}
.wticon-premiumFull:before {
	content: "\f11f";
}
.wticon-recommendationLight:before {
	content: "\f120";
}
.wticon-recommendationLightCard:before {
	content: "\f121";
}
.wticon-recommendationLightNoSuggestions:before {
	content: "\f122";
}
.wticon-refine:before {
	content: "\f123";
}
.wticon-rewrite:before {
	content: "\f124";
}
.wticon-rightChevron:before {
	content: "\f125";
}
.wticon-rocket:before {
	content: "\f126";
}
.wticon-sentenceExamples:before {
	content: "\f127";
}
.wticon-settings:before {
	content: "\f128";
}
.wticon-shorten:before {
	content: "\f129";
}
.wticon-tutorial:before {
	content: "\f12a";
}
.wticon-unlock:before {
	content: "\f12b";
}
.wticon-warn:before {
	content: "\f12c";
}
.wticon-WordtuneButton:before {
	content: "\f12d";
}
.wticon-x:before {
	content: "\f12e";
}

/*# sourceMappingURL=data:application/json;base64,{"version":3,"sources":["webpack://src/shared/Icons.font.js"],"names":[],"mappings":"AAAA;CACC,sBAAsB;CACtB,63SAA63S;AAC93S;;AAEA;CACC,cAAc;AACf;;AAEA;CACC,+BAA+B;CAC/B,kBAAkB;CAClB,8BAA8B;CAC9B,mBAAmB;AACpB;;AAEA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB;AACA;CACC,gBAAgB;AACjB","sourcesContent":["@font-face {\n\tfont-family: \"wticons\";\n\tsrc: url(\"data:font/woff2;charset=utf-8;base64,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\") format(\"woff2\");\n}\n\n.wticons {\n\tline-height: 1;\n}\n\n.wticons:before {\n\tfont-family: wticons !important;\n\tfont-style: normal;\n\tfont-weight: normal !important;\n\tvertical-align: top;\n}\n\n.wticon-account:before {\n\tcontent: \"\\f101\";\n}\n.wticon-add:before {\n\tcontent: \"\\f102\";\n}\n.wticon-cardResizeDrag:before {\n\tcontent: \"\\f103\";\n}\n.wticon-casual:before {\n\tcontent: \"\\f104\";\n}\n.wticon-check:before {\n\tcontent: \"\\f105\";\n}\n.wticon-checkSmall:before {\n\tcontent: \"\\f106\";\n}\n.wticon-chevron:before {\n\tcontent: \"\\f107\";\n}\n.wticon-copy:before {\n\tcontent: \"\\f108\";\n}\n.wticon-copySmall:before {\n\tcontent: \"\\f109\";\n}\n.wticon-dismiss:before {\n\tcontent: \"\\f10a\";\n}\n.wticon-downChevron:before {\n\tcontent: \"\\f10b\";\n}\n.wticon-error:before {\n\tcontent: \"\\f10c\";\n}\n.wticon-expand:before {\n\tcontent: \"\\f10d\";\n}\n.wticon-feedback:before {\n\tcontent: \"\\f10e\";\n}\n.wticon-filledDownArrow:before {\n\tcontent: \"\\f10f\";\n}\n.wticon-find:before {\n\tcontent: \"\\f110\";\n}\n.wticon-formal:before {\n\tcontent: \"\\f111\";\n}\n.wticon-gift:before {\n\tcontent: \"\\f112\";\n}\n.wticon-grayLogo:before {\n\tcontent: \"\\f113\";\n}\n.wticon-ignore:before {\n\tcontent: \"\\f114\";\n}\n.wticon-info:before {\n\tcontent: \"\\f115\";\n}\n.wticon-leftChevron:before {\n\tcontent: \"\\f116\";\n}\n.wticon-logo:before {\n\tcontent: \"\\f117\";\n}\n.wticon-love:before {\n\tcontent: \"\\f118\";\n}\n.wticon-noRecommendations:before {\n\tcontent: \"\\f119\";\n}\n.wticon-paragraphRewrite:before {\n\tcontent: \"\\f11a\";\n}\n.wticon-paste:before {\n\tcontent: \"\\f11b\";\n}\n.wticon-pin:before {\n\tcontent: \"\\f11c\";\n}\n.wticon-premium:before {\n\tcontent: \"\\f11d\";\n}\n.wticon-premiumDetail:before {\n\tcontent: \"\\f11e\";\n}\n.wticon-premiumFull:before {\n\tcontent: \"\\f11f\";\n}\n.wticon-recommendationLight:before {\n\tcontent: \"\\f120\";\n}\n.wticon-recommendationLightCard:before {\n\tcontent: \"\\f121\";\n}\n.wticon-recommendationLightNoSuggestions:before {\n\tcontent: \"\\f122\";\n}\n.wticon-refine:before {\n\tcontent: \"\\f123\";\n}\n.wticon-rewrite:before {\n\tcontent: \"\\f124\";\n}\n.wticon-rightChevron:before {\n\tcontent: \"\\f125\";\n}\n.wticon-rocket:before {\n\tcontent: \"\\f126\";\n}\n.wticon-sentenceExamples:before {\n\tcontent: \"\\f127\";\n}\n.wticon-settings:before {\n\tcontent: \"\\f128\";\n}\n.wticon-shorten:before {\n\tcontent: \"\\f129\";\n}\n.wticon-tutorial:before {\n\tcontent: \"\\f12a\";\n}\n.wticon-unlock:before {\n\tcontent: \"\\f12b\";\n}\n.wticon-warn:before {\n\tcontent: \"\\f12c\";\n}\n.wticon-WordtuneButton:before {\n\tcontent: \"\\f12d\";\n}\n.wticon-x:before {\n\tcontent: \"\\f12e\";\n}\n"],"sourceRoot":""} */</style><meta name="description" content="A community blog devoted to refining the art of rationality" data-react-helmet="true"><meta name="twitter:description" content="A community blog devoted to refining the art of rationality" data-react-helmet="true"><meta property="og:description" content="A community blog devoted to refining the art of rationality" data-react-helmet="true"><link rel="canonical" href="https://www.lesswrong.com/codex" data-react-helmet="true"><meta property="og:url" content="https://www.lesswrong.com/codex" data-react-helmet="true"></head>
<body class="abTestNoEffect_group1 collectionsPageABTest_originalLayoutGroup booksProgressBarABTest_control welcomeBoxABTest_welcomeBox twoLineEventsSidebar_expanded vsc-initialized" data-new-gr-c-s-check-loaded="14.1095.0" data-gr-ext-installed=""><div id="StayFocusd-infobar" style="display: none; top: 4080px;">
    <img src="chrome-extension://laankejkbhbdhmipfmgcngdelahlfoji/common/img/eye_19x19_red.png">
    <span id="StayFocusd-infobar-msg"></span>
    <span id="StayFocusd-infobar-links">
        <a id="StayFocusd-infobar-never-show">hide forever</a>&nbsp;&nbsp;|&nbsp;&nbsp;
        <a id="StayFocusd-infobar-hide">hide once</a>
    </span>
</div>
<div id="react-app"><div class="wrapper" id="wrapper"><div></div><span></span><div class="IntercomWrapper-intercomFrame" id="intercom-outer-frame"></div><noscript class="noscript-warning"> This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. </noscript><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TRC765W" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div class="Header-root"><div style="height:64px" class="Header-headroom headroom-wrapper"><div class="headroom headroom--unpinned headroom-disable-animation"><header class="Header-appBar"><div class="MuiToolbar-root MuiToolbar-regular MuiToolbar-gutters"><div class="Header-hideSmDown"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root MuiIconButton-colorInherit Header-menuButton" type="button" aria-label="Menu"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"></path></svg></span><span class="MuiTouchRipple-root"></span></button></div><div class="Header-hideMdUp"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root MuiIconButton-colorInherit Header-menuButton" type="button" aria-label="Menu"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M3 9h14V7H3v2zm0 4h14v-2H3v2zm0 4h14v-2H3v2zm16 0h2v-2h-2v2zm0-10v2h2V7h-2zm0 6h2v-2h-2v2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span><span class="MuiTouchRipple-root"></span></button></div><h2 class="Typography-root Typography-title Header-title"><div class="Header-hideSmDown"><div class="Header-titleSubtitleContainer"><a class="Header-titleLink" href="https://www.lesswrong.com/">LESSWRONG</a><span class="HeaderSubtitle-subtitle"><a href="https://www.lesswrong.com/codex">SlateStarCodex</a></span></div></div><div class="Header-hideMdUp"><a class="Header-titleLink" href="https://www.lesswrong.com/">LW</a></div></h2><div class="Header-rightHeaderItems"><div class="SearchBar-root"><div class="SearchBar-rootChild"><div class="SearchBar-searchInputArea"><div><svg class="MuiSvgIcon-root SearchBar-searchIcon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></div><div></div></div></div></div><div><div class="UsersMenu-root"><a href="https://www.lesswrong.com/users/stuckwork"><button tabindex="0" class="MuiButtonBase-root MuiButton-root UsersMenu-userButtonRoot MuiButton-text MuiButton-flat" type="button"><span class="MuiButton-label"><span class="UsersMenu-userButtonContents">Stuckwork</span></span><span class="MuiTouchRipple-root"></span></button></a></div></div><div class="KarmaChangeNotifier-root"><div><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root KarmaChangeNotifier-karmaNotifierButton" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root KarmaChangeNotifier-starIcon" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path d="M22 9.24l-7.19-.62L12 2 9.19 8.63 2 9.24l5.46 4.73L5.82 21 12 17.27 18.18 21l-1.63-7.03L22 9.24zM12 15.4l-3.76 2.27 1-4.28-3.32-2.88 4.38-.38L12 6.1l1.71 4.04 4.38.38-3.32 2.88 1 4.28L12 15.4z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span><span class="MuiTouchRipple-root"></span></button></div></div><span class="MuiBadge-root NotificationsMenuButton-badgeContainer"><button tabindex="0" class="MuiButtonBase-root MuiIconButton-root NotificationsMenuButton-buttonClosed" type="button"><span class="MuiIconButton-label"><svg class="MuiSvgIcon-root" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation"><path fill="none" d="M0 0h24v24H0z"></path><path d="M12 22c1.1 0 2-.9 2-2h-4c0 1.1.9 2 2 2zm6-6v-5c0-3.07-1.63-5.64-4.5-6.32V4c0-.83-.67-1.5-1.5-1.5s-1.5.67-1.5 1.5v.68C7.64 5.36 6 7.92 6 11v5l-2 2v1h16v-1l-2-2zm-2 1H8v-6c0-2.48 1.51-4.5 4-4.5s4 2.02 4 4.5v6z"></path></svg></span><span class="MuiTouchRipple-root"></span></button><span class="MuiBadge-badge NotificationsMenuButton-badge"></span></span></div></div></header><div class="jss103 jss104" style="width: 20px;"></div></div></div><div class="NotificationsMenu-root"></div></div><div class="Layout-standaloneNavFlex"><div class="Layout-searchResultsArea"></div><div class="Layout-main"><div class="flash-messages FlashMessages-root"></div><div class="CollectionsPage-root"><div class="ToCColumn-root ToCColumn-tocActivated"><div class="ToCColumn-header"></div><div class="ToCColumn-toc"><div class="ToCColumn-stickyBlockScroller"><div class="ToCColumn-stickyBlock"><div><div class="TableOfContentsRow-root TableOfContentsRow-level0"><a href="https://www.lesswrong.com/codex#" class="TableOfContentsRow-link TableOfContentsRow-title TableOfContentsRow-highlightDot">The Codex</a></div><div class="TableOfContentsRow-root TableOfContentsRow-level1"><a href="https://www.lesswrong.com/codex#jF58hKP9ZLzgy22Jr" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Good and Bad Reasoning</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level2"><a href="https://www.lesswrong.com/codex#XsMTxdQ6fprAQMoKi" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Argument and Analysis</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level2"><a href="https://www.lesswrong.com/codex#NHXY86jBahi968uW4" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Categorisation and Concepts</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level2"><a href="https://www.lesswrong.com/codex#TQW9brvXJ5Fajorr4" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Probability and Predictions</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level1"><a href="https://www.lesswrong.com/codex#YhQ39PPHNrRCgYXcs" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>The Institution of Science</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level2"><a href="https://www.lesswrong.com/codex#BQBqPowfxjvoee8jw" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Studies and Statistics</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level2"><a href="https://www.lesswrong.com/codex#B384FrQNrxSq4hZoS" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Research and Reviews</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level2"><a href="https://www.lesswrong.com/codex#k5MPpr72eiGknaS7F" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Hypotheses and Hunches</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level1"><a href="https://www.lesswrong.com/codex#kcCvSNNZd8pfQvf9E" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Designing the World</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level2 TableOfContentsRow-highlighted"><a href="https://www.lesswrong.com/codex#rNuPrZvabXe2MaZv8" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Politics and Pragmatics</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level2"><a href="https://www.lesswrong.com/codex#zfXAcwLnGocsCsriG" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Economics and Efficiency</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level2"><a href="https://www.lesswrong.com/codex#TKDT2Mt6dDMH8AsZW" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Futurism and Forecasting</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level2"><a href="https://www.lesswrong.com/codex#xmDeR64CivZiTAcLx" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Community and Cooperation</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level1"><a href="https://www.lesswrong.com/codex#2tPEd5Gdm3iewB53M" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Epilogue</span></a></div><div class="TableOfContentsRow-root TableOfContentsRow-level2"><a href="https://www.lesswrong.com/codex#WnTvZdXz2q9ySfr4o" class="TableOfContentsRow-link TableOfContentsRow-highlightDot"><span>Parables and Prayers</span></a></div></div></div></div></div><div class="ToCColumn-gap1"></div><div class="ToCColumn-content"><div class="CollectionsPage-section"><h1 class="Typography-root Typography-display3 CollectionsPage-title">The Codex</h1><div class="CollectionsPage-description ContentStyles-base content ContentStyles-postBody"><div><p>The Codex is a collection of essays written by Scott Alexander that discuss how good reasoning works, how to learn from the institution of science, and different ways society has been and could be designed. It also contains several short interludes containing fictional tales and real-life stories. The essays contained have been widely read within the rationality and effective altruism communities, and have a strong bias towards actually reading the scientific papers being discussed, analysing the arguments closely, and taking the conclusions seriously.</p></div></div><a tabindex="0" class="MuiButtonBase-root MuiButton-root MuiButton-text MuiButton-flat CollectionsPage-startReadingButton" role="button" href="https://www.lesswrong.com/codex/eight-short-studies-on-excuses"><span class="MuiButton-label">Start Reading</span><span class="MuiTouchRipple-root"></span></a></div><div><div class="CollectionsPage-section"><div><div class="SectionTitle-root"><h1 id="jF58hKP9ZLzgy22Jr" class="Typography-root Typography-display1 SectionTitle-title">Good and Bad Reasoning</h1><div class="SectionTitle-children"></div></div><div class="BooksProgressBar-root"><div class="BooksProgressBar-bookProgress"><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/gFMH3Cqw4XxwL69iy/eight-short-studies-on-excuses"><div class="BooksProgressBar-postProgressBox BooksProgressBar-read"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/Kbm6QnJv9dgWsPHQP/schelling-fences-on-slippery-slopes"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/9kcTNWopvXFncXgPy/intellectual-hipsters-and-meta-contrarianism"><div class="BooksProgressBar-postProgressBox BooksProgressBar-read"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/DSzpr8Y9299jdDLc9/cardiologists-and-chinese-robbers"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/PQ3nutgxfTgvq69Xt/all-debates-are-bravery-debates"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/2brqzQWfmNx5Agdrx/the-virtue-of-silence"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/G5eMM3Wp3hbCuKKPE/proving-too-much"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/fzeoYhKoYPR3tDYFT/beware-isolated-demands-for-rigor"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/AYbhqi65SWzHzy7Xx/transhumanist-fables"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/wJnm5cBiZGmKn595f/and-i-show-you-how-deep-the-rabbit-hole-goes"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/895quRDaK6gR2rM82/diseased-thinking-dissolving-questions-about-disease"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/aMHq4mA2PHSM2TMoH/the-categories-were-made-for-man-not-man-for-the-categories"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/yCWPkLi8wJvewPbEp/the-noncentral-fallacy-the-worst-argument-in-the-world"><div class="BooksProgressBar-postProgressBox BooksProgressBar-read"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/4xKeNKFXFB458f5N8/ethnic-tension-and-meaningless-arguments"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/BZMc9Xzqw5WcCMHrr/the-moral-of-the-story"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/9HSwh2mE3tX6xvZ2W/the-pyramid-and-the-garden"><div class="BooksProgressBar-postProgressBox BooksProgressBar-read"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/CcyGR3pp3FCDuW6Pf/on-overconfidence"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/9Tw5RqnEzqEtaoEkq/if-it-s-worth-doing-it-s-worth-doing-with-made-up-statistics"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/r8aAqSBeeeMNRtiYK/techniques-for-probability-estimates"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/GrtbTAPfkJa4D6jjH/confidence-levels-inside-and-outside-an-argument"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/2gWs8SScqeDFidqyv/the-logician-and-the-god-emperor"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/FLnDFnXyWrKr6eiT6/reverse-psychology"><div class="BooksProgressBar-postProgressBox"></div></a></span></div><div class="BooksProgressBar-sequence BooksProgressBar-progressText">4 / 22 posts read</div></div><div class="LargeSequencesItem-root" id="XsMTxdQ6fprAQMoKi"><div class="LargeSequencesItem-columns"><div class="LargeSequencesItem-left"><a class="LargeSequencesItem-imageLink" href="https://www.lesswrong.com/s/XsMTxdQ6fprAQMoKi"><div class="LargeSequencesItem-sequenceImage"><img class="LargeSequencesItem-sequenceImageImg" src="./codex_files/rfpef83ejiwbsi1pmroz"></div></a><div class="LargeSequencesItem-text"><div class="LargeSequencesItem-titleAndAuthor"><a class="LargeSequencesItem-title" href="https://www.lesswrong.com/s/XsMTxdQ6fprAQMoKi">Argument and Analysis</a></div><div class="LargeSequencesItem-description ContentStyles-base content ContentStyles-postHighlight"><div class="ContentItemTruncated-maxHeight"><p>A sequence of essays by Scott Alexander on how arguments work, how to use them, and how to misuse them.</p></div></div><span class="LWTooltip-root"><div class="LargeSequencesItem-wordcount">88 min read</div></span></div></div><div class="LargeSequencesItem-right"><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-read" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path fill="none" d="M0 0h24v24H0V0z"></path><path d="M5 19h14V5H5v14zm2.41-7.4l2.58 2.58 6.59-6.59L17.99 9l-8 8L6 13.01l1.41-1.41z" opacity=".3"></path><path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zm0 16H5V5h14v14z"></path><path d="M17.99 9l-1.41-1.42-6.59 6.59-2.58-2.57-1.42 1.41 4 3.99z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/XsMTxdQ6fprAQMoKi/p/gFMH3Cqw4XxwL69iy">Eight Short Studies On Excuses</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/XsMTxdQ6fprAQMoKi/p/Kbm6QnJv9dgWsPHQP">Schelling fences on slippery slopes</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-read" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path fill="none" d="M0 0h24v24H0V0z"></path><path d="M5 19h14V5H5v14zm2.41-7.4l2.58 2.58 6.59-6.59L17.99 9l-8 8L6 13.01l1.41-1.41z" opacity=".3"></path><path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zm0 16H5V5h14v14z"></path><path d="M17.99 9l-1.41-1.42-6.59 6.59-2.58-2.57-1.42 1.41 4 3.99z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/XsMTxdQ6fprAQMoKi/p/9kcTNWopvXFncXgPy">Intellectual Hipsters and Meta-Contrarianism</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/XsMTxdQ6fprAQMoKi/p/DSzpr8Y9299jdDLc9">Cardiologists and Chinese Robbers</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/XsMTxdQ6fprAQMoKi/p/PQ3nutgxfTgvq69Xt">All Debates Are Bravery Debates</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/XsMTxdQ6fprAQMoKi/p/2brqzQWfmNx5Agdrx">The Virtue of Silence</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/XsMTxdQ6fprAQMoKi/p/G5eMM3Wp3hbCuKKPE">Proving Too Much</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/XsMTxdQ6fprAQMoKi/p/fzeoYhKoYPR3tDYFT">Beware Isolated Demands For Rigor</a></span></div><div class="ChapterTitle-root">Interlude</div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/XsMTxdQ6fprAQMoKi/p/AYbhqi65SWzHzy7Xx">Transhumanist Fables</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/XsMTxdQ6fprAQMoKi/p/wJnm5cBiZGmKn595f">And I Show You How Deep The Rabbit Hole Goes</a></span></div></div></div></div><div class="LargeSequencesItem-root" id="NHXY86jBahi968uW4"><div class="LargeSequencesItem-columns"><div class="LargeSequencesItem-left"><a class="LargeSequencesItem-imageLink" href="https://www.lesswrong.com/s/NHXY86jBahi968uW4"><div class="LargeSequencesItem-sequenceImage"><img class="LargeSequencesItem-sequenceImageImg" src="./codex_files/bgpjay2m1labmbqdtjmi"></div></a><div class="LargeSequencesItem-text"><div class="LargeSequencesItem-titleAndAuthor"><a class="LargeSequencesItem-title" href="https://www.lesswrong.com/s/NHXY86jBahi968uW4">Categorisation and Concepts</a></div><div class="LargeSequencesItem-description ContentStyles-base content ContentStyles-postHighlight"><div class="ContentItemTruncated-maxHeight"><p>"The essay How An Algorithm Feels From The Inside is a gift that keeps on giving. You can get a reputation as a daring and original thinker just by copy-pasting it at different arguments with a couple of appropriate words substituted for one another, mad-libs like. It is the solution to something like 25% of extant philosophical problems."</p></div></div><span class="LWTooltip-root"><div class="LargeSequencesItem-wordcount">73 min read</div></span></div></div><div class="LargeSequencesItem-right"><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/NHXY86jBahi968uW4/p/895quRDaK6gR2rM82">Diseased thinking: dissolving questions about disease</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/NHXY86jBahi968uW4/p/aMHq4mA2PHSM2TMoH">The Categories Were Made For Man, Not Man For The Categories</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-read" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path fill="none" d="M0 0h24v24H0V0z"></path><path d="M5 19h14V5H5v14zm2.41-7.4l2.58 2.58 6.59-6.59L17.99 9l-8 8L6 13.01l1.41-1.41z" opacity=".3"></path><path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zm0 16H5V5h14v14z"></path><path d="M17.99 9l-1.41-1.42-6.59 6.59-2.58-2.57-1.42 1.41 4 3.99z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/NHXY86jBahi968uW4/p/yCWPkLi8wJvewPbEp">The noncentral fallacy - the worst argument in the world?</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/NHXY86jBahi968uW4/p/4xKeNKFXFB458f5N8">Ethnic Tension And Meaningless Arguments</a></span></div><div class="ChapterTitle-root">Interlude</div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/NHXY86jBahi968uW4/p/BZMc9Xzqw5WcCMHrr">The Moral Of The Story</a></span></div></div></div></div><div class="LargeSequencesItem-root" id="TQW9brvXJ5Fajorr4"><div class="LargeSequencesItem-columns"><div class="LargeSequencesItem-left"><a class="LargeSequencesItem-imageLink" href="https://www.lesswrong.com/s/TQW9brvXJ5Fajorr4"><div class="LargeSequencesItem-sequenceImage"><img class="LargeSequencesItem-sequenceImageImg" src="./codex_files/dyq1iu03mw0qo54n6byk"></div></a><div class="LargeSequencesItem-text"><div class="LargeSequencesItem-titleAndAuthor"><a class="LargeSequencesItem-title" href="https://www.lesswrong.com/s/TQW9brvXJ5Fajorr4">Probability and Predictions</a></div><div class="LargeSequencesItem-description ContentStyles-base content ContentStyles-postHighlight"><div class="ContentItemTruncated-maxHeight"><p>Nearly everyone is very very very overconfident. We know this from <span><span><span><a href="http://www.researchgate.net/profile/Baruch_Fischhoff/publication/230726569_Knowing_with_certainty_the_appropriateness_of_extreme_confidence/links/00b4952b854b29281c000000.pdf">experiments</a></span></span></span> where people answer true/false trivia questions, then are asked to state how confident they are in their answer. If peoples confidence was well-calibrated, someone who said they were 99% confident (ie only 1% chance theyre wrong) would get the question wrong only 1% of the time. In fact, people who say they are 99% confident get the question wrong about 20% of the time.</p><p>It gets worse. People who say theres only a 1 in 100,000 chance theyre wrong? Wrong 15% of the time. One in a million? Wrong 5% of the time. Theyre not just overconfident, they are <i>fifty thousand times</i> as confident as they should be.</p></div></div><span class="LWTooltip-root"><div class="LargeSequencesItem-wordcount">57 min read</div></span></div></div><div class="LargeSequencesItem-right"><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-read" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path fill="none" d="M0 0h24v24H0V0z"></path><path d="M5 19h14V5H5v14zm2.41-7.4l2.58 2.58 6.59-6.59L17.99 9l-8 8L6 13.01l1.41-1.41z" opacity=".3"></path><path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zm0 16H5V5h14v14z"></path><path d="M17.99 9l-1.41-1.42-6.59 6.59-2.58-2.57-1.42 1.41 4 3.99z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TQW9brvXJ5Fajorr4/p/9HSwh2mE3tX6xvZ2W">The Pyramid And The Garden</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TQW9brvXJ5Fajorr4/p/CcyGR3pp3FCDuW6Pf">On Overconfidence</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TQW9brvXJ5Fajorr4/p/9Tw5RqnEzqEtaoEkq">If Its Worth Doing, Its Worth Doing With Made-Up Statistics</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TQW9brvXJ5Fajorr4/p/r8aAqSBeeeMNRtiYK">Techniques for probability estimates</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TQW9brvXJ5Fajorr4/p/GrtbTAPfkJa4D6jjH">Confidence levels inside and outside an argument</a></span></div><div class="ChapterTitle-root">Interlude</div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TQW9brvXJ5Fajorr4/p/2gWs8SScqeDFidqyv">The Logician And The God-Emperor</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TQW9brvXJ5Fajorr4/p/FLnDFnXyWrKr6eiT6">Reverse Psychology</a></span></div></div></div></div></div></div><div class="CollectionsPage-section"><div><div class="SectionTitle-root"><h1 id="YhQ39PPHNrRCgYXcs" class="Typography-root Typography-display1 SectionTitle-title">The Institution of Science</h1><div class="SectionTitle-children"></div></div><div class="BooksProgressBar-root"><div class="BooksProgressBar-bookProgress"><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/ythFNoiAotjvuEGkg/beware-the-man-of-one-study"><div class="BooksProgressBar-postProgressBox BooksProgressBar-read"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/kdmCm5NQTpqhJmGm6/debunked-and-well-refuted"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/CsKrQdQJJCFPjfKjF/noisy-poll-results-and-reptilian-muslim-climatologists-from"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/SQAfPKZBAAKYMjx25/two-dark-side-statistics-papers"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/bXuAXCbzw9hsJSuEN/the-control-group-is-out-of-control"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/ckuuDa8DmJ4pdFeD8/the-cowpox-of-doubt"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/Sd2r7H8bCmd9ChGbX/how-common-are-science-failures"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/ERPL3v2Y976W7XG3j/learning-to-love-scientific-consensus"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/gBChm3THPGFcrq5eH/my-irb-nightmare"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/hMQPyLDbg3bA7P6aN/the-study-of-anglophysics"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/c8khnHoRTSGjmHLLf/marijuana-much-more-than-you-wanted-to-know"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/g4pi2jfQHFF6mPdjw/wheat-much-more-than-you-wanted-to-know"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/znEhB9hJtwXica5s3/ssris-much-more-than-you-wanted-to-know"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/CfX6pGepdjQYELSpK/alcoholics-anonymous-much-more-than-you-wanted-to-know"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/ALEYMFAuFSCz8v5YE/prescriptions-paradoxes-and-perversities"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/FW3DEYbKPZJh5A8Bj/guns-and-states"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/K9aLcuxAPyf5jGyFX/teachers-much-more-than-you-wanted-to-know"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/oHsMeXehPy4jHcmwy/antidepressant-pharmacogenomics-much-more-than-you-wanted-to"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/jFzovY2CERF5bd2EW/a-story-with-zombies"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/pfmZ5cYQCahABGZzi/asches-to-asches"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/xPJKZyPCvap4Fven8/the-atomic-bomb-considered-as-hungarian-high-school-science"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/KrEwDMN4YXp5YWD45/it-s-bayes-all-the-way-up"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/P2nYKqwmHdYKARTG8/why-are-transgender-people-immune-to-optical-illusions"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/HTGCGASf9xfB6edAh/the-case-of-the-suffocating-woman"><div class="BooksProgressBar-postProgressBox"></div></a></span></div><div class="BooksProgressBar-sequence BooksProgressBar-progressText">1 / 24 posts read</div></div><div class="LargeSequencesItem-root" id="BQBqPowfxjvoee8jw"><div class="LargeSequencesItem-columns"><div class="LargeSequencesItem-left"><a class="LargeSequencesItem-imageLink" href="https://www.lesswrong.com/s/BQBqPowfxjvoee8jw"><div class="LargeSequencesItem-sequenceImage"><img class="LargeSequencesItem-sequenceImageImg" src="./codex_files/zukiyrvljrwfe5bql7ek"></div></a><div class="LargeSequencesItem-text"><div class="LargeSequencesItem-titleAndAuthor"><a class="LargeSequencesItem-title" href="https://www.lesswrong.com/s/BQBqPowfxjvoee8jw">Studies and Statistics</a></div><div class="LargeSequencesItem-description ContentStyles-base content ContentStyles-postHighlight"><div class="ContentItemTruncated-maxHeight"><p><br>Aquinas famously <span><span><span><a href="http://en.wikipedia.org/wiki/Homo_unius_libri">said</a></span></span></span>: beware the man of one book. I would add: beware the man of one study.</p><p>For example, take medical research. Suppose a certain drug is weakly effective against a certain disease. After a few years, a bunch of different research groups have gotten their hands on it and done all sorts of different studies. In the best case scenario the average study will find the true result  that its weakly effective.</p><p>But there are also about 5 studies that find that the drug is very good, and 5 studies missing the sign entirely and finding that the drug is actively bad. Theres even 1 study finding that the drug is very bad, maybe seriously dangerous.</p></div></div><span class="LWTooltip-root"><div class="LargeSequencesItem-wordcount">140 min read</div></span></div></div><div class="LargeSequencesItem-right"><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-read" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path fill="none" d="M0 0h24v24H0V0z"></path><path d="M5 19h14V5H5v14zm2.41-7.4l2.58 2.58 6.59-6.59L17.99 9l-8 8L6 13.01l1.41-1.41z" opacity=".3"></path><path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zm0 16H5V5h14v14z"></path><path d="M17.99 9l-1.41-1.42-6.59 6.59-2.58-2.57-1.42 1.41 4 3.99z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/BQBqPowfxjvoee8jw/p/ythFNoiAotjvuEGkg">Beware The Man Of One Study</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/BQBqPowfxjvoee8jw/p/kdmCm5NQTpqhJmGm6">Debunked And Well-Refuted</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/BQBqPowfxjvoee8jw/p/CsKrQdQJJCFPjfKjF">Noisy Poll Results And Reptilian Muslim Climatologists from Mars</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/BQBqPowfxjvoee8jw/p/SQAfPKZBAAKYMjx25">Two Dark Side Statistics Papers</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/BQBqPowfxjvoee8jw/p/bXuAXCbzw9hsJSuEN">The Control Group Is Out Of Control</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/BQBqPowfxjvoee8jw/p/ckuuDa8DmJ4pdFeD8">The Cowpox of Doubt</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/BQBqPowfxjvoee8jw/p/Sd2r7H8bCmd9ChGbX">How Common Are Science Failures?</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/BQBqPowfxjvoee8jw/p/ERPL3v2Y976W7XG3j">Learning To Love Scientific Consensus</a></span></div><div class="ChapterTitle-root">Interlude</div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/BQBqPowfxjvoee8jw/p/gBChm3THPGFcrq5eH">My IRB Nightmare</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/BQBqPowfxjvoee8jw/p/hMQPyLDbg3bA7P6aN">The Study of Anglophysics</a></span></div></div></div></div><div class="LargeSequencesItem-root" id="B384FrQNrxSq4hZoS"><div class="LargeSequencesItem-columns"><div class="LargeSequencesItem-left"><a class="LargeSequencesItem-imageLink" href="https://www.lesswrong.com/s/B384FrQNrxSq4hZoS"><div class="LargeSequencesItem-sequenceImage"><img class="LargeSequencesItem-sequenceImageImg" src="./codex_files/ggdn92agzidnk0voif2z"></div></a><div class="LargeSequencesItem-text"><div class="LargeSequencesItem-titleAndAuthor"><a class="LargeSequencesItem-title" href="https://www.lesswrong.com/s/B384FrQNrxSq4hZoS">Research and Reviews</a></div><div class="LargeSequencesItem-description ContentStyles-base content ContentStyles-postHighlight"><div class="ContentItemTruncated-maxHeight"><p>Synthesising scientific knowledge to answer a policy question is difficult. This sequence is a series of attempts to do just that, with intricate and winding literature reviews.</p></div></div><span class="LWTooltip-root"><div class="LargeSequencesItem-wordcount">191 min read</div></span></div></div><div class="LargeSequencesItem-right"><div class="ChapterTitle-root">Much More Than You Wanted to Know</div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/B384FrQNrxSq4hZoS/p/c8khnHoRTSGjmHLLf">Marijuana: Much More Than You Wanted To Know</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/B384FrQNrxSq4hZoS/p/g4pi2jfQHFF6mPdjw">Wheat: Much More Than You Wanted To Know</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/B384FrQNrxSq4hZoS/p/znEhB9hJtwXica5s3">SSRIs: Much More Than You Wanted To Know</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/B384FrQNrxSq4hZoS/p/CfX6pGepdjQYELSpK">Alcoholics Anonymous: Much More Than You Wanted To Know</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/B384FrQNrxSq4hZoS/p/ALEYMFAuFSCz8v5YE">Prescriptions, Paradoxes, and Perversities</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/B384FrQNrxSq4hZoS/p/FW3DEYbKPZJh5A8Bj">Guns And States</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/B384FrQNrxSq4hZoS/p/K9aLcuxAPyf5jGyFX">Teachers: Much More Than You Wanted To Know</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/B384FrQNrxSq4hZoS/p/oHsMeXehPy4jHcmwy">Antidepressant Pharmacogenomics: Much More Than You Wanted To Know</a></span></div><div class="ChapterTitle-root">Interlude</div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/B384FrQNrxSq4hZoS/p/jFzovY2CERF5bd2EW">A Story With Zombies</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/B384FrQNrxSq4hZoS/p/pfmZ5cYQCahABGZzi">Asches to Asches</a></span></div></div></div></div><div class="LargeSequencesItem-root" id="k5MPpr72eiGknaS7F"><div class="LargeSequencesItem-columns"><div class="LargeSequencesItem-left"><a class="LargeSequencesItem-imageLink" href="https://www.lesswrong.com/s/k5MPpr72eiGknaS7F"><div class="LargeSequencesItem-sequenceImage"><img class="LargeSequencesItem-sequenceImageImg" src="./codex_files/byzxi4zdrlvodk0ph46r"></div></a><div class="LargeSequencesItem-text"><div class="LargeSequencesItem-titleAndAuthor"><a class="LargeSequencesItem-title" href="https://www.lesswrong.com/s/k5MPpr72eiGknaS7F">Hypotheses and Hunches</a></div><div class="LargeSequencesItem-description ContentStyles-base content ContentStyles-postHighlight"><div class="ContentItemTruncated-maxHeight"><div class="ory-row"><div class="ory-cell ory-cell-sm-12 ory-cell-xs-12"><div class="ory-cell-inner ory-cell-leaf"><div><p></p></div></div></div></div></div></div><span class="LWTooltip-root"><div class="LargeSequencesItem-wordcount">52 min read</div></span></div></div><div class="LargeSequencesItem-right"><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/k5MPpr72eiGknaS7F/p/xPJKZyPCvap4Fven8">The Atomic Bomb Considered As Hungarian High School Science Fair Project</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/k5MPpr72eiGknaS7F/p/KrEwDMN4YXp5YWD45">Its Bayes All The Way Up</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/k5MPpr72eiGknaS7F/p/P2nYKqwmHdYKARTG8">Why Are Transgender People Immune To Optical Illusions?</a></span></div><div class="ChapterTitle-root">Interlude</div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/k5MPpr72eiGknaS7F/p/HTGCGASf9xfB6edAh">The Case Of The Suffocating Woman</a></span></div></div></div></div></div></div><div class="CollectionsPage-section"><div><div class="SectionTitle-root"><h1 id="kcCvSNNZd8pfQvf9E" class="Typography-root Typography-display1 SectionTitle-title">Designing the World</h1><div class="SectionTitle-children"></div></div><div class="BooksProgressBar-root"><div class="BooksProgressBar-bookProgress"><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/GLMFmFvXGyAcG25ni/i-can-tolerate-anything-except-the-outgroup"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/Y345zuBetHqGnotwm/book-review-albion-s-seed"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/BpYDqQNZ2NZNCqPp6/albion-s-seed-genotyped"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/2HafkDSNdtMzptzcN/society-is-fixed-biology-is-mutable"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/BPKvZuLRyiJBjfNbg/a-philosopher-walks-into-a-coffee-shop"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/8KHR3tfa4SJjMSkXd/the-witching-hour"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/Fafzj3wMvoCW4WjeF/against-tulip-subsidies"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/BBQ5HEnL3ShefQxEj/considerations-on-cost-disease"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/ofL22R6KZsfrvdmwg/highlights-from-the-comments-on-cost-disease"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/oMiogKLkK8L59WzDe/the-price-of-glee-in-china"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/efMgZujzfjP9B9H4R/things-probably-matter"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/m7THsgXyxxiEXgyHv/how-the-west-was-won"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/iLMkKDKmfbMkDuQBm/the-lizard-people-of-alpha-draconis-1-decided-to-build-an"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/kSiT2XjfTnDHKx44W/a-modern-myth"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/LTtNXM9shNM9AC2mp/superintelligence-faq"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/sm6npdgZArSn4afeZ/ai-researchers-on-ai-risk"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/pgGiqLQg2KWsaz5RE/should-ai-be-open"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/qL8Z9TBCNWQyN6yLq/ssc-journal-club-ai-timelines"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/LY7Nca846X8kcT8Jk/where-the-falling-einstein-meets-the-rising-mouse"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/mnpkM57R6ZbjnwrYw/don-t-fear-the-filter"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/pZerSnxv6FPqvgoYu/book-review-age-of-em"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/ak9wY2t9K3K4GxCXv/ascended-economy"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/muhtBvbh4etjkKXd9/g-k-chesterton-on-ai-risk"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/Wh8HAK6LR5CAoPCCC/repost-the-demiurge-s-older-brother"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/rkpDX7j7va6c8Q7cZ/in-favor-of-niceness-community-and-civilization"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/qajfiXo5qRThZQG7s/guided-by-the-beauty-of-our-weapons"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/xtHd6sfdr2bZHa6Pb/the-ideology-is-not-the-movement"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/aP36QcAsxyuEispq6/archipelago-and-atomic-communitarianism"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/TxcRbCYHaeL59aY7E/meditations-on-moloch"><div class="BooksProgressBar-postProgressBox BooksProgressBar-read"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/ouSpHCCPgsXkwxAGb/five-planets-in-search-of-a-sci-fi-story"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/qaHHJ3kkCQS4nsoGJ/it-was-you-who-made-my-blue-eyes-blue"><div class="BooksProgressBar-postProgressBox"></div></a></span></div><div class="BooksProgressBar-sequence BooksProgressBar-progressText">1 / 31 posts read</div></div><div class="LargeSequencesItem-root" id="rNuPrZvabXe2MaZv8"><div class="LargeSequencesItem-columns"><div class="LargeSequencesItem-left"><a class="LargeSequencesItem-imageLink" href="https://www.lesswrong.com/s/rNuPrZvabXe2MaZv8"><div class="LargeSequencesItem-sequenceImage"><img class="LargeSequencesItem-sequenceImageImg" src="./codex_files/acfvxltz0mnyd7jqdq76"></div></a><div class="LargeSequencesItem-text"><div class="LargeSequencesItem-titleAndAuthor"><a class="LargeSequencesItem-title" href="https://www.lesswrong.com/s/rNuPrZvabXe2MaZv8">Politics and Pragmatics</a></div><div class="LargeSequencesItem-description ContentStyles-base content ContentStyles-postHighlight"><div class="ContentItemTruncated-maxHeight"><div class="ory-row"><div class="ory-cell ory-cell-sm-12 ory-cell-xs-12"><div class="ory-cell-inner ory-cell-leaf"><div><p></p></div></div></div></div></div></div><span class="LWTooltip-root"><div class="LargeSequencesItem-wordcount">91 min read</div></span></div></div><div class="LargeSequencesItem-right"><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/rNuPrZvabXe2MaZv8/p/GLMFmFvXGyAcG25ni">I Can Tolerate Anything Except The Outgroup</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/rNuPrZvabXe2MaZv8/p/Y345zuBetHqGnotwm">Book Review: Albions Seed</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/rNuPrZvabXe2MaZv8/p/BpYDqQNZ2NZNCqPp6">Albions Seed, Genotyped</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/rNuPrZvabXe2MaZv8/p/2HafkDSNdtMzptzcN">Society Is Fixed, Biology Is Mutable</a></span></div><div class="ChapterTitle-root">Interlude</div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/rNuPrZvabXe2MaZv8/p/BPKvZuLRyiJBjfNbg">A Philosopher Walks Into A Coffee Shop</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/rNuPrZvabXe2MaZv8/p/8KHR3tfa4SJjMSkXd">The Witching Hour</a></span></div></div></div></div><div class="LargeSequencesItem-root" id="zfXAcwLnGocsCsriG"><div class="LargeSequencesItem-columns"><div class="LargeSequencesItem-left"><a class="LargeSequencesItem-imageLink" href="https://www.lesswrong.com/s/zfXAcwLnGocsCsriG"><div class="LargeSequencesItem-sequenceImage"><img class="LargeSequencesItem-sequenceImageImg" src="./codex_files/hxgrnxobgf692eqpd8mz"></div></a><div class="LargeSequencesItem-text"><div class="LargeSequencesItem-titleAndAuthor"><a class="LargeSequencesItem-title" href="https://www.lesswrong.com/s/zfXAcwLnGocsCsriG">Economics and Efficiency</a></div><div class="LargeSequencesItem-description ContentStyles-base content ContentStyles-postHighlight"><div class="ContentItemTruncated-maxHeight"><div class="ory-row"><div class="ory-cell ory-cell-sm-12 ory-cell-xs-12"><div class="ory-cell-inner ory-cell-leaf"><div><p></p></div></div></div></div></div></div><span class="LWTooltip-root"><div class="LargeSequencesItem-wordcount">163 min read</div></span></div></div><div class="LargeSequencesItem-right"><div class="ChapterTitle-root">Marginally Important Econ Questions</div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/zfXAcwLnGocsCsriG/p/Fafzj3wMvoCW4WjeF">Against Tulip Subsidies</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/zfXAcwLnGocsCsriG/p/BBQ5HEnL3ShefQxEj">Considerations On Cost Disease</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/zfXAcwLnGocsCsriG/p/ofL22R6KZsfrvdmwg">Highlights From The Comments On Cost Disease</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/zfXAcwLnGocsCsriG/p/oMiogKLkK8L59WzDe">The Price Of Glee In China</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/zfXAcwLnGocsCsriG/p/efMgZujzfjP9B9H4R">Things Probably Matter</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/zfXAcwLnGocsCsriG/p/m7THsgXyxxiEXgyHv">How The West Was Won</a></span></div><div class="ChapterTitle-root">Interlude</div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/zfXAcwLnGocsCsriG/p/iLMkKDKmfbMkDuQBm">The Lizard People Of Alpha Draconis 1 Decided To Build An Ansible</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/zfXAcwLnGocsCsriG/p/kSiT2XjfTnDHKx44W">A Modern Myth</a></span></div></div></div></div><div class="LargeSequencesItem-root" id="TKDT2Mt6dDMH8AsZW"><div class="LargeSequencesItem-columns"><div class="LargeSequencesItem-left"><a class="LargeSequencesItem-imageLink" href="https://www.lesswrong.com/s/TKDT2Mt6dDMH8AsZW"><div class="LargeSequencesItem-sequenceImage"><img class="LargeSequencesItem-sequenceImageImg" src="./codex_files/lel3jdh48of1dhtwfo4i"></div></a><div class="LargeSequencesItem-text"><div class="LargeSequencesItem-titleAndAuthor"><a class="LargeSequencesItem-title" href="https://www.lesswrong.com/s/TKDT2Mt6dDMH8AsZW">Futurism and Forecasting</a></div><div class="LargeSequencesItem-description ContentStyles-base content ContentStyles-postHighlight"><div class="ContentItemTruncated-maxHeight"><p>A sequence of futurism discussion that includes AGI, brain emulations and the Fermi paradox.</p></div></div><span class="LWTooltip-root"><div class="LargeSequencesItem-wordcount">155 min read</div></span></div></div><div class="LargeSequencesItem-right"><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TKDT2Mt6dDMH8AsZW/p/LTtNXM9shNM9AC2mp">Superintelligence FAQ</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TKDT2Mt6dDMH8AsZW/p/sm6npdgZArSn4afeZ">AI Researchers On AI Risk</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TKDT2Mt6dDMH8AsZW/p/pgGiqLQg2KWsaz5RE">Should AI Be Open?</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TKDT2Mt6dDMH8AsZW/p/qL8Z9TBCNWQyN6yLq">SSC Journal Club: AI Timelines</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TKDT2Mt6dDMH8AsZW/p/LY7Nca846X8kcT8Jk">Where The Falling Einstein Meets The Rising Mouse</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TKDT2Mt6dDMH8AsZW/p/mnpkM57R6ZbjnwrYw">Dont Fear The Filter</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TKDT2Mt6dDMH8AsZW/p/pZerSnxv6FPqvgoYu">Book Review: Age of Em</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TKDT2Mt6dDMH8AsZW/p/ak9wY2t9K3K4GxCXv">Ascended Economy?</a></span></div><div class="ChapterTitle-root">Interlude</div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TKDT2Mt6dDMH8AsZW/p/muhtBvbh4etjkKXd9">G.K. Chesterton On AI Risk</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/TKDT2Mt6dDMH8AsZW/p/Wh8HAK6LR5CAoPCCC">[REPOST] The Demiurges Older Brother</a></span></div></div></div></div><div class="LargeSequencesItem-root" id="xmDeR64CivZiTAcLx"><div class="LargeSequencesItem-columns"><div class="LargeSequencesItem-left"><a class="LargeSequencesItem-imageLink" href="https://www.lesswrong.com/s/xmDeR64CivZiTAcLx"><div class="LargeSequencesItem-sequenceImage"><img class="LargeSequencesItem-sequenceImageImg" src="./codex_files/u0ackeoho1tquuiozpt4"></div></a><div class="LargeSequencesItem-text"><div class="LargeSequencesItem-titleAndAuthor"><a class="LargeSequencesItem-title" href="https://www.lesswrong.com/s/xmDeR64CivZiTAcLx">Community and Cooperation</a></div><span class="LWTooltip-root"><div class="LargeSequencesItem-wordcount">189 min read</div></span></div></div><div class="LargeSequencesItem-right"><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/xmDeR64CivZiTAcLx/p/rkpDX7j7va6c8Q7cZ">In Favor of Niceness, Community, and Civilization</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/xmDeR64CivZiTAcLx/p/qajfiXo5qRThZQG7s">Guided By The Beauty Of Our Weapons</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/xmDeR64CivZiTAcLx/p/xtHd6sfdr2bZHa6Pb">The Ideology Is Not The Movement</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/xmDeR64CivZiTAcLx/p/aP36QcAsxyuEispq6">Archipelago and Atomic Communitarianism</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-read" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path fill="none" d="M0 0h24v24H0V0z"></path><path d="M5 19h14V5H5v14zm2.41-7.4l2.58 2.58 6.59-6.59L17.99 9l-8 8L6 13.01l1.41-1.41z" opacity=".3"></path><path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zm0 16H5V5h14v14z"></path><path d="M17.99 9l-1.41-1.42-6.59 6.59-2.58-2.57-1.42 1.41 4 3.99z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/xmDeR64CivZiTAcLx/p/TxcRbCYHaeL59aY7E">Meditations On Moloch</a></span></div><div class="ChapterTitle-root">Interlude</div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/xmDeR64CivZiTAcLx/p/ouSpHCCPgsXkwxAGb">Five Planets In Search Of A Sci-Fi Story</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/xmDeR64CivZiTAcLx/p/qaHHJ3kkCQS4nsoGJ">It Was You Who Made My Blue Eyes Blue</a></span></div></div></div></div></div></div><div class="CollectionsPage-section"><div><div class="SectionTitle-root"><h1 id="2tPEd5Gdm3iewB53M" class="Typography-root Typography-display1 SectionTitle-title">Epilogue</h1><div class="SectionTitle-children"></div></div><div class="BooksProgressBar-root"><div class="BooksProgressBar-bookProgress"><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/JP7eZYHB7aY6fA4TR/burdens"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/zwDz9pgT43fRczkB4/the-parable-of-the-talents"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/qw3Z79HELMsmLkL9F/nobody-is-perfect-everything-is-commensurable"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/Lt8Rn4rkYwqiTXGPy/answer-to-job"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/SvKSwT6xYfYahH4XN/universal-love-said-the-cactus-person"><div class="BooksProgressBar-postProgressBox"></div></a></span><span class="LWTooltip-root"><a href="https://www.lesswrong.com/posts/MFNJ7kQttCuCXHp8P/the-goddess-of-everything-else"><div class="BooksProgressBar-postProgressBox"></div></a></span></div><div class="BooksProgressBar-sequence BooksProgressBar-progressText">0 / 6 posts read</div></div><div class="LargeSequencesItem-root" id="WnTvZdXz2q9ySfr4o"><div class="LargeSequencesItem-columns"><div class="LargeSequencesItem-left"><a class="LargeSequencesItem-imageLink" href="https://www.lesswrong.com/s/WnTvZdXz2q9ySfr4o"><div class="LargeSequencesItem-sequenceImage"><img class="LargeSequencesItem-sequenceImageImg" src="./codex_files/opwbi6lh0ud7r7dlyghc"></div></a><div class="LargeSequencesItem-text"><div class="LargeSequencesItem-titleAndAuthor"><a class="LargeSequencesItem-title" href="https://www.lesswrong.com/s/WnTvZdXz2q9ySfr4o">Parables and Prayers</a></div><div class="LargeSequencesItem-description ContentStyles-base content ContentStyles-postHighlight"><div class="ContentItemTruncated-maxHeight"><div class="ory-row"><div class="ory-cell ory-cell-sm-12 ory-cell-xs-12"><div class="ory-cell-inner ory-cell-leaf"><div><p></p></div></div></div></div></div></div><span class="LWTooltip-root"><div class="LargeSequencesItem-wordcount">69 min read</div></span></div></div><div class="LargeSequencesItem-right"><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/WnTvZdXz2q9ySfr4o/p/JP7eZYHB7aY6fA4TR">Burdens</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/WnTvZdXz2q9ySfr4o/p/zwDz9pgT43fRczkB4">The Parable Of The Talents</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/WnTvZdXz2q9ySfr4o/p/qw3Z79HELMsmLkL9F">Nobody Is Perfect, Everything Is Commensurable</a></span></div><div class="ChapterTitle-root">Interlude</div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/WnTvZdXz2q9ySfr4o/p/Lt8Rn4rkYwqiTXGPy">Answer to Job</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/WnTvZdXz2q9ySfr4o/p/SvKSwT6xYfYahH4XN">Universal Love, Said The Cactus Person</a></span></div><div class="SequencesSmallPostLink-title"><span class="SequencesSmallPostLink-checkbox"><span class="LWTooltip-root"><svg class="MuiSvgIcon-root PostReadCheckbox-root PostReadCheckbox-unread" focusable="false" viewBox="0 0 24 24" aria-hidden="true" role="presentation" style="width: 12px;"><path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"></path><path fill="none" d="M0 0h24v24H0z"></path></svg></span></span><span class=""><a href="https://www.lesswrong.com/s/WnTvZdXz2q9ySfr4o/p/MFNJ7kQttCuCXHp8P">The Goddess of Everything Else</a></span></div></div></div></div></div></div></div></div><div class="ToCColumn-gap2"></div><div class="ToCColumn-gap3"></div></div></div><div class="Footer-root"></div></div></div></div></div>

<script>window.ssrRenderedAt = "2023-02-10T16:22:41.943Z"</script>
<script>window.__APOLLO_STATE__ = {"Revision:P4zDcpuj7sXjWMSwh_biography":{"_id":"P4zDcpuj7sXjWMSwh_biography","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2022-09-26T19:17:47.925Z","userId":"P4zDcpuj7sXjWMSwh","originalContents":{"__typename":"ContentType","type":"ckEditorMarkup","data":""},"html":"","markdown":"","draftJS":{"blocks":[{"key":"d41d8","text":"","type":"unstyled","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}}],"entityMap":{}},"ckEditorMarkup":"","wordCount":1,"htmlHighlight":"","plaintextDescription":null},"Revision:P4zDcpuj7sXjWMSwh_moderationGuidelines":{"_id":"P4zDcpuj7sXjWMSwh_moderationGuidelines","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2022-09-26T19:17:47.805Z","userId":"P4zDcpuj7sXjWMSwh","originalContents":{"__typename":"ContentType","type":"ckEditorMarkup","data":""},"html":"","markdown":"","draftJS":{"blocks":[{"key":"d41d8","text":"","type":"unstyled","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}}],"entityMap":{}},"ckEditorMarkup":"","wordCount":1,"htmlHighlight":"","plaintextDescription":null},"User:P4zDcpuj7sXjWMSwh":{"_id":"P4zDcpuj7sXjWMSwh","__typename":"User","beta":null,"email":"bart.bussmann@uantwerpen.be","services":{"password":{},"email":{},"resume":{}},"acceptedTos":null,"pageUrl":"https://www.lesswrong.com/users/stuckwork","voteBanned":null,"banned":null,"isReviewed":true,"nullifyVotes":null,"hideIntercom":null,"hideNavigationSidebar":false,"currentFrontpageFilter":null,"frontpageFilterSettings":{"personalBlog":0,"tags":[{"tagId":"Ng8Gice9KNkncxqcj","tagName":"Rationality","filterMode":10},{"tagId":"sYm3HiWcfZvrGu3ui","tagName":"AI","filterMode":-25},{"tagId":"3uE2pXvbcnS9nnZRE","tagName":"World Modeling","filterMode":10},{"tagId":"xexCWMyds6QLWognu","tagName":"World Optimization","filterMode":25},{"tagId":"fkABsGCJZ6y9qConW","tagName":"Practical","filterMode":25},{"tagId":"izp6eeJJEg9v5zcur","tagName":"Community","filterMode":"Default"},{"tagId":"dqx5k65wjFfaiJ9sQ","tagName":"Procrastination","filterMode":25},{"tagId":"udPbn9RthmgTtHMiG","tagName":"Productivity","filterMode":25},{"tagId":"tNsqhzTibgGJKPEWB","tagName":"Coronavirus","filterMode":-25},{"tagId":"sSNtcEQsqHgN8ZmRF","tagName":"Fun Theory","filterMode":25},{"tagId":"irYLXtT9hkPXoZqhH","tagName":"Growth Stories","filterMode":25},{"tagId":"AodfCFefLAuwDyj7Z","tagName":"Self Experimentation","filterMode":25},{"tagId":"WqLn4pAWi5hn6McHQ","tagName":"Self Improvement","filterMode":25}]},"hideFrontpageFilterSettingsDesktop":null,"allPostsTimeframe":"allTime","allPostsSorting":"top","allPostsFilter":"frontpage","allPostsShowLowKarma":null,"allPostsIncludeEvents":null,"allPostsOpenSettings":true,"draftsListSorting":null,"draftsListShowArchived":null,"draftsListShowShared":null,"lastNotificationsCheck":"2023-01-10T14:22:09.579Z","bannedUserIds":null,"bannedPersonalUserIds":null,"biography":{"__ref":"Revision:P4zDcpuj7sXjWMSwh_biography"},"moderationStyle":null,"moderationGuidelines":{"__ref":"Revision:P4zDcpuj7sXjWMSwh_moderationGuidelines"},"noKibitz":null,"showHideKarmaOption":null,"markDownPostEditor":null,"hideElicitPredictions":null,"hideAFNonMemberInitialWarning":null,"commentSorting":"postCommentsTop","location":"","googleLocation":null,"mongoLocation":null,"mapLocation":null,"mapLocationSet":false,"mapMarkerText":null,"htmlMapMarkerText":"","nearbyEventsNotifications":true,"nearbyEventsNotificationsLocation":{"address_components":[{"long_name":"Antwerp","short_name":"Antwerp","types":["locality","political"]},{"long_name":"Antwerp","short_name":"AN","types":["administrative_area_level_2","political"]},{"long_name":"Flanders","short_name":"Flanders","types":["administrative_area_level_1","political"]},{"long_name":"Belgium","short_name":"BE","types":["country","political"]}],"adr_address":"<span class=\"locality\">Antwerp<\/span>, <span class=\"country-name\">Belgium<\/span>","formatted_address":"Antwerp, Belgium","geometry":{"location":{"lat":51.2194475,"lng":4.4024643},"viewport":{"south":51.14334002058517,"west":4.217600064800268,"north":51.37743006638301,"east":4.497840011267312}},"icon":"https://maps.gstatic.com/mapfiles/place_api/icons/v1/png_71/geocode-71.png","icon_background_color":"#7B9EB0","icon_mask_base_uri":"https://maps.gstatic.com/mapfiles/place_api/icons/v2/generic_pinlet","name":"Antwerp","photos":[{"height":3468,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/115378283856592738578\">Nanny Bierkens Brouwers<\/a>"],"width":4624},{"height":3648,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/112420603678656129455\">Koen Vermast<\/a>"],"width":2736},{"height":3472,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/107785888654238559604\">Gabriel Kowalski<\/a>"],"width":4624},{"height":3000,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/111509551464512526264\">Wendell Lins<\/a>"],"width":4000},{"height":3024,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/106379315498608992869\">Florian Truestedt<\/a>"],"width":4032},{"height":4032,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/100586229028946490622\">Herwig Aertbelien<\/a>"],"width":2268},{"height":4000,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/111603820554165793043\">Gabriel Lambert<\/a>"],"width":2252},{"height":3024,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/100226050364319902366\">Sige Nagels<\/a>"],"width":4032},{"height":2268,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/112748523251514087962\">Pavel Stulir<\/a>"],"width":4032},{"height":4000,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/103590333584434233469\">Panagiotis Chatzimichail<\/a>"],"width":3000}],"place_id":"ChIJfYjDv472w0cRuIqogoRErz4","reference":"ChIJfYjDv472w0cRuIqogoRErz4","types":["locality","political"],"url":"https://maps.google.com/?q=Antwerp,+Belgium&ftid=0x47c3f68ebfc3887d:0x3eaf448482a88ab8","utc_offset":60,"vicinity":"Antwerp","website":"http://www.antwerpen.be/","html_attributions":[],"utc_offset_minutes":60},"nearbyEventsNotificationsRadius":99,"nearbyPeopleNotificationThreshold":null,"hideFrontpageMap":null,"emailSubscribedToCurated":null,"subscribedToDigest":null,"unsubscribeFromAll":null,"emails":[{"address":"bart.bussmann@uantwerpen.be","verified":true}],"whenConfirmationEmailSent":null,"hideSubscribePoke":null,"hideMeetupsPoke":null,"noCollapseCommentsFrontpage":null,"noCollapseCommentsPosts":null,"noSingleLineComments":null,"karmaChangeNotifierSettings":{"updateFrequency":"daily","timeOfDayGMT":11,"dayOfWeekGMT":"Saturday","showNegativeKarma":false},"karmaChangeLastOpened":null,"shortformFeedId":null,"viewUnreviewedComments":null,"recommendationSettings":{"frontpage":{"method":"sample","count":3,"scoreOffset":0,"scoreExponent":3,"personalBlogpostModifier":0,"includePersonal":true,"includeMeta":false,"frontpageModifier":10,"curatedModifier":50,"onlyUnread":true,"hideContinueReading":true,"hideBookmarks":true}},"theme":null,"bookmarkedPostsMetadata":null,"hiddenPostsMetadata":null,"auto_subscribe_to_my_posts":true,"auto_subscribe_to_my_comments":true,"autoSubscribeAsOrganizer":true,"noExpandUnreadCommentsReview":null,"reviewVotesQuadratic":null,"reviewVotesQuadratic2019":null,"reviewVotesQuadratic2020":null,"hideTaggingProgressBar":null,"hideFrontpageBookAd":null,"hideFrontpageBook2019Ad":null,"abTestKey":"W7oqEuwqPe7HFXZqc","abTestOverrides":null,"sortDraftsBy":null,"petrovPressedButtonDate":null,"petrovLaunchCodeDate":null,"petrovOptOut":true,"lastUsedTimezone":"Europe/Amsterdam","acknowledgedNewUserGuidelines":null,"notificationSubforumUnread":null,"subforumPreferredLayout":null,"experiencedIn":null,"interestedIn":null,"allowDatadogSessionReplay":null,"oldSlugs":null,"groups":["canModeratePersonal"],"jobTitle":null,"organization":null,"careerStage":null,"howOthersCanHelpMe":null,"howICanHelpOthers":null,"profileTagIds":null,"profileTags":[],"organizerOfGroupIds":null,"organizerOfGroups":[],"programParticipation":null,"website":null,"linkedinProfileURL":null,"facebookProfileURL":null,"twitterProfileURL":null,"githubProfileURL":null,"frontpagePostCount":2,"afSequenceCount":null,"afSequenceDraftCount":null,"sequenceDraftCount":null,"profileImageId":null,"noindex":null,"paymentEmail":null,"paymentInfo":null,"goodHeartTokens":16,"postingDisabled":null,"allCommentingDisabled":null,"commentingOnOtherUsersDisabled":null,"conversationsDisabled":null,"walledGardenInvite":null,"hideWalledGardenUI":null,"walledGardenPortalOnboarded":null,"taggingDashboardCollapsed":null,"usernameUnset":null,"slug":"stuckwork","createdAt":"2020-10-10T16:33:19.165Z","username":"Stuckwork","displayName":"Stuckwork","previousDisplayName":null,"fullName":null,"karma":111,"afKarma":0,"deleted":null,"isAdmin":false,"htmlBio":"","postCount":2,"commentCount":16,"sequenceCount":null,"afPostCount":null,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0,"maxCommentCount":16,"maxPostCount":2,"voteCount":79,"smallUpvoteCount":31,"bigUpvoteCount":30,"smallDownvoteCount":6,"bigDownvoteCount":4,"reviewedByUserId":"XtphY3uYHwruKqDyG","reviewedAt":"2020-10-31T20:02:50.027Z","signUpReCaptchaRating":null,"needsReview":false,"sunshineNotes":null,"sunshineFlagged":false,"snoozedUntilContentCount":null,"moderatorActions":null,"usersContactedBeforeReview":null,"associatedClientId":null,"karmaChanges":{"__typename":"KarmaChanges","totalChange":0,"updateFrequency":"daily","startDate":"2023-02-09T11:00:00.000Z","endDate":"2023-02-10T11:00:00.000Z","nextBatchDate":"2023-02-11T11:00:00.000Z","posts":[],"comments":[],"tagRevisions":[]}},"ROOT_QUERY":{"__typename":"Query","currentUser":{"__ref":"User:P4zDcpuj7sXjWMSwh"},"featuredResources({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"limit\":10,\"view\":\"activeResources\"}}})":{"__typename":"MultiFeaturedResourceOutput","results":[],"totalCount":null},"unreadNotificationCounts":{"__typename":"NotificationCounts","unreadNotifications":0,"unreadPrivateMessages":0},"tags({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"limit\":100,\"view\":\"suggestedFilterTags\"}}})":{"__typename":"MultiTagOutput","results":[{"__ref":"Tag:Ng8Gice9KNkncxqcj"},{"__ref":"Tag:sYm3HiWcfZvrGu3ui"},{"__ref":"Tag:3uE2pXvbcnS9nnZRE"},{"__ref":"Tag:xexCWMyds6QLWognu"},{"__ref":"Tag:fkABsGCJZ6y9qConW"},{"__ref":"Tag:izp6eeJJEg9v5zcur"}],"totalCount":null},"tag({\"input\":{\"selector\":{\"documentId\":\"Ng8Gice9KNkncxqcj\"}}})":{"__typename":"SingleTagOutput","result":{"__ref":"Tag:Ng8Gice9KNkncxqcj"}},"tag({\"input\":{\"selector\":{\"documentId\":\"sYm3HiWcfZvrGu3ui\"}}})":{"__typename":"SingleTagOutput","result":{"__ref":"Tag:sYm3HiWcfZvrGu3ui"}},"tag({\"input\":{\"selector\":{\"documentId\":\"3uE2pXvbcnS9nnZRE\"}}})":{"__typename":"SingleTagOutput","result":{"__ref":"Tag:3uE2pXvbcnS9nnZRE"}},"tag({\"input\":{\"selector\":{\"documentId\":\"xexCWMyds6QLWognu\"}}})":{"__typename":"SingleTagOutput","result":{"__ref":"Tag:xexCWMyds6QLWognu"}},"tag({\"input\":{\"selector\":{\"documentId\":\"fkABsGCJZ6y9qConW\"}}})":{"__typename":"SingleTagOutput","result":{"__ref":"Tag:fkABsGCJZ6y9qConW"}},"tag({\"input\":{\"selector\":{\"documentId\":\"izp6eeJJEg9v5zcur\"}}})":{"__typename":"SingleTagOutput","result":{"__ref":"Tag:izp6eeJJEg9v5zcur"}},"tag({\"input\":{\"selector\":{\"documentId\":\"dqx5k65wjFfaiJ9sQ\"}}})":{"__typename":"SingleTagOutput","result":{"__ref":"Tag:dqx5k65wjFfaiJ9sQ"}},"tag({\"input\":{\"selector\":{\"documentId\":\"udPbn9RthmgTtHMiG\"}}})":{"__typename":"SingleTagOutput","result":{"__ref":"Tag:udPbn9RthmgTtHMiG"}},"tag({\"input\":{\"selector\":{\"documentId\":\"tNsqhzTibgGJKPEWB\"}}})":{"__typename":"SingleTagOutput","result":{"__ref":"Tag:tNsqhzTibgGJKPEWB"}},"tag({\"input\":{\"selector\":{\"documentId\":\"sSNtcEQsqHgN8ZmRF\"}}})":{"__typename":"SingleTagOutput","result":{"__ref":"Tag:sSNtcEQsqHgN8ZmRF"}},"tag({\"input\":{\"selector\":{\"documentId\":\"irYLXtT9hkPXoZqhH\"}}})":{"__typename":"SingleTagOutput","result":{"__ref":"Tag:irYLXtT9hkPXoZqhH"}},"tag({\"input\":{\"selector\":{\"documentId\":\"AodfCFefLAuwDyj7Z\"}}})":{"__typename":"SingleTagOutput","result":{"__ref":"Tag:AodfCFefLAuwDyj7Z"}},"tag({\"input\":{\"selector\":{\"documentId\":\"WqLn4pAWi5hn6McHQ\"}}})":{"__typename":"SingleTagOutput","result":{"__ref":"Tag:WqLn4pAWi5hn6McHQ"}},"notifications({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"limit\":20,\"userId\":\"P4zDcpuj7sXjWMSwh\",\"view\":\"userNotifications\"}}})":{"__typename":"MultiNotificationOutput","results":[{"__ref":"Notification:5cm5Fh9zmvpdFdRJS"},{"__ref":"Notification:MQNSsQJEtc4TynnHK"},{"__ref":"Notification:aRfMcE6wnZHJuioDK"},{"__ref":"Notification:fRospfegkFaK6t2bn"},{"__ref":"Notification:Bcj9kdJqYu9pqXM4Y"},{"__ref":"Notification:dzyspHv2MXQFdGktb"},{"__ref":"Notification:oruCmFkh9eNEjqwxC"},{"__ref":"Notification:Qhiz5xCagSxsE2StA"},{"__ref":"Notification:hj4wrbrZLKgx4GAqX"},{"__ref":"Notification:5PzoZNgyDxLsuzhCa"},{"__ref":"Notification:tvEQ25xW2Kw9ckty9"},{"__ref":"Notification:9HDCtMETNsadckTWm"},{"__ref":"Notification:NX865rwsvfWra5Krk"},{"__ref":"Notification:jGF3iyXyiQxXoTDKN"},{"__ref":"Notification:mQycwuMfMLjdGiEZD"},{"__ref":"Notification:LKo5ipftkjZKCWTcm"},{"__ref":"Notification:p7bWsaj9ppWzW7ZAJ"},{"__ref":"Notification:LndcjC6GT4SiCkNad"},{"__ref":"Notification:AFWCuvKEfsBQSpntg"},{"__ref":"Notification:PMEhyN4kqeoagnAHF"}],"totalCount":null},"posts({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"limit\":2,\"view\":\"globalEvents\"}}})":{"__typename":"MultiPostOutput","results":[{"__ref":"Post:JGf5RYqCfGuhvtAu3"}],"totalCount":null},"posts({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"limit\":3,\"view\":\"curated\"}}})":{"__typename":"MultiPostOutput","results":[{"__ref":"Post:aPeJE8bSo6rAFoLqg"},{"__ref":"Post:Zp6wG5eQFLGWwcG6j"},{"__ref":"Post:XPv4sYrKnPzeJASuk"}],"totalCount":null},"ContinueReading":[{"__typename":"RecommendResumeSequence","sequence":{"__ref":"Sequence:fxynfGCSHpY4FmBZy"},"collection":null,"nextPost":{"__ref":"Post:ZxR8P8hBFQ9kC8wMy"},"numRead":3,"numTotal":15,"lastReadTime":"2022-07-24T13:41:20.403Z"},{"__typename":"RecommendResumeSequence","sequence":{"__ref":"Sequence:pFatcKW3JJhTSxqAF"},"collection":null,"nextPost":{"__ref":"Post:HqQ3CpMqQyaaLLKew"},"numRead":8,"numTotal":46,"lastReadTime":"2022-12-17T20:57:36.372Z"},{"__typename":"RecommendResumeSequence","sequence":{"__ref":"Sequence:PKKsrXtuptWzaKCjr"},"collection":null,"nextPost":{"__ref":"Post:znfkdCoHMANwqc2WE"},"numRead":5,"numTotal":10,"lastReadTime":"2023-02-07T14:06:22.922Z"},{"__typename":"RecommendResumeSequence","sequence":{"__ref":"Sequence:onCRFFN7rGXTg3jyc"},"collection":null,"nextPost":{"__ref":"Post:9BqvY7tpqrD4BC6dL"},"numRead":3,"numTotal":7,"lastReadTime":"2023-02-08T10:51:34.711Z"},{"__typename":"RecommendResumeSequence","sequence":{"__ref":"Sequence:aek5ksSs2FHTeofsf"},"collection":null,"nextPost":{"__ref":"Post:oiftkZnFBqyHGALwv"},"numRead":4,"numTotal":6,"lastReadTime":"2023-02-08T11:29:29.328Z"},{"__typename":"RecommendResumeSequence","sequence":{"__ref":"Sequence:dT7CKGXwq9vt76CeX"},"collection":null,"nextPost":{"__ref":"Post:CsMQ7zsprBqWaeSvk"},"numRead":4,"numTotal":175,"lastReadTime":"2023-02-08T12:12:25.430Z"},{"__typename":"RecommendResumeSequence","sequence":{"__ref":"Sequence:HXkpm9b8o964jbQ89"},"collection":null,"nextPost":{"__ref":"Post:ENBzEkoyvdakz4w5d"},"numRead":4,"numTotal":15,"lastReadTime":"2023-02-09T12:16:34.090Z"}],"spotlights({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"limit\":1,\"view\":\"mostRecentlyPromotedSpotlights\"}}})":{"__typename":"MultiSpotlightOutput","results":[{"__ref":"Spotlight:arHKkuEjGdyfRnRoA"}],"totalCount":null},"user({\"input\":{\"selector\":{\"documentId\":\"P4zDcpuj7sXjWMSwh\"}}})":{"__typename":"SingleUserOutput","result":{"__ref":"User:P4zDcpuj7sXjWMSwh"}},"posts({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"globalEvent\":false,\"limit\":2,\"view\":\"events\"}}})":{"__typename":"MultiPostOutput","results":[{"__ref":"Post:fqha7yX28KyN7eK6v"},{"__ref":"Post:ixdDmjQs3akxNfvFJ"}],"totalCount":null},"RecentDiscussionFeed({\"af\":false,\"cutoff\":null,\"limit\":10,\"offset\":0})":{"__typename":"RecentDiscussionFeedQueryResults","cutoff":"2023-02-10T14:56:28.377Z","endOffset":10,"results":[{"__typename":"RecentDiscussionFeedEntryType","type":"postCommented","postCommented":{"__ref":"Post:zhhYwM7gk8LZsDzxj"},"tagDiscussed":null,"tagSubforumComments":null,"tagRevised":null},{"__typename":"RecentDiscussionFeedEntryType","type":"postCommented","postCommented":{"__ref":"Post:Fu7bqAyCMjfcMzBah"},"tagDiscussed":null,"tagSubforumComments":null,"tagRevised":null},{"__typename":"RecentDiscussionFeedEntryType","type":"postCommented","postCommented":{"__ref":"Post:uMQ3cqWDPHhjtiesc"},"tagDiscussed":null,"tagSubforumComments":null,"tagRevised":null},{"__typename":"RecentDiscussionFeedEntryType","type":"postCommented","postCommented":{"__ref":"Post:2ew4NFZovxCLsvHKS"},"tagDiscussed":null,"tagSubforumComments":null,"tagRevised":null},{"__typename":"RecentDiscussionFeedEntryType","type":"postCommented","postCommented":{"__ref":"Post:bxt7uCiHam4QXrQAA"},"tagDiscussed":null,"tagSubforumComments":null,"tagRevised":null},{"__typename":"RecentDiscussionFeedEntryType","type":"postCommented","postCommented":{"__ref":"Post:LAxAmooK4uDfWmbep"},"tagDiscussed":null,"tagSubforumComments":null,"tagRevised":null},{"__typename":"RecentDiscussionFeedEntryType","type":"subscribeReminder","postCommented":null,"tagDiscussed":null,"tagSubforumComments":null,"tagRevised":null},{"__typename":"RecentDiscussionFeedEntryType","type":"postCommented","postCommented":{"__ref":"Post:eywpzHRgXTCCAi8yt"},"tagDiscussed":null,"tagSubforumComments":null,"tagRevised":null},{"__typename":"RecentDiscussionFeedEntryType","type":"postCommented","postCommented":{"__ref":"Post:3xx9fpaJk6NfRhn7D"},"tagDiscussed":null,"tagSubforumComments":null,"tagRevised":null},{"__typename":"RecentDiscussionFeedEntryType","type":"postCommented","postCommented":{"__ref":"Post:rSiybWzeiG8agYtNr"},"tagDiscussed":null,"tagSubforumComments":null,"tagRevised":null}]},"posts({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"after\":\"2022-11-12\",\"filterSettings\":{\"personalBlog\":0,\"tags\":[{\"filterMode\":10,\"tagId\":\"Ng8Gice9KNkncxqcj\",\"tagName\":\"Rationality\"},{\"filterMode\":-25,\"tagId\":\"sYm3HiWcfZvrGu3ui\",\"tagName\":\"AI\"},{\"filterMode\":10,\"tagId\":\"3uE2pXvbcnS9nnZRE\",\"tagName\":\"World Modeling\"},{\"filterMode\":25,\"tagId\":\"xexCWMyds6QLWognu\",\"tagName\":\"World Optimization\"},{\"filterMode\":25,\"tagId\":\"fkABsGCJZ6y9qConW\",\"tagName\":\"Practical\"},{\"filterMode\":\"Default\",\"tagId\":\"izp6eeJJEg9v5zcur\",\"tagName\":\"Community\"},{\"filterMode\":25,\"tagId\":\"dqx5k65wjFfaiJ9sQ\",\"tagName\":\"Procrastination\"},{\"filterMode\":25,\"tagId\":\"udPbn9RthmgTtHMiG\",\"tagName\":\"Productivity\"},{\"filterMode\":-25,\"tagId\":\"tNsqhzTibgGJKPEWB\",\"tagName\":\"Coronavirus\"},{\"filterMode\":25,\"tagId\":\"sSNtcEQsqHgN8ZmRF\",\"tagName\":\"Fun Theory\"},{\"filterMode\":25,\"tagId\":\"irYLXtT9hkPXoZqhH\",\"tagName\":\"Growth Stories\"},{\"filterMode\":25,\"tagId\":\"AodfCFefLAuwDyj7Z\",\"tagName\":\"Self Experimentation\"},{\"filterMode\":25,\"tagId\":\"WqLn4pAWi5hn6McHQ\",\"tagName\":\"Self Improvement\"}]},\"forum\":true,\"limit\":13,\"view\":\"magic\"}}})":{"__typename":"MultiPostOutput","results":[{"__ref":"Post:BPRHZFH2xx7nz5TYT"},{"__ref":"Post:bxt7uCiHam4QXrQAA"},{"__ref":"Post:hfkjegoMZ8j8KGyiR"},{"__ref":"Post:aPeJE8bSo6rAFoLqg"},{"__ref":"Post:woCPxs8GxE7H35zzK"},{"__ref":"Post:3xx9fpaJk6NfRhn7D"},{"__ref":"Post:Fu7bqAyCMjfcMzBah"},{"__ref":"Post:gjxKuoMyRWh6Mxvke"},{"__ref":"Post:Qrg5tRBZvdABEJfDP"},{"__ref":"Post:LAxAmooK4uDfWmbep"},{"__ref":"Post:CYN7swrefEss4e3Qe"},{"__ref":"Post:gp9pmgSX3BXnhv8pJ"},{"__ref":"Post:YKfNZAmiLdepDngwi"}],"totalCount":null},"Recommendations({\"algorithm\":{\"count\":3,\"curatedModifier\":50,\"frontpageModifier\":10,\"hideBookmarks\":true,\"hideContinueReading\":true,\"includeMeta\":false,\"includePersonal\":true,\"lwRationalityOnly\":true,\"method\":\"sample\",\"onlyUnread\":true,\"personalBlogpostModifier\":0,\"scoreExponent\":3,\"scoreOffset\":0},\"count\":3})":[{"__ref":"Post:CoZhXrhpQxpy9xw9y"},{"__ref":"Post:LgavAYtzFQZKg95WC"},{"__ref":"Post:dLbkrPu5STNCBLRjr"}],"post({\"input\":{\"selector\":{\"documentId\":\"zhhYwM7gk8LZsDzxj\"}}})":{"__typename":"SinglePostOutput","result":{"__ref":"Post:zhhYwM7gk8LZsDzxj"}},"tagRels({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"limit\":100,\"postId\":\"zhhYwM7gk8LZsDzxj\",\"view\":\"tagsOnPost\"}}})":{"__typename":"MultiTagRelOutput","results":[],"totalCount":null},"tagRels({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"limit\":100,\"postId\":\"3xx9fpaJk6NfRhn7D\",\"view\":\"tagsOnPost\"}}})":{"__typename":"MultiTagRelOutput","results":[],"totalCount":null},"tagRels({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"limit\":100,\"postId\":\"uMQ3cqWDPHhjtiesc\",\"view\":\"tagsOnPost\"}}})":{"__typename":"MultiTagRelOutput","results":[{"__ref":"TagRel:S4usZxE98xXRoyE6A"},{"__ref":"TagRel:yiEmwuAf2spF2dJ7E"},{"__ref":"TagRel:YMcE9gYDb6FgL5dZS"}],"totalCount":null},"tagRels({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"limit\":100,\"postId\":\"2ew4NFZovxCLsvHKS\",\"view\":\"tagsOnPost\"}}})":{"__typename":"MultiTagRelOutput","results":[{"__ref":"TagRel:z5EgToBnshBYnGKgy"},{"__ref":"TagRel:ja7PhYfzjJ25CeeCC"},{"__ref":"TagRel:EYW2THTR66JtHdGKu"},{"__ref":"TagRel:PHRdJtusNikm9bwnB"}],"totalCount":null},"tagRels({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"limit\":100,\"postId\":\"rSiybWzeiG8agYtNr\",\"view\":\"tagsOnPost\"}}})":{"__typename":"MultiTagRelOutput","results":[{"__ref":"TagRel:5yKizuAKnzY8ewcvH"},{"__ref":"TagRel:dfbT6X5dTciA6Yrrf"},{"__ref":"TagRel:Rkck9jWMhvnLJim5z"}],"totalCount":null},"tagRels({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"limit\":100,\"postId\":\"Fu7bqAyCMjfcMzBah\",\"view\":\"tagsOnPost\"}}})":{"__typename":"MultiTagRelOutput","results":[{"__ref":"TagRel:TBSyZ7Y5TjJ57XKzP"},{"__ref":"TagRel:EyqQzRtnku7FDFnY2"},{"__ref":"TagRel:zJxPJrB8hjSm6PE98"},{"__ref":"TagRel:5obBsNirfvuLGGEJH"}],"totalCount":null},"tagRels({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"limit\":100,\"postId\":\"eywpzHRgXTCCAi8yt\",\"view\":\"tagsOnPost\"}}})":{"__typename":"MultiTagRelOutput","results":[{"__ref":"TagRel:Xd9BGmoaQ9YjkCizY"},{"__ref":"TagRel:i5srWBBcQkp3Mrpfa"}],"totalCount":null},"tagRels({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"limit\":100,\"postId\":\"bxt7uCiHam4QXrQAA\",\"view\":\"tagsOnPost\"}}})":{"__typename":"MultiTagRelOutput","results":[{"__ref":"TagRel:3uvJq34vchRzGTFZM"},{"__ref":"TagRel:kbkvvJiSPHQEzC53q"},{"__ref":"TagRel:DAbNaZMMvF4S5DHxq"},{"__ref":"TagRel:AkStND2Lqo746Gq4y"},{"__ref":"TagRel:3EPN9MjayeyJk6J39"},{"__ref":"TagRel:q8x3GnZa7hhNSBxC3"}],"totalCount":null},"tagRels({\"input\":{\"enableCache\":false,\"enableTotal\":false,\"terms\":{\"limit\":100,\"postId\":\"LAxAmooK4uDfWmbep\",\"view\":\"tagsOnPost\"}}})":{"__typename":"MultiTagRelOutput","results":[{"__ref":"TagRel:kJjffNLFi5kE45cix"},{"__ref":"TagRel:AsibzeHrCziB9byK2"},{"__ref":"TagRel:XbSDKNPwJnmjDcA3q"},{"__ref":"TagRel:shJtdt7mwe9qDzoJN"}],"totalCount":null},"getCrosspost({\"args\":{\"collectionName\":\"Posts\",\"documentId\":\"XLDfRTa6JbfCLXNTd\",\"fragmentName\":\"PostsList\"}})":{"__typename":"Post","deletedDraft":false,"contents":null,"fmCrosspost":{"hostedHere":false,"isCrosspost":true,"foreignPostId":"rSiybWzeiG8agYtNr"},"readTimeMinutes":1,"moderationGuidelines":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__typename":"Tag","parentTag":{"__typename":"Tag","_id":"oNiQsBHA3i837sySD","userId":"BkbwT5TzSj4aRxJMN","name":"AI safety","shortName":null,"slug":"ai-safety","core":true,"postCount":367,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-12-22T15:44:26.344Z","wikiOnly":false,"deleted":false,"isSubforum":true},"subTags":[],"description":{"__typename":"Revision","_id":"2bKZFw8Q5MCg9K95R_description","htmlHighlight":"<p>An <strong>AI risk<\/strong> is a<a href=\"https://forum.effectivealtruism.org/topics/global-catastrophic-risk\"> <u>catastrophic<\/u><\/a> or<a href=\"https://forum.effectivealtruism.org/topics/existential-risk\"> <u>existential<\/u><\/a> risk arising from the creation of advanced<a href=\"https://forum.effectivealtruism.org/topics/artificial-intelligence\"> <u>artificial intelligence<\/u><\/a> (AI).<\/p><p>Developments in AI have the potential to enable people around the world to flourish in hitherto unimagined ways. Such developments might also give humanity tools to address other sources of risk.<\/p><p>Despite this, AI also poses its own risks. AI systems sometimes behave in ways that surprise people. At the moment, such systems are usually narrow in their capabilities - for example, they are excellent at Go, or at minimizing power consumption in a server facility, but they cant do other tasks. If people designed a machine intelligence that was a sufficiently good general reasoner, or even<a href=\"https://forum.effectivealtruism.org/topics/superintelligence\"> <u>better at general reasoning than people are<\/u><\/a>, it might become difficult for human agents to interfere with its functioning. If it then behaved in a way which did not reflect human values, it might pose a real risk to humanity. Such a machine intelligence might use its intellectual superiority to develop a decisive strategic advantage. If its goals were incompatible with human flourishing, it could then pose an<a href=\"https://forum.effectivealtruism.org/topics/existential-risk\"> <u>existential risk<\/u><\/a>.<\/p><p>Note that AI could pose an existential risk without being sentient, gaining consciousness, or having any ill will towards humanity.&nbsp;<\/p><h2>Further reading<\/h2><p>Bostrom, Nick (2014) <a href=\"https://en.wikipedia.org/wiki/Special:BookSources/9780199678112\"><i>Superintelligence: Paths, Dangers, Strategies<\/i><\/a>, Oxford: Oxford University Press.<br><i>Offers a detailed analysis of risks posed by&nbsp;AI.<\/i><\/p><p>Christiano, Paul (2019) <a href=\"https://www.alignmentforum.org/posts/HBxe6wdjxK239zajf/what-failure-looks-like\">What failure looks like<\/a>, <i>LessWrong<\/i>, March 17.<\/p><p>Dewey, Daniel (2015) <a href=\"http://globalprioritiesproject.org/2015/10/three-areas-of-research-on-the-superintelligence-control-problem/\">Three areas of research on the superintelligence control problem<\/a>, <i>Global Priorities Project<\/i>, October 20.<br><i>Provides an overview and suggested reading in AI&nbsp;risk.<\/i><\/p><p>Karnofsky, Holden (2016) <a href=\"http://www.openphilanthropy.org/blog/potential-risks-advanced-artificial-intelligence-philanthropic-opportunity\">Potential risks from advanced artificial intelligence: the philanthropic opportunity<\/a>, <i>Open Philanthropy<\/i>, May 6.<br><i>Explains why the Open Philanthropy Project regards risks from AI as an area worth&nbsp;exploring.<\/i><\/p><p>Dai, Wei &amp; Daniel Kokotajlo (2019) <a href=\"https://www.alignmentforum.org/posts/WXvt8bxYnwBYpy9oT/the-main-sources-of-ai-risk\">The main sources of AI risk?<\/a>, <i>AI Alignment Forum<\/i>, March 21.<br><i>An attempt to list all the significant sources of AI risk.<\/i><\/p><h2>Related entries<\/h2><p><a href=\"https://forum.effectivealtruism.org/topics/ai-alignment\">AI alignment<\/a> | <a href=\"https://forum.effectivealtruism.org/topics/ai-governance\">AI governance<\/a> | <a href=\"https://forum.effectivealtruism.org/topics/ai-forecasting\">AI forecasting<\/a> |&nbsp;<a href=\"https://forum.effectivealtruism.org/tag/ai-safety\">AI safety<\/a> | <a href=\"https://forum.effectivealtruism.org/topics/instrumental-convergence-thesis\">instrumental convergence thesis<\/a> | <a href=\"https://forum.effectivealtruism.org/topics/instrumental-convergence-thesis\">orthogonality thesis<\/a><\/p>"},"_id":"2bKZFw8Q5MCg9K95R","userId":"jd3Bs7YAT2KqnLxYD","name":"AI risk","shortName":null,"slug":"ai-risk","core":false,"postCount":784,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-12-15T10:48:37.331Z","wikiOnly":false,"deleted":false,"isSubforum":null},{"__typename":"Tag","parentTag":{"__typename":"Tag","_id":"oNiQsBHA3i837sySD","userId":"BkbwT5TzSj4aRxJMN","name":"AI safety","shortName":null,"slug":"ai-safety","core":true,"postCount":367,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-12-22T15:44:26.344Z","wikiOnly":false,"deleted":false,"isSubforum":true},"subTags":[],"description":{"__typename":"Revision","_id":"9GQf4Ec6ckqvnPBSw_description","htmlHighlight":"<p><strong>AI alignment<\/strong> is research on how to align <a href=\"https://forum.effectivealtruism.org/topics/artificial-intelligence\">AI systems<\/a> with human or moral goals.<\/p><h2>Evaluation<\/h2><p><a href=\"https://forum.effectivealtruism.org/tag/80-000-hours\">80,000 Hours<\/a> rates AI alignment a \"highest priority area\": a problem at the top of their ranking of global issues assessed by <a href=\"https://forum.effectivealtruism.org/tag/itn-framework-1\">importance, tractability and neglectedness<\/a>.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreforjzl17i9vi\"><sup><a href=\"#fnorjzl17i9vi\">[1]<\/a><\/sup><\/span><\/p><h2>Further reading<\/h2><p>Christiano, Paul (2020) <a href=\"https://forum.effectivealtruism.org/posts/63stBTw3WAW6k45dY/paul-christiano-current-work-in-ai-alignment\">Current work in AI alignment<\/a>, <i>Effective Altruism Forum<\/i>, April 3.<\/p><p>Shah, Rohin (2020) <a href=\"https://forum.effectivealtruism.org/posts/nqTdRNngCGDD54owu/rohin-shah-what-s-been-happening-in-ai-alignment\">Whats been happening in AI alignment?<\/a>, <i>Effective Altruism Forum<\/i>, July 29.<\/p><h2>External links<\/h2><p><a href=\"https://alignmentforum.org/\">AI Alignment Forum<\/a>.<\/p><h2>Related entries<\/h2><p><a href=\"https://forum.effectivealtruism.org/topics/ai-governance\">AI governance<\/a> |&nbsp;<a href=\"https://forum.effectivealtruism.org/tag/ai-forecasting\">AI forecasting<\/a> | <a href=\"https://forum.effectivealtruism.org/tag/alignment-tax\">alignment tax<\/a> | <a href=\"https://forum.effectivealtruism.org/tag/center-for-human-compatible-artificial-intelligence\">Center for Human-Compatible Artificial Intelligence<\/a> | <a href=\"/tag/machine-intelligence-research-institute\">Machine Intelligence Research Institute<\/a> | <a href=\"https://forum.effectivealtruism.org/tag/rationality-community\">rationality community<\/a><\/p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnorjzl17i9vi\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnreforjzl17i9vi\">^<\/a><\/strong><\/sup><\/span><div class=\"footnote-content\"><p>80,000 Hours (2021) <a href=\"https://80000hours.org/problem-profiles/\">Our current list of the most important world problems<\/a>, <i>80,000 Hours<\/i>.<\/p><\/div><\/li><\/ol>"},"_id":"9GQf4Ec6ckqvnPBSw","userId":"jd3Bs7YAT2KqnLxYD","name":"AI alignment","shortName":null,"slug":"ai-alignment","core":false,"postCount":527,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":null,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-07-27T09:27:06.969Z","wikiOnly":false,"deleted":false,"isSubforum":null},{"__typename":"Tag","parentTag":null,"subTags":[{"__typename":"Tag","_id":"9GQf4Ec6ckqvnPBSw","userId":"jd3Bs7YAT2KqnLxYD","name":"AI alignment","shortName":null,"slug":"ai-alignment","core":false,"postCount":527,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":null,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-07-27T09:27:06.969Z","wikiOnly":false,"deleted":false,"isSubforum":null},{"__typename":"Tag","_id":"AtDxSNDDXPRa5kxjB","userId":"BkbwT5TzSj4aRxJMN","name":"Artificial intelligence","shortName":null,"slug":"artificial-intelligence","core":false,"postCount":139,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-12-22T13:29:29.121Z","wikiOnly":false,"deleted":false,"isSubforum":null},{"__typename":"Tag","_id":"2bKZFw8Q5MCg9K95R","userId":"jd3Bs7YAT2KqnLxYD","name":"AI risk","shortName":null,"slug":"ai-risk","core":false,"postCount":784,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-12-15T10:48:37.331Z","wikiOnly":false,"deleted":false,"isSubforum":null},{"__typename":"Tag","_id":"u3Xg8MjDe2e6BvKtv","userId":"tKxXWdBF6mbkSpEFx","name":"AI governance","shortName":null,"slug":"ai-governance","core":false,"postCount":333,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":null,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-07-21T03:16:46.017Z","wikiOnly":false,"deleted":false,"isSubforum":null},{"__typename":"Tag","_id":"yHnvv76eTfC4WT9F3","userId":"jd3Bs7YAT2KqnLxYD","name":"AI takeoff","shortName":null,"slug":"ai-takeoff","core":false,"postCount":19,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-12-15T12:01:14.263Z","wikiOnly":false,"deleted":false,"isSubforum":null},{"__typename":"Tag","_id":"kZv56672Gyj7J4Gra","userId":"jd3Bs7YAT2KqnLxYD","name":"Ethics of artificial intelligence","shortName":null,"slug":"ethics-of-artificial-intelligence","core":false,"postCount":22,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-12-15T10:44:15.790Z","wikiOnly":false,"deleted":false,"isSubforum":null},{"__typename":"Tag","_id":"MsZJrnxnoG7QRnhYe","userId":"BkbwT5TzSj4aRxJMN","name":"Orthogonality thesis","shortName":null,"slug":"orthogonality-thesis","core":false,"postCount":4,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2021-01-22T14:01:56.999Z","wikiOnly":false,"deleted":false,"isSubforum":null},{"__typename":"Tag","_id":"ct6dCPfJK9jkJnyAc","userId":"3xoyhbYRgcH8FxyFN","name":"Building the field of AI safety","shortName":null,"slug":"building-the-field-of-ai-safety","core":false,"postCount":50,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":true,"descriptionTruncationCount":0,"createdAt":"2022-07-28T21:03:21.049Z","wikiOnly":false,"deleted":false,"isSubforum":null}],"description":{"__typename":"Revision","_id":"oNiQsBHA3i837sySD_description","htmlHighlight":"<p><strong>AI safety<\/strong> is the study of ways to reduce risks posed by <a href=\"https://forum.effectivealtruism.org/tag/artificial-intelligence\">artificial intelligence<\/a>.<\/p><h2>AI safety as a career<\/h2><p><a href=\"https://forum.effectivealtruism.org/tag/80-000-hours\">80,000 Hours<\/a>' medium-depth investigation rates technical AI safety research a \"priority path\"among the most promising career opportunities the organization has identified so far.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefoy0q6nfb1j\"><sup><a href=\"#fnoy0q6nfb1j\">[1]<\/a><\/sup><\/span><span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefle8osyeymtm\"><sup><a href=\"#fnle8osyeymtm\">[2]<\/a><\/sup><\/span><\/p><h2>Further reading<\/h2><p>Gates, Vael (2022) <a href=\"https://forum.effectivealtruism.org/posts/8sAzgNcssH3mdb8ya/resources-i-send-to-ai-researchers-about-ai-safety\">Resources I send to AI researchers about AI safety<\/a>, <i>Effective Altruism Forum<\/i>, June 13.<\/p><p>Krakovna, Victoria (2017) <a href=\"https://vkrakovna.wordpress.com/2016/02/28/introductory-resources-on-ai-safety-research/\">Introductory resources on AI safety research<\/a>, <i>Victoria Krakovna's Blog<\/i>, October 19.<br><i>A list of readings on AI&nbsp;safety.<\/i><\/p><p>Ngo, Richard (2019) <a href=\"https://forum.effectivealtruism.org/posts/LprnaEj3uhkmYtmat/disentangling-arguments-for-the-importance-of-ai-safety\">Disentangling arguments for the importance of AI safety<\/a>, <i>Effective Altruism Forum<\/i>, January 21.<\/p><h2>Related entries<\/h2><p><a href=\"https://forum.effectivealtruism.org/tag/ai-alignment\">AI alignment<\/a> | <a href=\"https://forum.effectivealtruism.org/topics/ai-interpretability\">AI interpretability<\/a> |&nbsp;<a href=\"https://forum.effectivealtruism.org/tag/ai-risk\">AI risk<\/a> | <a href=\"https://forum.effectivealtruism.org/topics/cooperative-ai-1\">cooperative AI<\/a> | <a href=\"https://forum.effectivealtruism.org/topics/building-the-field-of-ai-safety\">building the field of AI safety<\/a><\/p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnoy0q6nfb1j\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefoy0q6nfb1j\">^<\/a><\/strong><\/sup><\/span><div class=\"footnote-content\"><p>Todd, Benjamin (2018) <a href=\"https://80000hours.org/articles/high-impact-careers/\">The highest impact career paths our research has identified so far<\/a>, <i>80,000 Hours<\/i>, August 12.<\/p><\/div><\/li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnle8osyeymtm\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefle8osyeymtm\">^<\/a><\/strong><\/sup><\/span><div class=\"footnote-content\"><p>Todd, Benjamin (2021) <a href=\"https://80000hours.org/career-reviews/ai-safety-researcher/\">AI safety technical research<\/a>, <i>80,000 Hours<\/i>, October.<\/p><\/div><\/li><\/ol>"},"_id":"oNiQsBHA3i837sySD","userId":"BkbwT5TzSj4aRxJMN","name":"AI safety","shortName":null,"slug":"ai-safety","core":true,"postCount":367,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-12-22T15:44:26.344Z","wikiOnly":false,"deleted":false,"isSubforum":true},{"__typename":"Tag","parentTag":null,"subTags":[],"description":{"__typename":"Revision","_id":"ynkTF7xXRoBRBqJrX_description","htmlHighlight":"<p>The <strong>effective altruism art and fiction<\/strong> tag covers artistic depictions of EA-related topics and discussion of the role of art and fiction within the EA movement.<\/p><h2>Further reading<\/h2><p>Wiblin, Robert (2015) <a href=\"https://80000hours.org/career-reviews/pursuing-fame-in-art-and-entertainment/\">Pursuing fame in art and entertainment<\/a>, <i>80,000 Hours<\/i>, July.<\/p><h2>Related entries<\/h2><p><a href=\"https://forum.effectivealtruism.org/tag/effective-altruism-in-the-media\">effective altruism in the media<\/a> | <a href=\"https://forum.effectivealtruism.org/tag/effective-altruism-messaging/\">effective altruism messaging<\/a> |&nbsp;<a href=\"https://forum.effectivealtruism.org/tag/existential-risk-fiction\">existential risk fiction<\/a><\/p>"},"_id":"ynkTF7xXRoBRBqJrX","userId":"jd3Bs7YAT2KqnLxYD","name":"Effective altruism art and fiction","shortName":null,"slug":"effective-altruism-art-and-fiction","core":false,"postCount":225,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":null,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-07-01T07:59:12.435Z","wikiOnly":false,"deleted":false,"isSubforum":null}],"url":null,"postedAt":"2023-01-12T09:37:21.808Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2023-01-12T10:39:40.280Z","meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"commentCount":null,"voteCount":13,"baseScore":21,"extendedScore":null,"unlisted":false,"score":0.026406286284327507,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2023-01-12T09:37:21.808Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"NLAXyDHNib4DFLWes","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"WaLYFSFfA3nXGcYG5","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":0,"afExtendedScore":null,"afCommentCount":null,"afLastCommentedAt":"2023-01-12T09:37:21.810Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"reviewCount":null,"reviewVoteCount":null,"positiveReviewVoteCount":null,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"user":{"__typename":"User","biography":null,"profileImageId":null,"moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":null,"_id":"NLAXyDHNib4DFLWes","slug":"karl-von-wendt-1","createdAt":"2022-06-02T04:31:42.773Z","username":"Karl von Wendt","displayName":"Karl von Wendt","previousDisplayName":null,"fullName":null,"karma":98,"afKarma":0,"deleted":null,"isAdmin":false,"htmlBio":"","postCount":4,"commentCount":8,"sequenceCount":0,"afPostCount":null,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":null},"coauthors":[],"_id":"XLDfRTa6JbfCLXNTd","slug":"virtua-a-novel-about-ai-alignment","title":"VIRTUA: a novel about AI alignment","draft":null,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null}},"Revision:Ng8Gice9KNkncxqcj_description":{"_id":"Ng8Gice9KNkncxqcj_description","__typename":"Revision","htmlHighlight":"<p><strong>Rationality<\/strong> is the art of thinking in ways that result in <a href=\"https://www.lesswrong.com/tag/world-modeling\">accurate beliefs<\/a> and <a href=\"https://www.lesswrong.com/tag/decision-theory\">good decisions<\/a>. It is the primary topic of LessWrong.<br><br>Rationality is not only about avoiding the vices of <a href=\"https://www.lesswrong.com/tag/self-deception\">self-deception<\/a> and obfuscation (the failure to <a href=\"https://www.lesswrong.com/tag/conversation-topic\">communicate clearly<\/a>), but also about the virtue of <a href=\"https://www.lesswrong.com/tag/curiosity\">curiosity<\/a>, seeing the world more clearly than before, and <a href=\"https://www.lesswrong.com/tag/ambition\">achieving things<\/a> <a href=\"https://www.lesswrong.com/tag/skill-building\">previously unreachable<\/a> <a href=\"https://www.lesswrong.com/tag/coordination-cooperation\">to you<\/a>. The study of rationality on LessWrong includes a theoretical understanding of ideal cognitive algorithms, as well as building a practice that uses these idealized algorithms to inform <a href=\"https://www.lesswrong.com/tag/heuristics-and-biases\">heuristics<\/a>, <a href=\"https://www.lesswrong.com/tag/habits\">habits<\/a>, and <a href=\"https://www.lesswrong.com/tag/techniques\">techniques<\/a>, to successfully reason and make decisions in the real world.<\/p><p>Topics covered in rationality include (but are not limited to): normative and theoretical explorations of <a href=\"https://www.lesswrong.com/tag/solomonoff-induction\">ideal<\/a> <a href=\"https://www.lesswrong.com/tag/probability-and-statistics\">reasoning<\/a>; the <a href=\"https://www.lesswrong.com/tag/evolutionary-psychology\">capabilities and limitations<\/a> <a href=\"https://www.lesswrong.com/tag/neuroscience\">of our brain<\/a>, <a href=\"https://www.lesswrong.com/tag/dual-process-theory-system-1-and-system-2\">mind and psychology<\/a>; applied advice such as <a href=\"https://www.lesswrong.com/tag/introspection\">introspection<\/a> techniques and <a href=\"https://www.lesswrong.com/tag/group-rationality\">how to achieve truth collaboratively<\/a>; practical techniques and methodologies for figuring out whats true ranging from rough quantitative modeling to full research guides.<\/p><p>Note that content about <i>how the world is <\/i>can be found under <a href=\"https://www.lesswrong.com/tag/world-modeling\">World Modeling<\/a>, and practical advice about <i>how to change the world<\/i> is categorized under <a href=\"https://www.lesswrong.com/tag/world-optimization\">World Optimization<\/a> or <a href=\"/tag/practical\">Practical<\/a>.<\/p><hr><figure class=\"table\" style=\"width:100%\"><table style=\"background-color:rgb(255, 255, 255);border:20px solid hsl(0, 0%, 100%)\"><tbody><tr><td style=\"border:1px solid hsl(0, 0%, 100%);padding:0px;vertical-align:top;width:33.33%\"><p><strong>Theory / Concepts<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/anticipated-experiences?showPostCount=true&amp;useTagName=true\"><u>Anticipated Experiences<\/u><\/a><br><a href=\"http://www.lesswrong.com/tag/aumann-s-agreement-theorem?showPostCount=true&amp;useTagName=true\">Aumann's Agreement Theorem<\/a><br><a href=\"http://www.lesswrong.com/tag/bayes-theorem?showPostCount=true&amp;useTagName=true\"><u>Bayes Theorem<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/bounded-rationality?showPostCount=true&amp;useTagName=true\">Bounded Rationality<\/a><br><a href=\"https://www.lesswrong.com/tag/conservation-of-expected-evidence?showPostCount=true&amp;useTagName=true\">Conservation of Expected<\/a><br><a href=\"http://www.lesswrong.com/tag/contrarianism?showPostCount=true&amp;useTagName=true\">Contrarianism<\/a><br><a href=\"https://www.lesswrong.com/tag/decision-theory?showPostCount=true&amp;useTagName=true\">Decision Theory<\/a><br><a href=\"http://www.lesswrong.com/tag/epistemology?showPostCount=true&amp;useTagName=true\"><u>Epistemology<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/game-theory?showPostCount=true&amp;useTagName=true\">Game Theory<\/a><br><a href=\"https://www.lesswrong.com/tag/gears-level?showPostCount=true&amp;useTagName=true\"><u>Gears-Level<\/u><\/a><br><a href=\"http://www.lesswrong.com/tag/hansonian-pre-rationality?useTagName=true&amp;showPostCount=true\">Hansonian Pre-Rationality<\/a><br><a href=\"https://www.lesswrong.com/tag/law-thinking?showPostCount=true&amp;useTagName=true\">Law-Thinking<\/a><br><a href=\"http://www.lesswrong.com/tag/map-and-territory?showPostCount=true&amp;useTagName=true\">Map and Territory<\/a><br><a href=\"https://www.lesswrong.com/tag/newcomb-s-problem?showPostCount=true&amp;useTagName=true\">Newcomb's Problem<\/a><br><a href=\"http://www.lesswrong.com/tag/occam-s-razor?showPostCount=true&amp;useTagName=true\">Occam's razor<\/a><br><a href=\"https://www.lesswrong.com/tag/robust-agents?showPostCount=true&amp;useTagName=true\">Robust Agents<\/a><br><a href=\"https://www.lesswrong.com/tag/solomonoff-induction?showPostCount=true&amp;useTagName=true\">Solomonoff Induction<\/a><br><a href=\"http://www.lesswrong.com/tag/truth-semantics-and-meaning?showPostCount=true&amp;useTagName=true\">Truth, Semantics, &amp; Meaning<\/a><br><a href=\"https://www.lesswrong.com/tag/utility-functions?showPostCount=true&amp;useTagName=true\">Utility Functions<\/a><br>&nbsp;<\/p><\/td><td style=\"border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:33.33%\"><p><strong>Applied Topics<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/alief?showPostCount=true&amp;useTagName=true\"><u>Alief<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/betting?showPostCount=true&amp;useTagName=true\">Betting<\/a><br><a href=\"http://www.lesswrong.com/tag/cached-thoughts?showPostCount=true&amp;useTagName=true\">Cached Thoughts<\/a><br><a href=\"http://www.lesswrong.com/tag/calibration?showPostCount=true&amp;useTagName=true\">Calibration<\/a><br><a href=\"https://www.lesswrong.com/tag/dark-arts?showPostCount=true&amp;useTagName=true\">Dark Arts<\/a><br><a href=\"http://www.lesswrong.com/tag/empiricism?showPostCount=true&amp;useTagName=true\">Empiricism<\/a><br><a href=\"http://www.lesswrong.com/tag/epistemic-modesty?showPostCount=true&amp;useTagName=true\">Epistemic Modesty<\/a><br><a href=\"https://www.lesswrong.com/tag/forecasting-and-prediction?showPostCount=true&amp;useTagName=true\">Forecasting &amp; Prediction<\/a><br><a href=\"http://www.lesswrong.com/tag/group-rationality?showPostCount=true&amp;useTagName=true\">Group Rationality<\/a><br><a href=\"https://www.lesswrong.com/tag/identity?showPostCount=true&amp;useTagName=true\">Identity<\/a><br><a href=\"http://www.lesswrong.com/tag/inside-outside-view?showPostCount=true&amp;useTagName=true\">Inside/Outside View<\/a><br><a href=\"http://www.lesswrong.com/tag/introspection?showPostCount=true&amp;useTagName=true\"><u>Introspection<\/u><\/a><br><a href=\"http://www.lesswrong.com/tag/intuition?showPostCount=true&amp;useTagName=true\">Intuition<\/a><br><a href=\"https://www.lesswrong.com/tag/practice-and-philosophy-of-science?showPostCount=true&amp;useTagName=true\"><u>Practice &amp; Philosophy of Science<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/scholarship-and-learning?showPostCount=true&amp;useTagName=true\">Scholarship &amp; Learning<\/a><br><a href=\"http://www.lesswrong.com/tag/taking-ideas-seriously?showPostCount=true&amp;useTagName=true\">Taking Ideas Seriously<\/a><br><a href=\"https://www.lesswrong.com/tag/value-of-information?showPostCount=true&amp;useTagName=true\">Value of Information<\/a><br>&nbsp;<\/p><\/td><td style=\"border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:33.33%\"><p><strong>Failure Modes<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/affect-heuristic?showPostCount=true&amp;useTagName=true\">Affect Heuristic<\/a><br><a href=\"https://www.lesswrong.com/tag/bucket-errors?showPostCount=true&amp;useTagName=true\">Bucket Errors<\/a><br><a href=\"https://www.lesswrong.com/tag/compartmentalization?showPostCount=true&amp;useTagName=true\">Compartmentalization<\/a><br><a href=\"https://www.lesswrong.com/tag/confirmation-bias?showPostCount=true&amp;useTagName=true\"><u>Confirmation Bias<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/logical-fallacies?showPostCount=true&amp;useTagName=true\">Fallacies<\/a><br><a href=\"https://www.lesswrong.com/tag/goodhart-s-law?showPostCount=true&amp;useTagName=true\">Goodharts Law<\/a><br><a href=\"http://www.lesswrong.com/tag/groupthink?showPostCount=true&amp;useTagName=true\"><u>Groupthink<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/heuristics-and-biases?showPostCount=true&amp;useTagName=true\">Heuristics and Biases<\/a><br><a href=\"https://www.lesswrong.com/tag/mind-projection-fallacy?showPostCount=true&amp;useTagName=true\">Mind Projection Fallacy<\/a><br><a href=\"https://www.lesswrong.com/tag/motivated-reasoning?showPostCount=true&amp;useTagName=true\"><u>Motivated Reasoning<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/pica?showPostCount=true&amp;useTagName=true\">Pica<\/a><br><a href=\"https://www.lesswrong.com/tag/pitfalls-of-rationality?showPostCount=true&amp;useTagName=true\">Pitfalls of Rationality<\/a><br><a href=\"https://www.lesswrong.com/tag/rationalization?showPostCount=true&amp;useTagName=true\">Rationalization<\/a>&nbsp;<br><a href=\"https://www.lesswrong.com/tag/self-deception?showPostCount=true&amp;useTagName=true\">Self-Deception<\/a><br><a href=\"https://www.lesswrong.com/tag/sunk-cost-fallacy?showPostCount=true&amp;useTagName=true\">Sunk-Cost Fallacy<\/a><\/p><\/td><\/tr><tr><td style=\"border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top\" rowspan=\"2\"><p><strong>Communication<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/common-knowledge?showPostCount=true&amp;useTagName=true\"><u>Common Knowledge<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/conversation-topic?showPostCount=true\"><u>Conversation<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/decoupling-vs-contextualizing?showPostCount=true&amp;useTagName=true\"><u>Decoupling vs Contextualizing<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/disagreement?showPostCount=true&amp;useTagName=true\"><u>Disagreement<\/u><\/a><br><a href=\"http://www.lesswrong.com/tag/distillation-and-pedagogy?showPostCount=true&amp;useTagName=true\">Distillation &amp; Pedagogy<\/a><br><a href=\"http://www.lesswrong.com/tag/double-crux?showPostCount=true&amp;useTagName=true\"><u>Double-Crux<\/u><\/a><br><a href=\"http://www.lesswrong.com/tag/good-explanations-advice?showPostCount=true&amp;useTagName=true\">Good Explanations (Advice)<\/a><br><a href=\"http://www.lesswrong.com/tag/ideological-turing-tests?showPostCount=true&amp;useTagName=true\">Ideological Turing Tests<\/a><br><a href=\"https://www.lesswrong.com/tag/inferential-distance?showPostCount=true&amp;useTagName=true\">Inferential Distance<\/a><br><a href=\"https://www.lesswrong.com/tag/information-cascades?showPostCount=true&amp;useTagName=true\">Information Cascades<\/a><br><a href=\"https://www.lesswrong.com/tag/memetic-immune-system?showPostCount=true&amp;useTagName=true\">Memetic Immune System<\/a><br><a href=\"https://www.lesswrong.com/tag/philosophy-of-language?showPostCount=true&amp;useTagName=true\"><u>Philos<\/u><\/a><\/p><\/td><\/tr><\/tbody><\/table><\/figure>..."},"Tag:Ng8Gice9KNkncxqcj":{"_id":"Ng8Gice9KNkncxqcj","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:Ng8Gice9KNkncxqcj_description"},"userId":"r38pkCm7wF4M44MDQ","name":"Rationality","slug":"rationality","core":true,"postCount":2621,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":true,"needsReview":null,"descriptionTruncationCount":100,"createdAt":"2020-06-14T22:24:17.072Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:sYm3HiWcfZvrGu3ui_description":{"_id":"sYm3HiWcfZvrGu3ui_description","__typename":"Revision","htmlHighlight":"<p><strong>Artificial Intelligence<\/strong> is the study of creating intelligence in algorithms. <strong>AI Alignment <\/strong>is the task of ensuring [powerful] AI system are aligned with human values and interests. The central concern is that a powerful enough AI, if not designed and implemented with sufficient understanding, would optimize something unintended by its creators and pose an existential threat to the future of humanity. This is known as the <i>AI alignment<\/i> problem.<\/p><p>Common terms in this space are <i>superintelligence, AI Alignment, AI Safety, Friendly AI, Transformative AI, human-level-intelligence, AI Governance, and Beneficial AI. <\/i>This entry and the associated tag roughly encompass all of these topics: anything part of the broad cluster of understanding AI and its future impacts on our civilization deserves this tag.<\/p><p><strong>AI Alignment<\/strong><\/p><p>There are narrow conceptions of alignment, where youre trying to get it to do something like cure Alzheimers disease without destroying the rest of the world. And theres much more ambitious notions of alignment, where youre trying to get it to do the right thing and achieve a happy intergalactic civilization.<\/p><p>But both the narrow and the ambitious alignment have in common that youre trying to have the AI do that thing rather than making a lot of paperclips.<\/p><p>See also <a href=\"https://www.lesswrong.com/tag/general-intelligence\">General Intelligence<\/a>.<\/p><figure class=\"table\" style=\"width:100%\"><table style=\"background-color:rgb(255, 255, 255);border:20px solid hsl(0, 0%, 100%)\"><tbody><tr><td style=\"border:1px solid hsl(0, 0%, 100%);padding:0px;vertical-align:top;width:33.33%\" rowspan=\"2\"><p><strong>Basic Alignment Theory<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/aixi?showPostCount=true&amp;useTagName=true\">AIXI<\/a><br><a href=\"http://www.lesswrong.com/tag/coherent-extrapolated-volition?showPostCount=true&amp;useTagName=true\">Coherent Extrapolated Volition<\/a><br><a href=\"https://www.lesswrong.com/tag/complexity-of-value?showPostCount=true&amp;useTagName=true\">Complexity of Value<\/a><br><a href=\"https://www.lesswrong.com/tag/corrigibility?showPostCount=true&amp;useTagName=true\">Corrigibility<\/a><br><a href=\"https://www.lesswrong.com/tag/deceptive-alignment?showPostCount=true&amp;useTagName=true\">Deceptive Alignment<\/a><br><a href=\"https://www.lesswrong.com/tag/decision-theory?showPostCount=true&amp;useTagName=true\">Decision Theory<\/a><br><a href=\"https://www.lesswrong.com/tag/embedded-agency?showPostCount=true&amp;useTagName=true\">Embedded Agency<\/a><br><a href=\"https://www.lesswrong.com/tag/fixed-point-theorems?showPostCount=true&amp;useTagName=true\">Fixed Point Theorems<\/a><br><a href=\"https://www.lesswrong.com/tag/goodhart-s-law?showPostCount=true&amp;useTagName=true\">Goodhart's Law<\/a><br><a href=\"https://www.lesswrong.com/tag/goal-directedness?showPostCount=true&amp;useTagName=true\">Goal-Directedness<\/a><br><a href=\"https://www.lesswrong.com/tag/gradient-hacking?showPostCount=true&amp;useTagName=true\">Gradient Hacking<\/a><br><a href=\"http://www.lesswrong.com/tag/infra-bayesianism?showPostCount=true&amp;useTagName=true\">Infra-Bayesianism<\/a><br><a href=\"https://www.lesswrong.com/tag/inner-alignment?showPostCount=true&amp;useTagName=true\">Inner Alignment<\/a><br><a href=\"https://www.lesswrong.com/tag/instrumental-convergence?showPostCount=true&amp;useTagName=true\">Instrumental Convergence<\/a><br><a href=\"https://www.lesswrong.com/tag/intelligence-explosion?showPostCount=true&amp;useTagName=true\">Intelligence Explosion<\/a><br><a href=\"https://www.lesswrong.com/tag/logical-induction?showPostCount=true&amp;useTagName=true\">Logical Induction<\/a><br><a href=\"http://www.lesswrong.com/tag/logical-uncertainty?showPostCount=true&amp;useTagName=true\">Logical Uncertainty<\/a><br><a href=\"https://www.lesswrong.com/tag/mesa-optimization?showPostCount=true&amp;useTagName=true\">Mesa-Optimization<\/a><br><a href=\"https://www.lesswrong.com/tag/multipolar-scenarios?showPostCount=true&amp;useTagName=true\">Multipolar Scenarios<\/a><br><a href=\"https://www.lesswrong.com/tag/myopia?showPostCount=true&amp;useTagName=true\">Myopia<\/a><br><a href=\"https://www.lesswrong.com/tag/newcomb-s-problem?showPostCount=true&amp;useTagName=true\">Newcomb's Problem<\/a><br><a href=\"https://www.lesswrong.com/tag/optimization?showPostCount=true&amp;useTagName=true\">Optimization<\/a><br><a href=\"https://www.lesswrong.com/tag/orthogonality-thesis?showPostCount=true&amp;useTagName=true\">Orthogonality Thesis<\/a><br><a href=\"https://www.lesswrong.com/tag/outer-alignment?showPostCount=true&amp;useTagName=true\">Outer Alignment<\/a><br><a href=\"http://www.lesswrong.com/tag/paperclip-maximizer?showPostCount=true&amp;useTagName=true\">Paperclip Maximizer<\/a><br><a href=\"https://www.lesswrong.com/tag/power-seeking-ai?showPostCount=true&amp;useTagName=true\">Power Seeking (AI)<\/a><br><a href=\"https://www.lesswrong.com/tag/recursive-self-improvement?showPostCount=true&amp;useTagName=true\">Recursive Self-Improvement<\/a><br><a href=\"https://www.lesswrong.com/tag/simulator-theory\">Simulator Theory<\/a><br><a href=\"https://www.lesswrong.com/tag/sharp-left-turn?showPostCount=true&amp;useTagName=true\">Sharp Left Turn<\/a><br><a href=\"https://www.lesswrong.com/tag/solomonoff-induction?showPostCount=true&amp;useTagName=true\">Solomonoff Induction<\/a><br><a href=\"https://www.lesswrong.com/tag/superintelligence?showPostCount=true&amp;useTagName=true\">Superintelligence<\/a><br><a href=\"https://www.lesswrong.com/tag/symbol-grounding\">Symbol Grounding<\/a><br><a href=\"https://www.lesswrong.com/tag/transformative-ai?showPostCount=true&amp;useTagName=true\">Transformative AI<\/a><br><a href=\"https://www.lesswrong.com/tag/treacherous-turn?showPostCount=true&amp;useTagName=true\">Treacherous Turn<\/a><br><a href=\"https://www.lesswrong.com/tag/utility-functions?showPostCount=true&amp;useTagName=true\">Utility Functions<\/a><br><a href=\"https://www.lesswrong.com/tag/whole-brain-emulation?showPostCount=true&amp;useTagName=true\">Whole Brain Emulation<\/a><\/p><\/td><td style=\"border-color:hsl(0, 0%, 100%);border-style:solid;height:50%;padding:0px;vertical-align:top;width:33.33%\"><p><strong>Engineering Alignment<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/agent-foundations?showPostCount=true&amp;useTagName=true\">Agent Foundations<\/a><br><a href=\"https://www.lesswrong.com/tag/ai-assisted-alignment?showPostCount=true&amp;useTagName=true\">AI-assisted Alignment&nbsp;<\/a><br><a href=\"https://www.lesswrong.com/tag/ai-boxing-containment?showPostCount=true&amp;useTagName=true\">AI Boxing (Containment)<\/a><br><a href=\"https://www.lesswrong.com/tag/conservatism-ai?showPostCount=true&amp;useTagName=true\">Conservatism (AI)<\/a><br><a href=\"https://www.lesswrong.com/tag/ai-safety-via-debate?showPostCount=true&amp;useTagName=true\">Debate (AI safety technique)<\/a><br><a href=\"https://www.lesswrong.com/tag/eliciting-latent-knowledge-elk\">Eliciting Latent Knowledge (ELK)<\/a><br><a href=\"https://www.lesswrong.com/tag/factored-cognition?showPostCount=true&amp;useTagName=true\">Factored Cognition<\/a><br><a href=\"https://www.lesswrong.com/tag/hch?showPostCount=true&amp;useTagName=true\">Humans Consulting HCH<\/a><br><a href=\"https://www.lesswrong.com/tag/impact-measures?showPostCount=true&amp;useTagName=true\">Impact Measures<\/a><br><a href=\"https://www.lesswrong.com/tag/inverse-reinforcement-learning?showPostCount=true&amp;useTagName=true\">Inverse Reinforcement Learning<\/a><br><a href=\"https://www.lesswrong.com/tag/iterated-amplification?showPostCount=true&amp;useTagName=true\">Iterated Amplification<\/a><br><a href=\"http://www.lesswrong.com/tag/mild-optimization?showPostCount=true&amp;useTagName=true\">Mild Optimization<\/a><br><a href=\"https://www.lesswrong.com/tag/oracle-ai?showPostCount=true&amp;useTagName=true\">Oracle AI<\/a><br><a href=\"https://www.lesswrong.com/tag/reward-functions?showPostCount=true&amp;useTagName=true\">Reward Functions<\/a><br><a href=\"https://www.lesswrong.com/tag/rlhf?showPostCount=true&amp;useTagName=true\">RLHF<\/a><br><a href=\"https://www.lesswrong.com/tag/shard-theory?showPostCount=true&amp;useTagName=true\">Shard Theory<\/a><br><a href=\"http://www.lesswrong.com/tag/tool-ai?showPostCount=true&amp;useTagName=true\">Tool AI<\/a><br><a href=\"https://www.lesswrong.com/tag/transparency-interpretability-ml-and-ai?showPostCount=true\">Transparency / Interpretability<\/a><br><a href=\"https://www.lesswrong.com/tag/tripwire?showPostCount=true&amp;useTagName=true\">Tripwire<\/a><br><a href=\"https://www.lesswrong.com/tag/value-learning?showPostCount=true&amp;useTagName=true\">Value Learning<\/a><br>&nbsp;<\/p><\/td><td style=\"border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:33.33%\"><p><strong>Organizations<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/ai-safety-camp?showPostCount=true&amp;useTagName=true\">AI Safety Camp<\/a><br><a href=\"https://www.lesswrong.com/tag/alignment-research-center\">Alignment Research Center<\/a><br><a href=\"https://www.lesswrong.com/tag/anthropic?showPostCount=true&amp;useTagName=true\">Ant<\/a><\/p><\/td><\/tr><\/tbody><\/table><\/figure>..."},"Tag:sYm3HiWcfZvrGu3ui":{"_id":"sYm3HiWcfZvrGu3ui","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:sYm3HiWcfZvrGu3ui_description"},"userId":"r38pkCm7wF4M44MDQ","name":"AI","slug":"ai","core":true,"postCount":4617,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":true,"needsReview":null,"descriptionTruncationCount":2000,"createdAt":"2020-06-14T22:24:22.097Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:3uE2pXvbcnS9nnZRE_description":{"_id":"3uE2pXvbcnS9nnZRE_description","__typename":"Revision","htmlHighlight":"<p><strong>World Modeling<\/strong> is getting curious about how the world works. Its diving into wikipedia, its running a survey to get data from your friends, its dropping balls from different heights and measuring how long they take to fall. Empiricism, scholarship, googling, introspection, data-gathering, science. Applying your epistemology and curiosity, <i>finding out how the damn thing works,<\/i> and writing it down for the rest of us.<\/p><blockquote><p><i>The eleventh virtue is scholarship. Study many sciences and absorb their power as your own. Each field that you consume makes you larger. If you swallow enough sciences the gaps between them will diminish and your knowledge will become a unified whole. If you are gluttonous you will become vaster than mountains.<\/i><\/p><p><a href=\"https://www.lesswrong.com/posts/7ZqGiPHTpiDMwqMN2/the-twelve-virtues-of-rationality\"><u>Twelve Virtues of Rationality<\/u><\/a><\/p><\/blockquote><hr><h1><strong>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; World Modeling Sub-Topics<\/strong><\/h1><figure class=\"table\" style=\"width:100%\"><table style=\"border:20px solid hsl(0, 0%, 100%)\"><tbody><tr><td style=\"background-color:hsl(0,0%,100%);border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:33.33%\"><p><strong>Mathematical Sciences<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/abstraction?showPostCount=true&amp;useTagName=true\">Abstraction<\/a><br><a href=\"https://www.lesswrong.com/tag/anthropics?showPostCount=true&amp;useTagName=true\">Anthropics<\/a><br><a href=\"http://www.lesswrong.com/tag/category-theory?showPostCount=true&amp;useTagName=true\">Category Theory<\/a><br><a href=\"https://www.lesswrong.com/tag/causality?showPostCount=true&amp;useTagName=true\">Causality<\/a><br><a href=\"https://www.lesswrong.com/tag/game-theory?showPostCount=true&amp;useTagName=true\">Game Theory<\/a><br><a href=\"https://www.lesswrong.com/tag/decision-theory?showPostCount=true&amp;useTagName=true\">Decision Theory<\/a><br><a href=\"http://www.lesswrong.com/tag/information-theory?showPostCount=true&amp;useTagName=true\">Information Theory<\/a><br><a href=\"https://www.lesswrong.com/tag/logic-and-mathematics?showPostCount=true&amp;useTagName=true\">Logic &amp; Mathematics<\/a><br><a href=\"https://www.lesswrong.com/tag/probability-and-statistics?showPostCount=true&amp;useTagName=false\">Probability &amp; Statistics<\/a><\/p><p><i>Specifics<\/i><br><a href=\"http://www.lesswrong.com/tag/prisoner-s-dilemma?showPostCount=true&amp;useTagName=true\">Prisoner's Dilemma<\/a><br>&nbsp;<\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border-color:hsl(0, 0%, 100%);border-style:solid;height:50%;padding:0px;vertical-align:top;width:33.33%\"><p><strong>General Science &amp; Eng<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/machine-learning?showPostCount=true&amp;useTagName=true\">Machine Learning<\/a><br><a href=\"https://www.lesswrong.com/tag/nanotechnology?showPostCount=true&amp;useTagName=true\">Nanotechnology<\/a><br><a href=\"https://www.lesswrong.com/tag/physics?showPostCount=true&amp;useTagName=true\">Physics<\/a><br><a href=\"https://www.lesswrong.com/tag/programming?showPostCount=true&amp;useTagName=true\">Programming<\/a><br><a href=\"http://www.lesswrong.com/tag/space-exploration-and-colonization?showPostCount=true&amp;useTagName=true\">Space Exploration &amp; Colonization<\/a><\/p><p><i>Specifics<\/i><br><a href=\"https://www.lesswrong.com/tag/great-filter?showPostCount=true&amp;useTagName=true\">The Great Filter<\/a><\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:33.33%\"><p><strong>Meta / Misc<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/academic-papers?showPostCount=true&amp;useTagName=true\">Academic Papers<\/a><br><a href=\"https://www.lesswrong.com/tag/book-reviews?showPostCount=true&amp;useTagName=true\">Book Reviews<\/a><br><a href=\"http://www.lesswrong.com/tag/distillation-and-pedagogy?showPostCount=true&amp;useTagName=true\">Distillation &amp; Pedagogy<\/a><br><a href=\"https://www.lesswrong.com/tag/fact-posts?showPostCount=true&amp;useTagName=true\">Fact Posts<\/a><br><a href=\"https://www.lesswrong.com/tag/research-agendas?showPostCount=true&amp;useTagName=true\">Research Agendas<\/a><br><a href=\"https://www.lesswrong.com/tag/scholarship-and-learning?showPostCount=true&amp;useTagName=true\">Scholarship &amp; Learning<\/a><\/p><\/td><\/tr><tr><td style=\"background-color:hsl(0,0%,100%);border:1px solid hsl(0, 0%, 100%);padding:0px;vertical-align:top\"><p><strong>Social &amp; Economic<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/economics?showPostCount=true&amp;useTagName=true\">Economics<\/a><br><a href=\"https://www.lesswrong.com/tag/financial-investing?showPostCount=true&amp;useTagName=true\">Financial Investing<\/a><br><a href=\"https://www.lesswrong.com/tag/history?showPostCount=true&amp;useTagName=true\">History<\/a><br><a href=\"https://www.lesswrong.com/tag/politics?showPostCount=true&amp;useTagName=true\">Politics<\/a><br><a href=\"https://www.lesswrong.com/tag/progress-studies?showPostCount=true&amp;useTagName=true\">Progress Studies<\/a><br><a href=\"https://www.lesswrong.com/tag/social-and-cultural-dynamics?showPostCount=true&amp;useTagName=true\">Social and Cultural Dynamics<\/a><\/p><p><i>Specifics<\/i><br><a href=\"https://www.lesswrong.com/tag/conflict-vs-mistake?showPostCount=true&amp;useTagName=true\">Conflict vs Mistake Theory<\/a><br><a href=\"https://www.lesswrong.com/tag/cost-disease?showPostCount=true&amp;useTagName=true\">Cost Disease<\/a><br><a href=\"https://www.lesswrong.com/tag/efficient-market-hypothesis?showPostCount=true&amp;useTagName=true\">Efficient Market Hypothesis<\/a><br><a href=\"https://www.lesswrong.com/tag/industrial-revolution?showPostCount=true&amp;useTagName=true\">Industrial Revolution<\/a><br><a href=\"https://www.lesswrong.com/tag/moral-mazes?showPostCount=true&amp;useTagName=true\">Moral Mazes<\/a><br><a href=\"https://www.lesswrong.com/tag/signaling?showPostCount=true&amp;useTagName=true\">Signaling<\/a><br><a href=\"https://www.lesswrong.com/tag/social-reality?showPostCount=true&amp;useTagName=true\">Social Reality<\/a><br><a href=\"https://www.lesswrong.com/tag/social-status?showPostCount=true&amp;useTagName=true\">Social Status<\/a><\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border-color:hsl(0, 0%, 100%);border-style:solid;height:25px;padding:0px;vertical-align:top\"><p><strong>Biological &amp; Psychological<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/aging?showPostCount=true&amp;useTagName=true\">Aging<\/a><br><a href=\"https://www.lesswrong.com/tag/biology?showPostCount=true&amp;useTagName=true\">Biology<\/a><br><a href=\"https://www.lesswrong.com/tag/consciousness?showPostCount=true&amp;useTagName=true\">Consciousness<\/a><br><a href=\"https://www.lesswrong.com/tag/evolution?showPostCount=true&amp;useTagName=true\">Evolution<\/a><br><a href=\"http://www.lesswrong.com/tag/evolutionary-psychology?showPostCount=true&amp;useTagName=true\">Evolutionary Psychology<\/a><br><a href=\"https://www.lesswrong.com/tag/medicine?showPostCount=true&amp;useTagName=true\">Medicine<\/a><br><a href=\"https://www.lesswrong.com/tag/neuroscience?showPostCount=true&amp;useTagName=true\">Neuroscience<\/a><br><a href=\"https://www.lesswrong.com/tag/qualia?showPostCount=true&amp;useTagName=true\">Qualia<\/a><\/p><p><i>Specifics<\/i><br><a href=\"https://www.lesswrong.com/tag/coronavirus?showPostCount=true&amp;useTagName=true\">Coronavirus<\/a><br><a href=\"https://www.lesswrong.com/tag/general-intelligence?showPostCount=true&amp;useTagName=true\">General Intelligence<\/a><br><a href=\"http://www.lesswrong.com/tag/iq-g-factor?showPostCount=true&amp;useTagName=true\"><u>IQ / g-factor<\/u><\/a><br><a href=\"http://www.lesswrong.com/tag/neocortex?showPostCount=true&amp;useTagName=true\">Neocortex<\/a><\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border:1px solid hsl(0, 0%, 100%);padding:0px;vertical-align:top\"><p><strong>The Practice of Modeling<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/epistemic-review?showPostCount=true&amp;useTagName=true\">Epistemic Review<\/a><br><a href=\"https://www.lesswrong.com/tag/expertise?showPostCount=true&amp;useTagName=true\">Expertise<\/a><br><a href=\"https://www.lesswrong.com/tag/gears-level?showPostCount=true&amp;useTagName=true\">Gears-Level Models<\/a><br><a href=\"http://www.lesswrong.com/tag/falsifiability?showPostCount=true&amp;useTagName=true\">Falsifiability<\/a><br><a href=\"https://www.lesswrong.com/tag/forecasting-and-prediction?showPostCount=true&amp;useTagName=true\">Forecasting &amp; Prediction<\/a><br><a href=\"https://www.lesswrong.com/tag/forecasts-lists-of?showPostCount=true&amp;useTagName=true\">Forecasts (Lists of)<\/a><br><a href=\"http://www.lesswrong.com/tag/inside-outside-view?showPostCount=true&amp;useTagName=true\">Inside/Outside View<\/a><br><a href=\"http://www.lesswrong.com/tag/jargon-meta?showPostCount=true&amp;useTagName=true\">Jargon (meta)<\/a><br><a href=\"https://www.lesswrong.com/tag/practice-and-philosophy-of-science?showPostCount=true&amp;useTagName=true\">Practice and Philosophy of Science<\/a><br><a href=\"https://www.lesswrong.com/tag/prediction-markets?showPostCount=true&amp;useTagName=true\">Prediction Markets<\/a><br><a href=\"http://www.lesswrong.com/tag/reductionism?showPostCount=true&amp;useTagName=true\">Reductionism<\/a><br><a href=\"https://www.lesswrong.com/tag/replicability?showPostCount=true&amp;useTagName=true\">Replicability<\/a><br>&nbsp;<\/p><\/td><\/tr><\/tbody><\/table><\/figure><p>&nbsp;<\/p><h2>A definition by elimination<\/h2><p>Properly considered, the overwhelming majority of content LessWrong is about <i>modeling how the world is<\/i>, including almost all posts on Rationality and all practical advice. The intended usage of World Modeling is to capture all content describing how the world is that is not captured by the more specific major tags of <a href=\"https://www.lesswrong.com/tag/rationality\">Rationality<\/a>, <a href=\"https://www.lesswrong.com/tag/world-optimization\">World Optimization<\/a>, ... <\/p>"},"Tag:3uE2pXvbcnS9nnZRE":{"_id":"3uE2pXvbcnS9nnZRE","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:3uE2pXvbcnS9nnZRE_description"},"userId":"r38pkCm7wF4M44MDQ","name":"World Modeling","slug":"world-modeling","core":true,"postCount":2942,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":true,"needsReview":null,"descriptionTruncationCount":27,"createdAt":"2020-06-14T22:24:50.898Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:xexCWMyds6QLWognu_description":{"_id":"xexCWMyds6QLWognu_description","__typename":"Revision","htmlHighlight":"<p><strong>World Optimization<\/strong> is the full use of our agency. It is extending the reach of human civilization. It is building cities and democracies and economic systems and computers and flight and science and space rockets and the internet. World optimization is about adding to that list.&nbsp;<br><br>But its not just about growth, its also about preservation. We are still in the dawn of civilization, with most of civilization in the billions of years ahead. We mustnt let this light go out.<\/p><hr><h1>World Optimization Sub-Topics<\/h1><figure class=\"table\" style=\"width:100%\"><table style=\"border:20px solid hsl(0, 0%, 100%)\"><tbody><tr><td style=\"background-color:hsl(0,0%,100%);border-color:hsl(0, 0%, 100%);border-style:solid;height:50%;padding:0px;vertical-align:top;width:33%\"><p><strong>Moral Theory<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/altruism?showPostCount=true&amp;useTagName=true\">Altruism<\/a><br><a href=\"https://www.lesswrong.com/tag/consequentialism?showPostCount=true&amp;useTagName=true\">Consequentialism<\/a><br><a href=\"https://www.lesswrong.com/tag/deontology?showPostCount=true&amp;useTagName=true\">Deontology<\/a><br><a href=\"http://www.lesswrong.com/tag/ethics-and-morality?showPostCount=true&amp;useTagName=true\"><u>Ethics &amp; Morality<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/metaethics?showPostCount=true&amp;useTagName=true\">Metaethics<\/a><br><a href=\"http://www.lesswrong.com/tag/moral-uncertainty?showPostCount=true&amp;useTagName=true\"><u>Moral Uncertainty<\/u><\/a><\/p><p>&nbsp;<\/p><p>&nbsp;<\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:33%\"><p><strong>Causes / Interventions<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/aging?showPostCount=true&amp;useTagName=true\">Aging<\/a><br><a href=\"https://www.lesswrong.com/tag/animal-welfare?showPostCount=true&amp;useTagName=true\">Animal Welfare<\/a><br><a href=\"https://www.lesswrong.com/tag/existential-risk?showPostCount=true&amp;useTagName=true\">Existential Risk<\/a><br><a href=\"http://www.lesswrong.com/tag/futurism?showPostCount=true&amp;useTagName=true\">Futurism<\/a><br><a href=\"https://www.lesswrong.com/tag/mind-uploading?showPostCount=true&amp;useTagName=true\">Mind Uploading<\/a><br><a href=\"https://www.lesswrong.com/tag/life-extension?showPostCount=true&amp;useTagName=true\">Life Extension<\/a><br><a href=\"http://www.lesswrong.com/tag/risks-of-astronomical-suffering-s-risks?showPostCount=true&amp;useTagName=false\"><u>S-risks<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/transhumanism?showPostCount=true&amp;useTagName=true\"><u>Transhumanism<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/voting-theory?showPostCount=true&amp;useTagName=true\">Voting Theory<\/a><\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:33%\"><p><strong>Working with Humans<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/coalitional-instincts?showPostCount=true&amp;useTagName=true\"><u>Coalitional Instincts<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/common-knowledge?showPostCount=true&amp;useTagName=true\"><u>Common Knowledge<\/u><\/a><br><a href=\"http://www.lesswrong.com/tag/coordination-cooperation?showPostCount=true&amp;useTagName=true\">Coordination / Cooperation<\/a><br><a href=\"https://www.lesswrong.com/tag/game-theory?showPostCount=true&amp;useTagName=true\">Game Theory<\/a><br><a href=\"http://www.lesswrong.com/tag/group-rationality?showPostCount=true&amp;useTagName=true\">Group Rationality<\/a><br><a href=\"https://www.lesswrong.com/tag/institution-design?showPostCount=true&amp;useTagName=true\">Institution Design<\/a><br><a href=\"https://www.lesswrong.com/tag/moloch?showPostCount=true&amp;useTagName=true\">Moloch<\/a><br><a href=\"https://www.lesswrong.com/tag/signaling?showPostCount=true&amp;useTagName=true\">Signaling<\/a><br><a href=\"https://www.lesswrong.com/tag/simulacrum-levels?showPostCount=true&amp;useTagName=true\">Simulacrum Levels<\/a><br><a href=\"https://www.lesswrong.com/tag/social-status?showPostCount=true&amp;useTagName=true\">Social Status<\/a><\/p><\/td><\/tr><tr><td style=\"background-color:hsl(0,0%,100%);border:1px solid hsl(0, 0%, 100%);padding:0em;vertical-align:top\"><p><strong>Applied Topics<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/blackmail?showPostCount=true&amp;useTagName=true\">Blackmail<\/a><br><a href=\"http://www.lesswrong.com/tag/censorship?showPostCount=true&amp;useTagName=true\">Censorship<\/a><br><a href=\"http://www.lesswrong.com/tag/chesterton-s-fence?showPostCount=true&amp;useTagName=true\">Chesterton's Fence<\/a><br><a href=\"http://www.lesswrong.com/tag/death?showPostCount=true&amp;useTagName=true\">Death<\/a><br><a href=\"https://www.lesswrong.com/tag/deception?showPostCount=true&amp;useTagName=true\">Deception<\/a><br><a href=\"https://www.lesswrong.com/tag/honesty?showPostCount=true&amp;useTagName=true\">Honesty<\/a><br><a href=\"https://www.lesswrong.com/tag/hypocrisy?showPostCount=true&amp;useTagName=true\">Hypocrisy<\/a><br><a href=\"https://www.lesswrong.com/tag/information-hazards?showPostCount=true&amp;useTagName=true\">Information Hazards<\/a><br><a href=\"https://www.lesswrong.com/tag/meta-honesty?showPostCount=true&amp;useTagName=true\">Meta-Honesty<\/a><br><a href=\"http://www.lesswrong.com/tag/pascal-s-mugging?showPostCount=true&amp;useTagName=true\">Pascal's Mugging<\/a><br><a href=\"http://www.lesswrong.com/tag/war?showPostCount=true&amp;useTagName=true\">War<\/a><\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border-color:hsl(0, 0%, 100%);border-style:solid;height:25px;padding:0px;vertical-align:top\"><p><strong>Value &amp; Virtue<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/ambition?showPostCount=true&amp;useTagName=true\">Ambition<\/a><br><a href=\"https://www.lesswrong.com/tag/art?showPostCount=true&amp;useTagName=true\">Art<\/a><br><a href=\"https://www.lesswrong.com/tag/aesthetics?showPostCount=true&amp;useTagName=true\">Aesthetics<\/a><br><a href=\"https://www.lesswrong.com/tag/complexity-of-value?showPostCount=true&amp;useTagName=true\">Complexity of Value<\/a><br><a href=\"http://www.lesswrong.com/tag/courage?showPostCount=true&amp;useTagName=true\">Courage<\/a><br><a href=\"http://www.lesswrong.com/tag/fun-theory?showPostCount=true&amp;useTagName=true\">Fun Theory<\/a><br><a href=\"http://www.lesswrong.com/tag/principles?showPostCount=true&amp;useTagName=true\">Principles<\/a><br><a href=\"http://www.lesswrong.com/tag/suffering?showPostCount=true&amp;useTagName=true\"><u>Suffering<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/superstimuli?showPostCount=true&amp;useTagName=true\">Superstimuli<\/a><br><a href=\"https://www.lesswrong.com/tag/wireheading?showPostCount=true&amp;useTagName=true\">Wireheading<\/a><\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border:1px solid hsl(0, 0%, 100%);padding:0em;vertical-align:top\"><p><strong>Meta<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/cause-prioritization?showPostCount=true&amp;useTagName=true\">Cause Prioritization<\/a><br><a href=\"http://www.lesswrong.com/tag/center-on-long-term-risk-clr?useTagName=true&amp;showPostCount=true\">Center for Long-term Risk<\/a><br><a href=\"https://www.lesswrong.com/tag/effective-altruism?showPostCount=true&amp;useTagName=true\">Effective Altruism<\/a><br><a href=\"https://www.lesswrong.com/tag/heroic-responsibility?showPostCount=true&amp;useTagName=true\">Heroic Responsibility<\/a><br>&nbsp;<\/p><\/td><\/tr><\/tbody><\/table><\/figure><hr><p>Content which describes <i>how the world is <\/i>that directly bears upon choices one makes to optimize the world fall under this tag. Examples include discussion of the moral patienthood of different animals, the potential of human civilization, and the most effective interventions against a global health threat.<\/p><p>Some material has both immediate relevance to world optimization decisions but also can inform broader world models. This material might be included under both <a href=\"https://www.lesswrong.com/tag/world-modeling\">World Modeling<\/a> tag and this tag.<\/p>"},"Tag:xexCWMyds6QLWognu":{"_id":"xexCWMyds6QLWognu","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:xexCWMyds6QLWognu_description"},"userId":"XtphY3uYHwruKqDyG","name":"World Optimization","slug":"world-optimization","core":true,"postCount":1807,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":true,"needsReview":null,"descriptionTruncationCount":20,"createdAt":"2020-06-14T03:38:23.532Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:fkABsGCJZ6y9qConW_description":{"_id":"fkABsGCJZ6y9qConW_description","__typename":"Revision","htmlHighlight":"<p><strong>Practical<\/strong> posts give direct, actionable advice on how to achieve goals and generally succeed. The art of rationality would be useless if it did not connect to the real world; we must take our ideas and abstractions and collide them with reality. Many places on the internet will give you advice; here, we value survey data, literature reviews, self-blinded trials, quantitative estimates, and theoretical models that aim to explain the phenomena.<\/p><p>Material that is directly about <i>how to think better<\/i> can be found at <a href=\"https://www.lessestwrong.com/tag/rationality\">Rationality<\/a>.<\/p><p>&nbsp;<\/p><h1><strong>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Practical Sub-Topics<\/strong><\/h1><figure class=\"table\" style=\"width:100%\"><table style=\"background-color:rgb(255, 255, 255);border:2px solid hsl(0, 0%, 90%)\"><tbody><tr><td style=\"border:1px solid hsl(0, 0%, 100%);padding:0px;vertical-align:top;width:33%\" rowspan=\"2\"><p><strong>Domains of Well-being<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/careers?showPostCount=true&amp;useTagName=true\">Careers<\/a><br><a href=\"https://www.lesswrong.com/tag/emotions?showPostCount=true&amp;useTagName=true\">Emotions<\/a><br><a href=\"http://www.lesswrong.com/tag/exercise-physical?showPostCount=true&amp;useTagName=true\">Exercise (Physical)<\/a><br><a href=\"https://www.lesswrong.com/tag/financial-investing?showPostCount=true&amp;useTagName=true\">Financial Investing<\/a><br><a href=\"http://www.lesswrong.com/tag/gratitude?showPostCount=true&amp;useTagName=true\">Gratitude<\/a><br><a href=\"http://www.lesswrong.com/tag/happiness-1?showPostCount=true&amp;useTagName=true\">Happiness<\/a><br><a href=\"http://www.lesswrong.com/tag/human-bodies?showPostCount=true&amp;useTagName=true\">Human Bodies<\/a><br><a href=\"http://www.lesswrong.com/tag/nutrition?showPostCount=true&amp;useTagName=true\">Nutrition<\/a><br><a href=\"https://www.lesswrong.com/tag/parenting?showPostCount=true&amp;useTagName=true\">Parenting<\/a><br><a href=\"https://www.lesswrong.com/tag/slack?showPostCount=true&amp;useTagName=true\">Slack<\/a><br><a href=\"https://www.lesswrong.com/tag/sleep?showPostCount=true&amp;useTagName=true\">Sleep<\/a><br><a href=\"https://www.lesswrong.com/tag/well-being?showPostCount=true&amp;useTagName=true\">Well-being<\/a><\/p><\/td><td style=\"border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:33%\" rowspan=\"2\"><p><strong>Skills, Tools, Techniques<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/cryonics?showPostCount=true&amp;useTagName=true\">Cryonics<\/a><br><a href=\"https://www.lesswrong.com/tag/emotions?showPostCount=true&amp;useTagName=true\">Emotions<\/a><br><a href=\"https://www.lesswrong.com/tag/goal-factoring?showPostCount=true&amp;useTagName=true\">Goal Factoring<\/a><br><a href=\"http://www.lesswrong.com/tag/habits?showPostCount=true&amp;useTagName=true\">Habits<\/a><br><a href=\"https://www.lesswrong.com/tag/hamming-questions?showPostCount=true&amp;useTagName=true\">Hamming Questions<\/a><br><a href=\"http://www.lesswrong.com/tag/life-improvements?showPostCount=true&amp;useTagName=true\">Life Improvements<\/a><br><a href=\"https://www.lesswrong.com/tag/meditation?showPostCount=true&amp;useTagName=true\">Meditation<\/a><br><a href=\"http://www.lesswrong.com/tag/more-dakka?showPostCount=true&amp;useTagName=true\">More Dakka<\/a><br><a href=\"https://www.lesswrong.com/tag/pica?showPostCount=true\"><u>Pica<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/planning-and-decision-making?showPostCount=true&amp;useTagName=true\">Planning &amp; Decision-Making<\/a><br><a href=\"https://www.lesswrong.com/tag/self-experimentation?showPostCount=true&amp;useTagName=true\">Self Experimentation<\/a><br><a href=\"http://www.lesswrong.com/tag/skill-building?showPostCount=true&amp;useTagName=true\">Skill Building<\/a><br><a href=\"https://www.lesswrong.com/tag/software-tools?showPostCount=true&amp;useTagName=true\">Software Tools<\/a><br><a href=\"https://www.lesswrong.com/tag/spaced-repetition?showPostCount=true&amp;useTagName=true\">Spaced Repetition<\/a><br><a href=\"https://www.lesswrong.com/tag/virtues-instrumental?showPostCount=true&amp;useTagName=false\">Virtues (Instrumental)<\/a><\/p><\/td><td style=\"border-color:hsl(0, 0%, 100%);border-style:solid;height:50%;padding:0px;vertical-align:top;width:33%\"><p><strong>Productivity<\/strong><\/p><p><a href=\"https://www.lesswrong.com/tag/akrasia?showPostCount=true&amp;useTagName=true\">Akrasia<\/a><br><a href=\"https://www.lesswrong.com/tag/motivations?showPostCount=true&amp;useTagName=true\">Motivations<\/a><br><a href=\"https://www.lesswrong.com/tag/prioritization?showPostCount=true&amp;useTagName=true\">Prioritization<\/a><br><a href=\"https://www.lesswrong.com/tag/procrastination?showPostCount=true&amp;useTagName=true\">Procrastination<\/a><br><a href=\"https://www.lesswrong.com/tag/productivity?showPostCount=true&amp;useTagName=true\">Productivity<\/a><br><a href=\"https://www.lesswrong.com/tag/willpower?showPostCount=true&amp;useTagName=true\">Willpower<\/a><\/p><\/td><\/tr><tr><td style=\"border:1px solid hsl(0, 0%, 100%);padding:0px;vertical-align:top\"><strong>Interpersonal<\/strong><br><a href=\"http://www.lesswrong.com/tag/circling?showPostCount=true&amp;useTagName=true\"><u>Circling<\/u><\/a><br><a href=\"https://www.lesswrong.com/tag/conversation-topic?showPostCount=true&amp;useTagName=true\">Conversation (topic)<\/a><br><a href=\"https://www.lesswrong.com/tag/communication-cultures?showPostCount=true&amp;useTagName=true\">Communication Cultures<\/a><br><a href=\"http://www.lesswrong.com/tag/relationships-interpersonal?showPostCount=true&amp;useTagName=false\"><u>Relationship<\/u><\/a><\/td><\/tr><\/tbody><\/table><\/figure>"},"Tag:fkABsGCJZ6y9qConW":{"_id":"fkABsGCJZ6y9qConW","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:fkABsGCJZ6y9qConW_description"},"userId":"oBSWiHjgproTiThmY","name":"Practical","slug":"practical","core":true,"postCount":2028,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":true,"needsReview":null,"descriptionTruncationCount":2000,"createdAt":"2020-06-14T06:06:46.947Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:izp6eeJJEg9v5zcur_description":{"_id":"izp6eeJJEg9v5zcur_description","__typename":"Revision","htmlHighlight":"<p>The <strong>LessWrong<\/strong> <strong>Community<\/strong> consists of the people who write on LessWrong and who contribute to its mission of refining the art of human rationality. This tag includes community events, analysis of the health, norms and direction of the community, and space to understand communities in general.<\/p><p>LessWrong also has many brothers and sisters like the Berkeley Rationality Community, <a href=\"https://www.reddit.com/r/slatestarcodex/\">SlateStarCodex<\/a>, <a href=\"https://www.reddit.com/r/rational/\">Rational Fiction<\/a>, <a href=\"https://forum.effectivealtruism.org/\">Effective Altruism<\/a>, <a href=\"https://www.alignmentforum.org/\">AI Alignment<\/a>, and more, who participate here. To see upcoming LessWrong events, go to the <a href=\"https://www.lesswrong.com/community\">community section<\/a>.<\/p><hr><h2><strong>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Community Sub-Topics<\/strong><\/h2><figure class=\"table\" style=\"width:100%\"><table style=\"border:20px solid hsl(0, 0%, 100%)\"><tbody><tr><td style=\"background-color:hsl(0,0%,100%);border-color:hsl(0, 0%, 100%);border-style:solid;padding:0px;vertical-align:top;width:50%\"><p><strong>All<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/bounties-active?showPostCount=true&amp;useTagName=true\">Bounties (active)<\/a><br><a href=\"https://www.lesswrong.com/tag/grants-and-fundraising-opportunities?showPostCount=true\">Grants &amp; Fundraising<\/a><br><a href=\"http://www.lesswrong.com/tag/growth-stories?showPostCount=true&amp;useTagName=true\">Growth Stories<\/a><br><a href=\"https://www.lesswrong.com/tag/online-socialization?showPostCount=true&amp;useTagName=true\">Online Socialization<\/a><br><a href=\"https://www.lesswrong.com/tag/petrov-day?showPostCount=true&amp;useTagName=true\">Petrov Day<\/a><br><a href=\"https://www.lesswrong.com/tag/public-discourse?showPostCount=true&amp;useTagName=true\">Public Discourse<\/a><br><a href=\"https://www.lesswrong.com/tag/research-agendas?showPostCount=true&amp;useTagName=true\">Research Agendas<\/a><br><a href=\"https://www.lesswrong.com/tag/ritual?showPostCount=true&amp;useTagName=true\">Ritual<\/a><br><a href=\"https://www.lesswrong.com/tag/solstice-celebration?showPostCount=true&amp;useTagName=true\">Solstice Celebration<\/a><br>&nbsp;<\/p><\/td><td style=\"background-color:hsl(0,0%,100%);border:1px solid hsl(0, 0%, 100%);padding:0px;vertical-align:top;width:50%\"><p><strong>LessWrong<\/strong><\/p><p><a href=\"http://www.lesswrong.com/tag/events-community?showPostCount=true&amp;useTagName=true\">Events (Community)<\/a><br><a href=\"https://www.lesswrong.com/tag/site-meta?showPostCount=true&amp;useTagName=true\">Site Meta<\/a><br><a href=\"https://www.lesswrong.com/tag/greaterwrong-meta?showPostCount=true&amp;useTagName=true\">GreaterWrong Meta<\/a><br><a href=\"https://www.lesswrong.com/tag/lesswrong-events?showPostCount=true&amp;useTagName=true\">LessWrong Events<\/a><br><a href=\"http://www.lesswrong.com/tag/lw-moderation?showPostCount=true&amp;useTagName=true\">LW Moderation<\/a><br><a href=\"http://www.lesswrong.com/tag/meetups-topic?showPostCount=true&amp;useTagName=true\">Meetups (topic)<\/a><br><a href=\"http://www.lesswrong.com/tag/moderation-topic?showPostCount=true&amp;useTagName=true\">Moderation (topic)<\/a><br><a href=\"http://www.lesswrong.com/tag/the-sf-bay-area?showPostCount=true&amp;useTagName=true\">The SF Bay Area<\/a><br><a href=\"http://www.lesswrong.com/tag/tagging?showPostCount=true\">Tagging<\/a><\/p><\/td><\/tr><\/tbody><\/table><\/figure><p><i>Not all Community posts are tagged with subtopics.<\/i><\/p><hr><p>This tag applies to any post about:<\/p><ul><li>Specific projects, orgs, and prizes [e.g. <a href=\"http://www.lesswrong.com/posts/xFGQdgJndLcthgWoE\"><u>1<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/KgFrtaajjfSnBSZoH\"><u>2<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/auL2gAGTb3MsYhCeN\"><u>3<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/cSzaxcmeYW6z7cgtc\"><u>4<\/u><\/a>, <a href=\"https://www.lesswrong.com/posts/nDHbgjdddG5EN6ocg\"><u>5<\/u><\/a>]<\/li><li>Requests and offers for help [<a href=\"http://www.lesswrong.com/posts/bSWavBThj6ebB62gD\"><u>1<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/LuL7LLqcdmM7TTYvW\"><u>2<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/x72ta8C3dKu2QRfPv\"><u>3<\/u><\/a>]<\/li><li>Announcements, retrospectives, funding requests, and AMAs from orgs [<a href=\"http://www.lesswrong.com/posts/XJiNtvxoiLCpBn6FH\"><u>1<\/u><\/a> <a href=\"https://www.lesswrong.com/posts/96N8BT9tJvybLbn5z/we-run-the-center-for-applied-rationality-ama\"><u>2<\/u><\/a> <a href=\"http://www.lesswrong.com/posts/KgFrtaajjfSnBSZoH\"><u>3<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/auL2gAGTb3MsYhCeN\"><u>4<\/u><\/a>, <a href=\"https://www.lesswrong.com/posts/tCHsm5ZyAca8HfJSG\"><u>5<\/u><\/a>]<\/li><li>Discussions of the orgs in the LessWrong, Rationalist cluster [<a href=\"http://www.lesswrong.com/posts/KpnyCT7CZy4Qe6kx6\"><u>1<\/u><\/a>, <a href=\"https://www.lesswrong.com/posts/6SGqkCgHuNr7d4yJm/thoughts-on-the-singularity-institute-si\"><u>2<\/u><\/a>]<\/li><li>Discussions about the LessWrong, Rationalist, and related communities [<a href=\"http://www.lesswrong.com/posts/2Ee5DPBxowTTXZ6zf\"><u>1<\/u><\/a>, <a href=\"http://www.lesswrong.com/posts/yGycR8tFA3JJbvApp\"><u>2<\/u><\/a>, <a href=\"https://www.lesswrong.com/posts/zAqoj79A7QuhJKKvi\"><u>3<\/u><\/a>]<\/li><\/ul><p>While the <a href=\"https://www.lesswrong.com/tag/world-optimization\">World Optimization<\/a><i> <\/i>core tag is for posts discussing how to do good in general, the Community tag is for the specific, concrete efforts of our community to execute plans.<\/p>"},"Tag:izp6eeJJEg9v5zcur":{"_id":"izp6eeJJEg9v5zcur","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:izp6eeJJEg9v5zcur_description"},"userId":"XtphY3uYHwruKqDyG","name":"Community","slug":"community","core":true,"postCount":1333,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":true,"needsReview":null,"descriptionTruncationCount":15,"createdAt":"2020-06-14T03:38:34.631Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:dqx5k65wjFfaiJ9sQ_description":{"_id":"dqx5k65wjFfaiJ9sQ_description","__typename":"Revision","htmlHighlight":"<p><strong>Procrastination<\/strong> is [TODO: finish tag description]<\/p>"},"Tag:dqx5k65wjFfaiJ9sQ":{"_id":"dqx5k65wjFfaiJ9sQ","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:dqx5k65wjFfaiJ9sQ_description"},"userId":"nLbwLhBaQeG6tCNDN","name":"Procrastination","slug":"procrastination","core":false,"postCount":34,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-11T20:28:09.572Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Tag:udPbn9RthmgTtHMiG":{"_id":"udPbn9RthmgTtHMiG","__typename":"Tag","parentTag":null,"subTags":[],"description":null,"userId":"nLbwLhBaQeG6tCNDN","name":"Productivity","slug":"productivity","core":false,"postCount":174,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":null,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-11T20:28:13.679Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:tNsqhzTibgGJKPEWB_description":{"_id":"tNsqhzTibgGJKPEWB_description","__typename":"Revision","htmlHighlight":"<p>The <strong>2019 Novel Coronavirus<\/strong> (aka COVID-19, SARS-CoV-2) is a pandemic sweeping the world.<\/p>"},"Tag:tNsqhzTibgGJKPEWB":{"_id":"tNsqhzTibgGJKPEWB","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:tNsqhzTibgGJKPEWB_description"},"userId":"r38pkCm7wF4M44MDQ","name":"Covid-19","slug":"covid-19","core":false,"postCount":908,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-14T22:24:27.569Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:sSNtcEQsqHgN8ZmRF_description":{"_id":"sSNtcEQsqHgN8ZmRF_description","__typename":"Revision","htmlHighlight":"<p><strong>Fun Theory<\/strong> is the field of knowledge studying how to design for fun in future society: it deals in questions such as \"How much fun is there in the universe?\", \"Will we ever run out of fun?\", \"Are we having fun yet?\" and \"Could we be having more fun?\"<\/p><p>From <a href=\"https://www.lesswrong.com/posts/K4aGvLnHvYgX9pZHS/the-fun-theory-sequence\">The Fun Theory Sequence<\/a>:<\/p>\n<blockquote>\n<p>Many critics (including <a href=\"https://www.lesswrong.com/lw/xl/eutopia_is_scary/\">George Orwell<\/a>) have commented on the inability of authors to imagine Utopias where anyone would actually want to live. If no one can imagine a Future where anyone would want to live, that may drain off motivation to work on the project. The prospect of endless boredom is routinely fielded by conservatives as a knockdown argument against research on lifespan extension, against cryonics, against all transhumanism, and occasionally against the entire Enlightenment ideal of a better future.<\/p>\n<\/blockquote>\n<blockquote>\n<p>Fun Theory is also the fully general reply to religious theodicy (attempts to justify why God permits evil). Our present world has flaws even from the standpoint of such eudaimonic considerations as freedom, personal responsibility, and self-reliance. Fun Theory tries to describe the dimensions along which a benevolently designed world can and should be optimized, and our present world is clearly <em>not<\/em> the result of such optimization. Fun Theory also highlights the flaws of any particular religion's perfect afterlife - you wouldn't want to go to their Heaven.<\/p>\n<\/blockquote>\n<h2>The argument against Enlightenment<\/h2>\n<p>Some critiques of <a href=\"https://www.lesswrong.com/tag/transhumanism\">transhumanism<\/a> (and related fields such as cryonics or lifespan extension) suggest that human enhancement would be accompanied boredom and the end of fun as we know it. For example: \"if we self-improve human minds to extreme levels of intelligence, all challenges known today may bore us.\" Likewise, \"if superhumanly intelligent machines take care of our every need, it is apparent that no challenges nor fun will remain.\"<\/p><p>However, we can work towards determining whether and how the universe will offer, or whether we ourselves can create, ever more complex and sophisticated opportunities to delight, entertain and challenge ever more powerful and resourceful minds.<\/p>\n<h2>The concept of Utopia<\/h2>\n<p>Transhumanists are usually seen as working towards a better human future. This future is sometimes conceptualized, as George Orwell <a href=\"http://www.orwell.ru/library/articles/socialists/english/e_fun\">aptly describes it<\/a>, as Utopia:<\/p>\n<blockquote>\n<p>\"It is a commonplace [view] that the Christian Heaven, as usually portrayed, would attract nobody. Almost all Christian writers de<\/p><\/blockquote>..."},"Tag:sSNtcEQsqHgN8ZmRF":{"_id":"sSNtcEQsqHgN8ZmRF","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:sSNtcEQsqHgN8ZmRF_description"},"userId":"r38pkCm7wF4M44MDQ","name":"Fun Theory","slug":"fun-theory","core":false,"postCount":48,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-08-06T00:51:42.262Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:irYLXtT9hkPXoZqhH_description":{"_id":"irYLXtT9hkPXoZqhH_description","__typename":"Revision","htmlHighlight":"<p>Recollections of personal progress, lessons learned, memorable experiences, coming of age, in autobiographical form.<\/p><p><strong>Sequences:<\/strong>&nbsp;<\/p><ul><li><a href=\"https://www.lesswrong.com/s/SXurf2mWFw8LX2mkG\">Yudkowsky's Coming of Age<\/a><\/li><\/ul><p><strong>Related Pages:<\/strong> <a href=\"https://www.lesswrong.com/tag/postmortems-and-retrospectives\">Postmortems &amp; Retrospectives<\/a>, <a href=\"https://www.lesswrong.com/tag/updated-beliefs-examples-of\">Updated Beliefs (examples of)<\/a>, <a href=\"https://www.lesswrong.com/tag/self-improvement\">Self Improvement<\/a>, <a href=\"https://www.lesswrong.com/tag/progress-studies\">Progress Studies<\/a> (society level)<\/p>"},"Tag:irYLXtT9hkPXoZqhH":{"_id":"irYLXtT9hkPXoZqhH","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:irYLXtT9hkPXoZqhH_description"},"userId":"QBvPFLFyZyuHcBwFm","name":"Growth Stories","slug":"growth-stories","core":false,"postCount":61,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-31T12:16:21.965Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Tag:AodfCFefLAuwDyj7Z":{"_id":"AodfCFefLAuwDyj7Z","__typename":"Tag","parentTag":null,"subTags":[],"description":null,"userId":"qKdS7bw9McaSeMNbY","name":"Self Experimentation","slug":"self-experimentation","core":false,"postCount":55,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":null,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-05-22T01:42:06.501Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:WqLn4pAWi5hn6McHQ_description":{"_id":"WqLn4pAWi5hn6McHQ_description","__typename":"Revision","htmlHighlight":"<p>Personal Growth, etc<\/p><p><strong>Related Pages: <\/strong><a href=\"https://www.lesswrong.com/tag/growth-stories\">Growth Stories<\/a><\/p>"},"Tag:WqLn4pAWi5hn6McHQ":{"_id":"WqLn4pAWi5hn6McHQ","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:WqLn4pAWi5hn6McHQ_description"},"userId":"r38pkCm7wF4M44MDQ","name":"Self Improvement","slug":"self-improvement","core":false,"postCount":105,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-08-01T21:40:20.646Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Notification:5cm5Fh9zmvpdFdRJS":{"_id":"5cm5Fh9zmvpdFdRJS","__typename":"Notification","documentId":"BssE6u2c2yePFTt5Y","documentType":"comment","deleted":false,"userId":"P4zDcpuj7sXjWMSwh","createdAt":"2023-01-04T19:20:34.789Z","link":"/posts/o5hbpFxmHR3QHtse4/talking-to-god?commentId=BssE6u2c2yePFTt5Y","message":"abramdemski replied to your comment on \"Talking to God\"","type":"newReplyToYou","viewed":false,"extraData":null},"Notification:MQNSsQJEtc4TynnHK":{"_id":"MQNSsQJEtc4TynnHK","__typename":"Notification","documentId":"Z5pJBXJsDzQNuSzHk","documentType":"comment","deleted":false,"userId":"P4zDcpuj7sXjWMSwh","createdAt":"2022-12-26T21:42:59.434Z","link":"/posts/BwZiNv8YuionaGAh5/under-appreciated-ways-to-use-flashcards?commentId=Z5pJBXJsDzQNuSzHk","message":"Florence Hinder replied to your comment on \"Under-Appreciated Ways to Use Flashcards\"","type":"newReplyToYou","viewed":false,"extraData":null},"Notification:aRfMcE6wnZHJuioDK":{"_id":"aRfMcE6wnZHJuioDK","__typename":"Notification","documentId":"3TBmHEeypMYutp9gy","documentType":"comment","deleted":false,"userId":"P4zDcpuj7sXjWMSwh","createdAt":"2022-12-25T23:03:57.622Z","link":"/posts/rCZ9fruWriD6uGNLp/who-are-some-prominent-reasonable-people-who-are-confident?commentId=3TBmHEeypMYutp9gy","message":"Optimization Process replied to your comment on \"Who are some prominent reasonable people who are confident that AI won't kill everyone?\"","type":"newReplyToYou","viewed":false,"extraData":null},"Notification:fRospfegkFaK6t2bn":{"_id":"fRospfegkFaK6t2bn","__typename":"Notification","documentId":"ZFYzYQbEEAXKBCski","documentType":"post","deleted":false,"userId":"P4zDcpuj7sXjWMSwh","createdAt":"2022-09-07T18:12:46.534Z","link":"/events/ZFYzYQbEEAXKBCski/introduction-to-effective-altruism-how-to-do-good-with-your","message":"New event in your area: Introduction to Effective Altruism: How to do good with your career","type":"newEventInRadius","viewed":false,"extraData":null},"Notification:Bcj9kdJqYu9pqXM4Y":{"_id":"Bcj9kdJqYu9pqXM4Y","__typename":"Notification","documentId":"ZFYzYQbEEAXKBCski","documentType":"post","deleted":false,"userId":"P4zDcpuj7sXjWMSwh","createdAt":"2022-09-07T18:12:46.532Z","link":"/events/ZFYzYQbEEAXKBCski/introduction-to-effective-altruism-how-to-do-good-with-your","message":"New event in your area: Introduction to Effective Altruism: How to do good with your career","type":"newEventInRadius","viewed":false,"extraData":null},"Notification:dzyspHv2MXQFdGktb":{"_id":"dzyspHv2MXQFdGktb","__typename":"Notification","documentId":"Qh3AeTyREkrJFwGH4","documentType":"post","deleted":false,"userId":"P4zDcpuj7sXjWMSwh","createdAt":"2022-08-30T12:00:55.278Z","link":"/events/Qh3AeTyREkrJFwGH4/the-hague-netherlands-acx-meetups-everywhere-2022","message":"Event in your area updated: The Hague, Netherlands  ACX Meetups Everywhere 2022","type":"editedEventInRadius","viewed":false,"extraData":null},"Notification:oruCmFkh9eNEjqwxC":{"_id":"oruCmFkh9eNEjqwxC","__typename":"Notification","documentId":"Qh3AeTyREkrJFwGH4","documentType":"post","deleted":false,"userId":"P4zDcpuj7sXjWMSwh","createdAt":"2022-08-24T23:06:57.256Z","link":"/events/Qh3AeTyREkrJFwGH4/the-hague-netherlands-acx-meetups-everywhere-2022","message":"New event in your area: The Hague, Netherlands  ACX Meetups Everywhere 2022","type":"newEventInRadius","viewed":false,"extraData":null},"Notification:Qhiz5xCagSxsE2StA":{"_id":"Qhiz5xCagSxsE2StA","__typename":"Notification","documentId":"unrrGibxptCgid4mr","documentType":"post","deleted":false,"userId":"P4zDcpuj7sXjWMSwh","createdAt":"2022-08-24T23:06:49.378Z","link":"/events/unrrGibxptCgid4mr/helmond-netherlands-acx-meetups-everywhere-2022","message":"New event in your area: Helmond, Netherlands  ACX Meetups Everywhere 2022","type":"newEventInRadius","viewed":false,"extraData":null},"Notification:hj4wrbrZLKgx4GAqX":{"_id":"hj4wrbrZLKgx4GAqX","__typename":"Notification","documentId":"7hmoCG5un5qhpyJZc","documentType":"post","deleted":false,"userId":"P4zDcpuj7sXjWMSwh","createdAt":"2022-08-24T23:06:38.438Z","link":"/events/7hmoCG5un5qhpyJZc/delft-netherlands-acx-meetups-everywhere-2022","message":"New event in your area: Delft, Netherlands  ACX Meetups Everywhere 2022","type":"newEventInRadius","viewed":false,"extraData":null},"Notification:5PzoZNgyDxLsuzhCa":{"_id":"5PzoZNgyDxLsuzhCa","__typename":"Notification","documentId":"ko2N3qbWxfcmAaP6w","documentType":"comment","deleted":false,"userId":"P4zDcpuj7sXjWMSwh","createdAt":"2022-04-04T15:18:43.319Z","link":"/posts/pi4owuC7Rdab7uWWR/book-review-why-greatness-cannot-be-planned-the-myth-of-the?commentId=ko2N3qbWxfcmAaP6w","message":"Devansh Pandey left a new comment on \"[Book Review] Why Greatness Cannot Be Planned: The Myth of the Objective\"","type":"newComment","viewed":false,"extraData":null},"Notification:tvEQ25xW2Kw9ckty9":{"_id":"tvEQ25xW2Kw9ckty9","__typename":"Notification","documentId":"us8Xj3hsaKkLypGpa","documentType":"comment","deleted":false,"userId":"P4zDcpuj7sXjWMSwh","createdAt":"2022-04-03T19:45:04.572Z","link":"/posts/yzmDgP2hueHRsCP7i/working-out-in-vr-really-works?commentId=us8Xj3hsaKkLypGpa","message":"Yonatan Cale replied to your comment on \"Working Out in VR Really Works\"","type":"newReplyToYou","viewed":false,"extraData":null},"Notification:9HDCtMETNsadckTWm":{"_id":"9HDCtMETNsadckTWm","__typename":"Notification","documentId":"Em79MsoK7N4ZmaLwD","documentType":"comment","deleted":false,"userId":"P4zDcpuj7sXjWMSwh","createdAt":"2022-04-03T19:41:21.691Z","link":"/posts/yzmDgP2hueHRsCP7i/working-out-in-vr-really-works?commentId=Em79MsoK7N4ZmaLwD","message":"Dustin replied to your comment on \"Working Out in VR Really Works\"","type":"newReplyToYou","viewed":false,"extraData":null},"Notification:NX865rwsvfWra5Krk":{"_id":"NX865rwsvfWra5Krk","__typename":"Notification","documentId":"9G7uuis6HQxFfwGGr","documentType":"comment","deleted":false,"userId":"P4zDcpuj7sXjWMSwh","createdAt":"2022-04-03T19:40:04.045Z","link":"/posts/LkEpSNvehbKgne5Ln/a-simple-guide-to-life?commentId=9G7uuis6HQxFfwGGr","message":"jasoncrawford replied to your comment on \"A simple guide to life\"","type":"newReplyToYou","viewed":false,"extraData":null},"Notification:jGF3iyXyiQxXoTDKN":{"_id":"jGF3iyXyiQxXoTDKN","__typename":"Notification","documentId":"4orNGHnFYh7rQ6FAx","documentType":"comment","deleted":false,"userId":"P4zDcpuj7sXjWMSwh","createdAt":"2021-10-03T16:41:04.260Z","link":"/posts/zHS4FJhByRjqsuH4o/the-best-software-for-every-need?commentId=4orNGHnFYh7rQ6FAx","message":"milo replied to your comment on \"The Best Software For Every Need\"","type":"newReplyToYou","viewed":false,"extraData":null},"Notification:mQycwuMfMLjdGiEZD":{"_id":"mQycwuMfMLjdGiEZD","__typename":"Notification","documentId":"nRBAvvRE2pQeSghh2","documentType":"comment","deleted":false,"userId":"P4zDcpuj7sXjWMSwh","createdAt":"2021-09-20T02:08:50.753Z","link":"/posts/zHS4FJhByRjqsuH4o/the-best-software-for-every-need?commentId=nRBAvvRE2pQeSghh2","message":"charlesoblack replied to your comment on \"The Best Software For Every Need\"","type":"newReplyToYou","viewed":false,"extraData":null},"Notification:LKo5ipftkjZKCWTcm":{"_id":"LKo5ipftkjZKCWTcm","__typename":"Notification","documentId":"nAPrHTWZrSSrbJNi4","documentType":"comment","deleted":false,"userId":"P4zDcpuj7sXjWMSwh","createdAt":"2021-09-12T17:14:51.185Z","link":"/posts/zHS4FJhByRjqsuH4o/the-best-software-for-every-need?commentId=nAPrHTWZrSSrbJNi4","message":"mb99 replied to your comment on \"The Best Software For Every Need\"","type":"newReplyToYou","viewed":false,"extraData":null},"Notification:p7bWsaj9ppWzW7ZAJ":{"_id":"p7bWsaj9ppWzW7ZAJ","__typename":"Notification","documentId":"utSEyebNsDphzBumx","documentType":"comment","deleted":false,"userId":"P4zDcpuj7sXjWMSwh","createdAt":"2021-09-12T11:59:52.657Z","link":"/posts/zHS4FJhByRjqsuH4o/the-best-software-for-every-need?commentId=utSEyebNsDphzBumx","message":"supposedlyfun replied to your comment on \"The Best Software For Every Need\"","type":"newReplyToYou","viewed":false,"extraData":null},"Notification:LndcjC6GT4SiCkNad":{"_id":"LndcjC6GT4SiCkNad","__typename":"Notification","documentId":"TB6tvMJBAnjEHXb2n","documentType":"comment","deleted":false,"userId":"P4zDcpuj7sXjWMSwh","createdAt":"2021-09-11T20:51:58.929Z","link":"/posts/zHS4FJhByRjqsuH4o/the-best-software-for-every-need?commentId=TB6tvMJBAnjEHXb2n","message":"Gunnar_Zarncke replied to your comment on \"The Best Software For Every Need\"","type":"newReplyToYou","viewed":false,"extraData":null},"Notification:AFWCuvKEfsBQSpntg":{"_id":"AFWCuvKEfsBQSpntg","__typename":"Notification","documentId":"MmhmFNembXimGdmuX","documentType":"comment","deleted":false,"userId":"P4zDcpuj7sXjWMSwh","createdAt":"2021-09-10T20:37:45.612Z","link":"/posts/zHS4FJhByRjqsuH4o/the-best-software-for-every-need?commentId=MmhmFNembXimGdmuX","message":"TheTrueSquidward replied to your comment on \"The Best Software For Every Need\"","type":"newReplyToYou","viewed":false,"extraData":null},"Notification:PMEhyN4kqeoagnAHF":{"_id":"PMEhyN4kqeoagnAHF","__typename":"Notification","documentId":"kxhSSsFnNCqsxSyMh","documentType":"comment","deleted":false,"userId":"P4zDcpuj7sXjWMSwh","createdAt":"2021-09-07T20:18:43.949Z","link":"/posts/wBxEJdZomzzuMjDcN/tasks-apps-w-time-estimates-to-gauge-how-much-you-ll?commentId=kxhSSsFnNCqsxSyMh","message":"IrenicTruth replied to your comment on \"Tasks apps w/ time estimates to gauge how much you'll overshoot?\"","type":"newReplyToYou","viewed":false,"extraData":null},"Revision:JGf5RYqCfGuhvtAu3_":{"_id":"JGf5RYqCfGuhvtAu3_","__typename":"Revision","htmlHighlight":"<p>Hi!<\/p><p>My name's Logan Chipkin. I'm hosting the second Philly Rat Fest the weekend of June 30th - July 2nd, 2023.<\/p><p>Join us for workshops, talks, good food, new friends, old friends, philosophizing, and laughing.<\/p><p>Last time, we had a very successful event in Philadelphia. People flew from all across the world to discuss, debate, and learn about some of the deepest ideas Rats of all stripes care about.<\/p><p>While online communities serve many purposes, there's nothing quite like meeting up in person to fortify a community.<\/p><p>To be clear, Rats of all stripes are welcome to join! Last time, we had plenty of rationalists, crit rats, post rats, and Bayesians.<\/p><p>If you have any questions, email me at chipkin.logan@gmail.com, or DM me on Twitter @chipkinlogan.<\/p><p>Here's the ticket link: https://www.eventbrite.com/e/the-rat-fest-tickets-387125692367.<\/p><p>Cheers,<\/p><p>Logan<br>&nbsp;<\/p><p><br>&nbsp;<\/p>","wordCount":133,"version":"1.0.0"},"User:CWxPBBctj39bqv2uC":{"_id":"CWxPBBctj39bqv2uC","__typename":"User","biography":null,"profileImageId":null,"moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":null,"slug":"loganchipkin","createdAt":"2023-01-22T22:54:46.401Z","username":"LoganChipkin","displayName":"LoganChipkin","previousDisplayName":null,"fullName":null,"karma":1,"afKarma":null,"deleted":null,"isAdmin":false,"htmlBio":"","postCount":1,"commentCount":0,"sequenceCount":null,"afPostCount":null,"afCommentCount":0,"spamRiskScore":0.9,"tagRevisionCount":null},"Post:JGf5RYqCfGuhvtAu3":{"_id":"JGf5RYqCfGuhvtAu3","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:JGf5RYqCfGuhvtAu3_"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":1,"moderationGuidelines":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:izp6eeJJEg9v5zcur"}],"url":null,"postedAt":"2023-01-23T04:01:12.815Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"commentCount":null,"voteCount":2,"baseScore":2,"extendedScore":null,"unlisted":false,"score":0.001970698405542385,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2023-01-23T04:01:12.815Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"CWxPBBctj39bqv2uC","location":"Philadelphia, PA, USA","googleLocation":{"address_components":[{"long_name":"Philadelphia","short_name":"Philadelphia","types":["locality","political"]},{"long_name":"Philadelphia County","short_name":"Philadelphia County","types":["administrative_area_level_2","political"]},{"long_name":"Pennsylvania","short_name":"PA","types":["administrative_area_level_1","political"]},{"long_name":"United States","short_name":"US","types":["country","political"]}],"adr_address":"<span class=\"locality\">Philadelphia<\/span>, <span class=\"region\">PA<\/span>, <span class=\"country-name\">USA<\/span>","formatted_address":"Philadelphia, PA, USA","geometry":{"location":{"lat":39.9525839,"lng":-75.1652215},"viewport":{"south":39.86700406742303,"west":-75.28029371735357,"north":40.13799186419682,"east":-74.95576291304663}},"icon":"https://maps.gstatic.com/mapfiles/place_api/icons/v1/png_71/geocode-71.png","icon_background_color":"#7B9EB0","icon_mask_base_uri":"https://maps.gstatic.com/mapfiles/place_api/icons/v2/generic_pinlet","name":"Philadelphia","photos":[{"height":700,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/117011274228240363350\">Patrick Trindade<\/a>"],"width":1280},{"height":285,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/110343381716301704895\">travel and events<\/a>"],"width":512},{"height":3024,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/103526580607590477819\">Cam Andrews<\/a>"],"width":4032},{"height":339,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/102989838164749710474\">Samuel Lim<\/a>"],"width":509},{"height":2160,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/105258312502759803427\">Alex Shevchenko<\/a>"],"width":3840},{"height":2544,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/101709309402118159319\">LBM<\/a>"],"width":1431},{"height":407,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/109862657745816505337\">stephen pollock<\/a>"],"width":720},{"height":1530,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/105814257563475985711\">Mark Henninger<\/a>"],"width":2720},{"height":3024,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/110129947554845275479\">Loc Antoine<\/a>"],"width":4032},{"height":1081,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/108252628278597712087\">Abdulrahman Ghummied<\/a>"],"width":1079}],"place_id":"ChIJ60u11Ni3xokRwVg-jNgU9Yk","reference":"ChIJ60u11Ni3xokRwVg-jNgU9Yk","types":["locality","political"],"url":"https://maps.google.com/?q=Philadelphia,+PA,+USA&ftid=0x89c6b7d8d4b54beb:0x89f514d88c3e58c1","utc_offset":-300,"vicinity":"Philadelphia","website":"http://www.phila.gov/","html_attributions":[],"utc_offset_minutes":-300},"onlineEvent":false,"globalEvent":true,"startTime":"2023-06-30T19:00:00.000Z","endTime":"2023-07-02T21:00:00.000Z","localStartTime":"2023-06-30T15:00:00.000Z","localEndTime":"2023-07-02T17:00:00.000Z","eventRegistrationLink":"https://www.eventbrite.com/e/the-rat-fest-tickets-387125692367","joinEventLink":"https://www.eventbrite.com/e/the-rat-fest-tickets-387125692367","facebookLink":null,"meetupLink":null,"website":"https://www.eventbrite.com/e/the-rat-fest-tickets-387125692367","contactInfo":"chipkin.logan@gmail.com","isEvent":true,"eventImageId":null,"eventType":"social","types":[],"groupId":null,"reviewedByUserId":"qgdGA4ZEyW7zNdK84","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"afBaseScore":0,"afExtendedScore":null,"afCommentCount":null,"afLastCommentedAt":"2023-01-22T23:13:55.817Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":false,"shortform":false,"onlyVisibleToLoggedIn":false,"reviewCount":null,"reviewVoteCount":null,"positiveReviewVoteCount":null,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"user":{"__ref":"User:CWxPBBctj39bqv2uC"},"coauthors":[],"slug":"philly-rat-fest","title":"Philly Rat Fest","draft":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null},"Revision:aPeJE8bSo6rAFoLqg_":{"_id":"aPeJE8bSo6rAFoLqg_","__typename":"Revision","htmlHighlight":"<p>Work done at <a href=\"https://www.serimats.org/\">SERI-MATS<\/a>, over the past two months, by Jessica Rumbelow and Matthew Watkins.<\/p><p>TL;DR<\/p><p>Anomalous tokens: a mysterious failure mode for GPT (which reliably insulted Matthew)<\/p><ul><li>We have found a set of anomalous tokens which result in a previously undocumented failure mode for GPT-2 and GPT-3 models. (The 'instruct' models are particularly deranged in this context, as&nbsp;<a href=\"https://www.lesswrong.com/users/janus-1\"><u>janus<\/u><\/a> has observed.)<\/li><li>Many of these tokens reliably break determinism in the OpenAI GPT-3 playground at temperature 0 (which theoretically shouldn't happen).<\/li><\/ul><p>Prompt generation: a new interpretability method for language models (which reliably finds prompts that result in a target completion). This is good for:<\/p><ul><li>eliciting knowledge<\/li><li>generating adversarial inputs<\/li><li>automating prompt search (e.g. for fine-tuning)<\/li><\/ul><p>In this post, we'll introduce the prototype of a new model-agnostic interpretability method for language models which reliably generates adversarial prompts that result in a target completion. We'll also demonstrate a previously undocumented failure mode for GPT-2 and GPT-3 language models, which results in bizarre completions (in some cases explicitly contrary to the purpose of the model), and present the results of our investigation into this phenomenon. Further detail can be found in a <a href=\"https://www.lesswrong.com/posts/Ya9LzwEbfaAMY8ABo/solidgoldmagikarp-ii-technical-details-and-more-recent\">follow-up post<\/a>.<\/p><figure class=\"image\"><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675551031/mirroredImages/aPeJE8bSo6rAFoLqg/bwyyp2bnwisvravpijzy.png\" srcset=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675551032/mirroredImages/aPeJE8bSo6rAFoLqg/iwlckuafb6w8trermitj.png 120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675551032/mirroredImages/aPeJE8bSo6rAFoLqg/qdsx2m4h65k3krnp13ru.png 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675551032/mirroredImages/aPeJE8bSo6rAFoLqg/zaxm5rngobykxypxszky.png 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675551032/mirroredImages/aPeJE8bSo6rAFoLqg/ovgdkrb4lk0v2ryebhfm.png 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675551031/mirroredImages/aPeJE8bSo6rAFoLqg/j8ked3h54ccggduc39bl.png 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675551031/mirroredImages/aPeJE8bSo6rAFoLqg/jou2ti715f7ezt76gqe0.png 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675551031/mirroredImages/aPeJE8bSo6rAFoLqg/ozjv6rdriyw6nigll7vx.png 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675551031/mirroredImages/aPeJE8bSo6rAFoLqg/l2mlr7oe3mletmmxbufu.png 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675551031/mirroredImages/aPeJE8bSo6rAFoLqg/u7wvoaqqizy1rq3ir7g5.png 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675551031/mirroredImages/aPeJE8bSo6rAFoLqg/ipduymkhhntbgvjerqda.png 1136w\"><figcaption>A rather unexpected prompt completion from the GPT-3 davinci-instruct-beta model.<\/figcaption><\/figure><h2>Prompt generation<\/h2><p>First up, prompt generation. An easy intuition for this is to think about feature visualisation for image classifiers (an excellent explanation <a href=\"https://distill.pub/2017/feature-visualization/\">here<\/a>, if you're unfamiliar with the concept).<\/p><figure class=\"image\"><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675551031/mirroredImages/aPeJE8bSo6rAFoLqg/ivf8pmmvfeg2evc9sdqo.png\" srcset=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675551034/mirroredImages/aPeJE8bSo6rAFoLqg/b59iwr7vvqst7aj80o0g.png 230w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675551034/mirroredImages/aPeJE8bSo6rAFoLqg/wg8khai6w2ez5ysgjw8v.png 460w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675551031/mirroredImages/aPeJE8bSo6rAFoLqg/m3fvxoojxixmmtg8z1u0.png 690w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675551031/mirroredImages/aPeJE8bSo6rAFoLqg/sgrwoxcuuzuzkexidfna.png 920w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675551031/mirroredImages/aPeJE8bSo6rAFoLqg/nv17qf5765wqdlihp5zp.png 1150w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675551031/mirroredImages/aPeJE8bSo6rAFoLqg/vvz4zsth8jjhbzmpbrv0.png 1380w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675551034/mirroredImages/aPeJE8bSo6rAFoLqg/sfxizsicclkhjihs3dv4.png 1610w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675551034/mirroredImages/aPeJE8bSo6rAFoLqg/mnj2ulnwaiqhyjxxjg7e.png 1840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675551034/mirroredImages/aPeJE8bSo6rAFoLqg/ajyjynyjcwqhxcqqbzrq.png 2070w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675551031/mirroredImages/aPeJE8bSo6rAFoLqg/ubxsdgcdphkgd9eztrfn.png 2210w\"><figcaption>Feature visualisation of VGG network by <a href=\"https://timsainburg.com/tensorflow-2-feature-visualization-visualizing-classes\">Tim Sainburg<\/a>.<\/figcaption><\/figure><p>We can study how a neural network represents concepts by taking some random input and using gradient descent to tweak it until it it maximises a particular activation. The image above shows the resulting inputs that maximise the output logits for the classes 'goldfish', 'monarch', 'tarantula' and 'flamingo'. This is pretty cool! We can see what VGG thinks is the <i>most<\/i> 'goldfish'-y thing in the world, and it's got scales and fins. Note though, that it isn't a picture of a single goldfish. We're not seeing the kind of input that VGG was trained on. We're seeing what VGG has learned. This is handy: if you wanted to sanity check your goldfish detector, and the feature visualisation showed just water, you'd know that the model hadn't actually learned to detect gold... <\/p>","wordCount":3533,"version":"1.10.17"},"Revision:aPeJE8bSo6rAFoLqg_moderationGuidelines":{"_id":"aPeJE8bSo6rAFoLqg_moderationGuidelines","__typename":"Revision","html":""},"Revision:YSSNFEnW6ugFhEE6m_description":{"_id":"YSSNFEnW6ugFhEE6m_description","__typename":"Revision","htmlHighlight":"<p><strong>Adversarial examples<\/strong> are situations that have unusual features that will cause an <a href=\"http://lesswrong.com/tag/ai\">AI<\/a> to make choices that seem obviously wrong to a human. For example, an image of a panda can be subtly manipulated so that an image classifier classifies it as a gibbon.<\/p>"},"Tag:YSSNFEnW6ugFhEE6m":{"_id":"YSSNFEnW6ugFhEE6m","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:YSSNFEnW6ugFhEE6m_description"},"userId":"mcKSiwq2TBrTMZS6X","name":"Adversarial Examples","slug":"adversarial-examples","core":false,"postCount":11,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-08-07T07:04:09.696Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:56yXXrcxRjrQs6z9R_description":{"_id":"56yXXrcxRjrQs6z9R_description","__typename":"Revision","htmlHighlight":"<p><strong>Transparency and interpretability<\/strong> is the ability for the decision processes and inner workings of AI and machine learning systems to be understood by humans or other outside observers.<\/p><p>Present-day machine learning systems are typically not very transparent or interpretable. You can use a model's output, but the model can't tell you why it made that output.  This makes it hard to determine the cause of biases in ML models.<\/p>"},"Tag:56yXXrcxRjrQs6z9R":{"_id":"56yXXrcxRjrQs6z9R","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:56yXXrcxRjrQs6z9R_description"},"userId":"DgsGzjyBXN8XSK22q","name":"Interpretability (ML & AI)","slug":"interpretability-ml-and-ai","core":false,"postCount":230,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-30T22:00:37.947Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:YYFBmLCzeFsyd27rd_description":{"_id":"YYFBmLCzeFsyd27rd_description","__typename":"Revision","htmlHighlight":"<p>The <strong>Stanford Existential Risks Initiative ML Alignment Theory Scholars<\/strong> program.<\/p><p><a href=\"https://www.serimats.org/\">https://www.serimats.org/<\/a><\/p>"},"Tag:YYFBmLCzeFsyd27rd":{"_id":"YYFBmLCzeFsyd27rd","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:YYFBmLCzeFsyd27rd_description"},"userId":"qgdGA4ZEyW7zNdK84","name":"SERI MATS","slug":"seri-mats","core":false,"postCount":95,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2022-07-18T17:39:10.815Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:KmgkrftQuX7jmjjp5_description":{"_id":"KmgkrftQuX7jmjjp5_description","__typename":"Revision","htmlHighlight":"<p><strong>Language Models<\/strong> are a class of <a href=\"https://www.lesswrong.com/tag/ai\">AI<\/a> trained on text, usually to predict the next word or a word which has been obscured. They have the ability to generate novel prose or code based on an initial prompt, which gives rise to a kind of natural language programming called prompt engineering. The most popular architecture for very large language models is called a <a href=\"https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)\">transformer<\/a>, which follows consistent <a href=\"https://www.lesswrong.com/tag/scaling-laws\">scaling laws<\/a> with respect to the size of the model being trained, meaning that a larger model trained with the same amount of compute will produce results which are better by a predictable amount (when measured by the 'perplexity', or how surprised the AI is by a test set of human-generated text).<\/p><h3>See also<\/h3><ul><li><a href=\"https://www.lesswrong.com/tag/gpt\">GPT<\/a> - A family of large language models created by <a href=\"https://www.lesswrong.com/tag/openai\">OpenAI<\/a><\/li><\/ul>"},"Tag:KmgkrftQuX7jmjjp5":{"_id":"KmgkrftQuX7jmjjp5","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:KmgkrftQuX7jmjjp5_description"},"userId":"Sp5wM4aRAhNERd4oY","name":"Language Models","slug":"language-models","core":false,"postCount":190,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2021-09-24T14:01:59.395Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:tQed6AxEYCgSpWfX4_biography":{"_id":"tQed6AxEYCgSpWfX4_biography","__typename":"Revision","version":"1.2.0","updateType":"minor","editedAt":"2023-02-05T20:50:52.458Z","userId":"grecHJcgkb3KW5wnM","html":"<p>AI interpretability researcher<\/p>","wordCount":3,"htmlHighlight":"<p>AI interpretability researcher<\/p>","plaintextDescription":"AI interpretability researcher"},"User:tQed6AxEYCgSpWfX4":{"_id":"tQed6AxEYCgSpWfX4","__typename":"User","biography":{"__ref":"Revision:tQed6AxEYCgSpWfX4_biography"},"profileImageId":null,"moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":null,"slug":"jessica-rumbelow","createdAt":"2022-07-12T10:18:48.820Z","username":"jessica-cooper","displayName":"Jessica Rumbelow","previousDisplayName":"Jessica Mary","fullName":"Jessica Rumbelow","karma":753,"afKarma":137,"deleted":null,"isAdmin":false,"htmlBio":"<p>AI interpretability researcher<\/p>","postCount":4,"commentCount":15,"sequenceCount":null,"afPostCount":null,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":null},"User:CnRCwDErJWYsrkMmh":{"_id":"CnRCwDErJWYsrkMmh","__typename":"User","slug":"mwatkins","createdAt":"2022-04-29T21:14:18.287Z","username":"mwatkins","displayName":"mwatkins","previousDisplayName":null,"fullName":null,"karma":651,"afKarma":null,"deleted":null,"isAdmin":false,"htmlBio":"","postCount":2,"commentCount":26,"sequenceCount":null,"afPostCount":null,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":null},"Post:aPeJE8bSo6rAFoLqg":{"_id":"aPeJE8bSo6rAFoLqg","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:aPeJE8bSo6rAFoLqg_"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":14,"moderationGuidelines":{"__ref":"Revision:aPeJE8bSo6rAFoLqg_moderationGuidelines"},"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:sYm3HiWcfZvrGu3ui"},{"__ref":"Tag:YSSNFEnW6ugFhEE6m"},{"__ref":"Tag:56yXXrcxRjrQs6z9R"},{"__ref":"Tag:YYFBmLCzeFsyd27rd"},{"__ref":"Tag:KmgkrftQuX7jmjjp5"}],"url":null,"postedAt":"2023-02-05T22:02:35.854Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2023-02-04T23:56:33.607Z","meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":[{"userId":"CnRCwDErJWYsrkMmh","confirmed":true,"requested":true}],"hasCoauthorPermission":true,"commentCount":150,"voteCount":302,"baseScore":578,"extendedScore":null,"unlisted":false,"score":2.371052867763278,"lastVisitedAt":"2023-02-05T08:16:05.080Z","isFuture":false,"isRead":true,"lastCommentedAt":"2023-02-10T00:53:48.426Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":"2023-02-09T05:40:08.779Z","commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"tQed6AxEYCgSpWfX4","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"qgdGA4ZEyW7zNdK84","suggestForCuratedUserIds":["EQNTWXLKMeWMp2FQS"],"suggestForCuratedUsernames":"Ben Pace","reviewForCuratedUserId":"qgdGA4ZEyW7zNdK84","authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"afBaseScore":139,"afExtendedScore":null,"afCommentCount":11,"afLastCommentedAt":"2023-02-07T18:44:19.557Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"reviewCount":null,"reviewVoteCount":null,"positiveReviewVoteCount":null,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"user":{"__ref":"User:tQed6AxEYCgSpWfX4"},"coauthors":[{"__ref":"User:CnRCwDErJWYsrkMmh"}],"slug":"solidgoldmagikarp-plus-prompt-generation","title":"SolidGoldMagikarp (plus, prompt generation)","draft":false,"hideCommentKarma":false,"af":true,"currentUserReviewVote":null},"Revision:Zp6wG5eQFLGWwcG6j_":{"_id":"Zp6wG5eQFLGWwcG6j_","__typename":"Revision","htmlHighlight":"<p>Writing down something Ive found myself repeating in different conversations:<\/p><p>If you're looking for ways to help with the whole <a href=\"https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities\"><u>the world looks pretty doomed<\/u><\/a> business, here's my advice:&nbsp;<strong>look around for places where we're all being total idiots.<\/strong><\/p><p>Look for places where everyone's fretting about a problem that some part of you thinks it could obviously just solve.<\/p><p>Look around for places where something seems incompetently run, or hopelessly inept, and where some part of you thinks you can do better.<\/p><p>Then do it better.<\/p><p>For a concrete example, consider Devansh. Devansh came to me last year and said something to the effect of,&nbsp; Hey, wait, it sounds like you think Eliezer does a sort of alignment-idea-generation that nobody else does, and he's limited here by his unusually low stamina, but I can think of a bunch of medical tests that you haven't run, are you an idiot or something?\" And I was like, \"Yes, definitely, please run them, do you need money\".<\/p><p>I'm not particularly hopeful there, but hell, its worth a shot! And, importantly, this is the sort of attitude that can lead people to actually trying things&nbsp;<i>at all<\/i>, rather than assuming that we live in a more&nbsp;<a href=\"https://equilibriabook.com/toc/\"><u>adequate world<\/u><\/a> where all the (seemingly) dumb obvious ideas have already been tried.<\/p><p>Or, this is basically my model of how Paul Christiano manages to have a research agenda that seems at least internally coherent to me. From my perspective, he's like, \"I dunno, man, I'm not sure I can solve this, but I also think it's not clear I can't, and there's a bunch of obvious stuff to try, that nobody else is even really looking at, so I'm trying it\". That's the sort of orientation to the world that I think can be productive.<\/p><p>Or the shard theory folks. I think their idea is&nbsp;<a href=\"https://www.lesswrong.com/s/v55BhXbpJuaExkpcD/p/Aet2mbnK7GDDfrEQu\"><u>basically unworkable<\/u><\/a>, but I appreciate the&nbsp;<i>mindset<\/i> they are applying to the alignment problem: something like, \"Wait, aren't y'all being idiots, it seems to me like I can just do X and then the thing will be aligned\".<\/p><p>I don't think we'll be saved by the shard theory folk; not everyone audaciously trying to save the world will succeed. But if someone&nbsp;<i>does<\/i> save us, I think theres a good chance that theyll go through similar What the hell, are you all idiots? phases, where they autonomously pursue a path that strikes them as obviously egregiously neglected, to see if it bears fruit. (Regardless of what I think.)<\/p><p>Contrast ... <\/p>","wordCount":1154,"version":"1.2.0"},"Revision:Zp6wG5eQFLGWwcG6j_moderationGuidelines":{"_id":"Zp6wG5eQFLGWwcG6j_moderationGuidelines","__typename":"Revision","html":""},"Revision:Zp6wG5eQFLGWwcG6j_customHighlight":{"_id":"Zp6wG5eQFLGWwcG6j_customHighlight","__typename":"Revision","html":""},"Revision:iP2X4jQNHMWHRNPne_description":{"_id":"iP2X4jQNHMWHRNPne_description","__typename":"Revision","htmlHighlight":"<html><head><\/head><body><p><strong>Motivations<\/strong> are the reasons why we think and do the things that we do. Related: <strong>Desire, Values<\/strong>. Many questions can asked about motivation such as: i) what does/could/should motivate people? ii) which stated motivations are true motivations for belief and behavior? iii) which motivations are <i>valid<\/i> vs <i>invalid<\/i>? iv) How does motivation even work?&nbsp;<\/p><p><i>Note: This tag is a work in progress<\/i><\/p><p>See also:<\/p><ul><li><a href=\"www.lesswrong.com/stub\">Inspirational<\/a><\/li><li>CEV<\/li><li>Utility Functions<\/li><li>Elephant in the Brain by Simler and Hanson<\/li><li>Signaling<\/li><li>Multi-Agent Theories of Mind<\/li><li><strong>Rationalization <\/strong>is the act of finding reasons to support a desired conclusion rather than reasoning in ways which reach the true conclusion.<\/li><li><strong>Motivated Cognition <\/strong>is when one's thinking does not purely follow processes for generating truth, and are instead influenced by desires/motivation to reach certain conclusion.<\/li><\/ul><h2>Motivation and Belief<\/h2><p>In the context of belief, a valid motivation for believing something might be having encountered Bayesian evidence for it; in contrast, simply wishing something were true is a poor motivation for believing and often results <i>motivated reasoning [link need].<\/i><\/p><p>The Litanies of Gendlin and Tarsky [links] are often invoked to elicit feels which motivate truth-seeking behaviors.<\/p><h2>Motivated Cognition, Confirmation Bias, Rationalization<\/h2><p>...<\/p><h2>Stated vs Actual Motivation<\/h2><p>It is no secret that often the reasons people give for their actions and beliefs are probably not the real ones driving their behavior. Is that your real objection? The work of Hanson....Signaling...<\/p><ul><li>Act of Charity<\/li><li>Player vs Character<\/li><\/ul><h2>The Cognitive Science of Motivation<\/h2><p>While most people can recognize the feeling of motivation, it is a much more complication question on how agents, particularly humans, implement <i>motivation.<\/i><\/p><p>In 20xx, Lukeprog wrote &lt;Neuroscience Review&gt;. Lengthy and thorough. Unknown uptodateness.<\/p><p>Related to the question of Motivation is subagents. Is one's overall self actually made up of subagents each with their own desires. Kaj Sotala explores this in his Multiagent Theories of Mind Sequences. CFAR techniques: Internal Double Crux are aimed harmonizing between the desires/motivations of different \"parts\" of oneself.<\/p><h2>Aligning Motivations<\/h2><ul><li>Overcoming akrasia...<\/li><\/ul><h2>Practical Techniques for Motivation<\/h2><ul><li>Propagating Urges<\/li><li>Mental Contrasting (external)<\/li><li>Propagating Urges<\/li><li>Internal Double Crux<\/li><\/ul><p>Habitual Productivity and Nate's Writing<\/p><p>Something to Protect<\/p><p>&nbsp;<\/p><p>See also Motivated Reasoning<\/p><\/body><\/html>..."},"Tag:iP2X4jQNHMWHRNPne":{"_id":"iP2X4jQNHMWHRNPne","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:iP2X4jQNHMWHRNPne_description"},"userId":"qgdGA4ZEyW7zNdK84","name":"Motivations","slug":"motivations","core":false,"postCount":165,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-08T00:06:01.955Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:xSfc2APSi8WzFxp7i_biography":{"_id":"xSfc2APSi8WzFxp7i_biography","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2022-11-24T14:06:34.887Z","userId":"xSfc2APSi8WzFxp7i","html":"","wordCount":0,"htmlHighlight":"","plaintextDescription":null},"User:xSfc2APSi8WzFxp7i":{"_id":"xSfc2APSi8WzFxp7i","__typename":"User","biography":{"__ref":"Revision:xSfc2APSi8WzFxp7i_biography"},"profileImageId":null,"moderationStyle":"reign-of-terror","bannedUserIds":["CpPz4596hmk9Pk8Jh"],"moderatorAssistance":true,"slug":"so8res","createdAt":"2012-01-10T05:50:18.713Z","username":"So8res","displayName":"So8res","previousDisplayName":null,"fullName":"Nate Soares","karma":10254,"afKarma":1092,"deleted":false,"isAdmin":false,"htmlBio":"","postCount":125,"commentCount":413,"sequenceCount":2,"afPostCount":24,"afCommentCount":15,"spamRiskScore":1,"tagRevisionCount":0},"Post:Zp6wG5eQFLGWwcG6j":{"_id":"Zp6wG5eQFLGWwcG6j","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:Zp6wG5eQFLGWwcG6j_"},"fmCrosspost":{"isCrosspost":true,"hostedHere":true,"foreignPostId":"SsMYCwugcpotfiCT6"},"readTimeMinutes":5,"moderationGuidelines":{"__ref":"Revision:Zp6wG5eQFLGWwcG6j_moderationGuidelines"},"customHighlight":{"__ref":"Revision:Zp6wG5eQFLGWwcG6j_customHighlight"},"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:Ng8Gice9KNkncxqcj"},{"__ref":"Tag:iP2X4jQNHMWHRNPne"},{"__ref":"Tag:xexCWMyds6QLWognu"}],"url":null,"postedAt":"2023-02-02T00:27:55.687Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2023-02-02T00:28:34.435Z","meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"commentCount":53,"voteCount":150,"baseScore":328,"extendedScore":null,"unlisted":false,"score":0.7223344727224016,"lastVisitedAt":"2023-02-02T11:06:29.159Z","isFuture":false,"isRead":true,"lastCommentedAt":"2023-02-09T22:01:32.342Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":"2023-02-06T00:44:41.211Z","commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"xSfc2APSi8WzFxp7i","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"2aoRX3ookcCozcb3m","suggestForCuratedUserIds":["r38pkCm7wF4M44MDQ","7w7hLkTTQLuPSAWTT"],"suggestForCuratedUsernames":"Raemon, Elizabeth","reviewForCuratedUserId":"r38pkCm7wF4M44MDQ","authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"afBaseScore":101,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":"2023-02-02T00:27:55.687Z","afSticky":false,"hideAuthor":false,"moderationStyle":"reign-of-terror","submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"reviewCount":null,"reviewVoteCount":null,"positiveReviewVoteCount":null,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"user":{"__ref":"User:xSfc2APSi8WzFxp7i"},"coauthors":[],"slug":"focus-on-the-places-where-you-feel-shocked-everyone-s","title":"Focus on the places where you feel shocked everyone's dropping the ball","draft":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null},"Revision:XPv4sYrKnPzeJASuk_":{"_id":"XPv4sYrKnPzeJASuk_","__typename":"Revision","htmlHighlight":"<h2><strong>Introduction<\/strong><\/h2><p>This post is meant to be a linkable resource. Its core is a <a href=\"https://www.lesswrong.com/posts/XPv4sYrKnPzeJASuk/basics-of-rationalist-discourse-1#Guidelines__in_brief_\">short list of guidelines<\/a> (you can link directly to the list) that are intended to be fairly straightforward and uncontroversial, for the purpose of nurturing and strengthening a culture of clear thinking, clear communication, and collaborative truth-seeking.<\/p><blockquote><p>\"Alas,\" said Dumbledore, \"we all know that what <i>should be<\/i>, and what <i>is<\/i>, are two different things. &nbsp;Thank you for keeping this in mind.\"<\/p><\/blockquote><p>There is also (for those who want to read more than the simple list) substantial expansion/clarification of each specific guideline, along with justification for the overall philosophy behind the set.<\/p><hr><h2><strong>Prelude: On Shorthand<\/strong><\/h2><p>Once someone has a deep, rich understanding of a complex topic, they are often able to refer to that topic with short, simple sentences that correctly convey the intended meaning to other people with similar context and expertise.<\/p><p>However, those same short, simple sentences are often <i>dangerously misleading,<\/i> in the hands of a novice who lacks the proper background. &nbsp;Dangerous precisely <i>because<\/i> they seem straightforward and comprehensible, and thus the novice will confidently extrapolate outward from them in what feel like perfectly reasonable ways, unaware the whole time that the concept in their head bears little or no resemblance to the concept that lives in the expert's head.<\/p><p>Good shorthand <i>in the hands of an experienced user<\/i> need only be an accurate fit for the already-existing concept it refers toit doesn't need the additional property of being an unmistakeable <i>non<\/i>-fit for other nearby attractors. &nbsp;It doesn't need to contain complexity or nuanceit just needs to remind the listener of the complexity already contained in their mental model. &nbsp;It's doing its job if it <i>efficiently evokes<\/i> the understanding that already exists, independent of itself.<\/p><p>This is important, because <strong>what follows this introduction is a list of short, simple sentences comprising the basics of rationalist discourse<\/strong>. &nbsp;Each of those sentences is a solid fit for the more-complicated concept it's gesturing at, <i>provided you already understand that concept. &nbsp;<\/i>The short sentences are mnemonics, reminders, hyperlinks.<\/p><p>They are <i>not<\/i> sufficient, on their own, to reliably cause a beginner to construct the proper concepts from the ground up, and they do <i>not,<\/i> by themselves, rule out all likely misunde... <\/p>","wordCount":10788,"version":"1.11.13"},"Revision:XPv4sYrKnPzeJASuk_moderationGuidelines":{"_id":"XPv4sYrKnPzeJASuk_moderationGuidelines","__typename":"Revision","html":""},"Revision:AADZcNS24mmSfPp2w_description":{"_id":"AADZcNS24mmSfPp2w_description","__typename":"Revision","htmlHighlight":"<p>A <strong>Communication Culture <\/strong>is a set of norms, expectations, and assumptions that a group of people adopts around communication. It is probable that some Communication Cultures are objectively better than others, but is definite that difficult clashes occur when people operating under different cultures interact.<\/p><p>Awareness of Communication Cultures is therefore key to getting along with others not perfectly sharing our background and preferences.<\/p><p>Notable Communication Cultures (these are usually contrasted along some dimension) are: <a href=\"https://www.lessestwrong.com/posts/vs3kzjLhbdKsndnBy/ask-and-guess\">Ask vs Guess<\/a> (and <a href=\"https://www.lessestwrong.com/posts/rEBXN3x6kXgD4pLxs/tell-culture\">Tell<\/a>/<a href=\"https://malcolmocean.com/2015/06/reveal-culture/\">Reveal<\/a>); <a href=\"https://www.lessestwrong.com/posts/LuXb6CZG4x7pDRBP8/wait-vs-interrupt-culture\">Wait vs Interrupt<\/a>; and <a href=\"https://www.lessestwrong.com/posts/ExssKjAaXEEYcnzPd/conversational-cultures-combat-vs-nurture-v2\">Combat vs Nurture<\/a>.<\/p><p>See also: <a href=\"https://www.lesswrong.com/tag/simulacrum-levels\">Simulacrum Levels<\/a><\/p><p><i>Tag Status: C-Class<\/i><\/p>"},"Tag:AADZcNS24mmSfPp2w":{"_id":"AADZcNS24mmSfPp2w","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:AADZcNS24mmSfPp2w_description"},"userId":"r38pkCm7wF4M44MDQ","name":"Communication Cultures","slug":"communication-cultures","core":null,"postCount":86,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":null,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-04T17:06:26.479Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:FoKb35gJijkSFYeXa_biography":{"_id":"FoKb35gJijkSFYeXa_biography","__typename":"Revision","version":"1.2.0","updateType":"minor","editedAt":"2023-02-08T06:26:27.923Z","userId":"FoKb35gJijkSFYeXa","html":"","wordCount":0,"htmlHighlight":"","plaintextDescription":null},"User:FoKb35gJijkSFYeXa":{"_id":"FoKb35gJijkSFYeXa","__typename":"User","biography":{"__ref":"Revision:FoKb35gJijkSFYeXa_biography"},"profileImageId":null,"moderationStyle":"norm-enforcing","bannedUserIds":["mPipmBTniuABY5PQy","g8JkZfL8PTqAefpvx","pnFbJAtNHGDK8PHQx","mvf4xdfcGzPN8PsXM"],"moderatorAssistance":true,"slug":"duncan_sabien","createdAt":"2015-12-01T05:18:10.610Z","username":"Duncan_Sabien","displayName":"Duncan_Sabien","previousDisplayName":null,"fullName":null,"karma":9562,"afKarma":0,"deleted":false,"isAdmin":false,"htmlBio":"","postCount":36,"commentCount":989,"sequenceCount":1,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":1},"Post:XPv4sYrKnPzeJASuk":{"_id":"XPv4sYrKnPzeJASuk","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:XPv4sYrKnPzeJASuk_"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":43,"moderationGuidelines":{"__ref":"Revision:XPv4sYrKnPzeJASuk_moderationGuidelines"},"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:Ng8Gice9KNkncxqcj"},{"__ref":"Tag:AADZcNS24mmSfPp2w"},{"__ref":"Tag:izp6eeJJEg9v5zcur"}],"url":null,"postedAt":"2023-01-27T02:40:52.739Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2023-01-27T06:27:10.554Z","meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"commentCount":173,"voteCount":132,"baseScore":213,"extendedScore":null,"unlisted":false,"score":0.2635738382245058,"lastVisitedAt":"2023-01-27T09:14:01.921Z","isFuture":false,"isRead":true,"lastCommentedAt":"2023-02-09T03:14:51.442Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":"2023-02-02T17:56:19.729Z","commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"FoKb35gJijkSFYeXa","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"r38pkCm7wF4M44MDQ","suggestForCuratedUserIds":["qgdGA4ZEyW7zNdK84","r38pkCm7wF4M44MDQ"],"suggestForCuratedUsernames":"Ruby, Raemon","reviewForCuratedUserId":"r38pkCm7wF4M44MDQ","authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"afBaseScore":41,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":"2023-01-27T02:40:52.739Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"reviewCount":null,"reviewVoteCount":null,"positiveReviewVoteCount":null,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"user":{"__ref":"User:FoKb35gJijkSFYeXa"},"coauthors":[],"slug":"basics-of-rationalist-discourse-1","title":"Basics of Rationalist Discourse","draft":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null},"Sequence:fxynfGCSHpY4FmBZy":{"_id":"fxynfGCSHpY4FmBZy","__typename":"Sequence","title":"Science and Rationality","gridImageId":"sequencesgrid/qynhzqukuonidzl0c0kp","canonicalCollectionSlug":"rationality"},"Revision:ZxR8P8hBFQ9kC8wMy_":{"_id":"ZxR8P8hBFQ9kC8wMy_","__typename":"Revision","htmlHighlight":"<p>This time there were no robes, no hoods, no masks.&nbsp; Students were expected to become friends, and allies.&nbsp; And everyone knew why you were in the classroom.&nbsp; It would have been pointless to pretend you weren't in the Conspiracy.<\/p><p><span>Their <em>sensei <\/em>was Jeffreyssai, who might have been the best of his era, in his era.&nbsp; His students were either the most promising learners, or those whom the <em>beisutsukai<\/em><span style=\"font-style: normal;\"> saw political advantage in molding.<\/span><\/span><\/p>\n<p style=\"font-style: normal;\"><span>Brennan fell into the latter category, and knew it.&nbsp; Nor had he hesitated to use his Mistress's name to open doors.&nbsp; You used every avenue available to you, in seeking knowledge; that was respected here.<br /><\/span><\/p><p><span>\"&mdash;for over thirty years,\" Jeffreyssai said.&nbsp; \"Not one of them saw it; not Einstein, not Schr&ouml;dinger, not even von Neumann.\"&nbsp; He turned away from his sketcher, and toward the classroom.&nbsp; \"I pose to you to the question:&nbsp; How did they fail?\"<\/span><\/p><p><span>The students exchanged quick glances, a calculus of mutual risk between the wary and the merely baffled.&nbsp; Jeffreyssai was known to play games.<\/span><\/p><p><a id=\"more\"><\/a><\/p><p><span>Finally Hiriwa-called-the-Black leaned forward, jangling slightly as her equation-carved bracelets shifted on her ankles.&nbsp; \"By your years given, <em>sensei,<\/em><span style=\"font-style: normal;\">&nbsp;<\/span>this was two hundred and fifty years after Newton.&nbsp; Surely, the scientists of that era must have grokked the concept of a universal law.\"<\/span><\/p><p><span>\"Knowing the universal law of gravity,\" said the student Taji, from a nearby seat, \"is not the same as understanding the concept <em>of<\/em> a universal law.\" He was one of the promising ones, as was Hiriwa.<\/span><\/p><p><span>Hiriwa frowned.&nbsp; \"No... it was said that Newton had been praised <em>for<\/em><span style=\"font-style: normal;\"> discovering the first universal.&nbsp; Even in his own era.&nbsp; So it was known.\"&nbsp; Hiriwa paused.&nbsp; \"But Newton himself would have been gone.&nbsp; <\/span>Was there a <em>religious<\/em><span style=\"font-style: normal;\"> injunction against proposing further universals?&nbsp; Did they refrain out of respect for Newton, or were they waiting for his <\/span><em>ghost<\/em><span style=\"font-style: normal;\"> to speak?&nbsp; I am not clear on how Eld science was motivated&mdash;\"<\/span><\/span><\/p><p><span><span style=\"font-style: normal;\">\"No,\" murmured Taji, a laugh in his voice, \"you really, <\/span><em>really<\/em><span style=\"font-style: normal;\"> aren't.\"<\/span><\/span><\/p>\n<p style=\"font-style: normal;\"><span>Jeffreyssai's expression was kindly.&nbsp; \"Hiriwa, it wasn't religion, and it wasn't lead in the drinking water, and they didn't all have Alzheimers, and they weren't sitting around all day reading webcomics.&nbsp; Forget the catalogue of horrors out of ancient times. Just think in t<\/span>... <\/p>","wordCount":2732,"version":"1.0.0"},"Revision:etDohXtBrXd8WqCtR_description":{"_id":"etDohXtBrXd8WqCtR_description","__typename":"Revision","htmlHighlight":"<p><strong>Fiction<\/strong> isn't literal truth, but when done well it captures truths and intuitions that are difficult to explain directly. (Its also damn fun to read.)<\/p><blockquote><p>Nonfiction conveys <i>knowledge,<\/i> fiction conveys <i>experience.<\/i> - Eliezer Yudkowsky&nbsp;<\/p><\/blockquote><p>Eliezer Yudkowsky helped kickstart the genre of <a href=\"https://www.lesswrong.com/posts/q79vYjHAE9KHcAjSs/rationalist-fiction\"><i>rationalist fiction<\/i><\/a>, which is about characters who solve the problems in their world by thinking, in a way where the reader <i>could figure it out too<\/i>. Not where the genius character explains it afterward like Sherlock Holmes or Artemis Fowl, but where the problem is fair and you couldve figured it out first. Eliezer has written about this in his short online book <a href=\"https://yudkowsky.tumblr.com/writing\"><u>The Abridged Guide to Intelligent Characters<\/u><\/a>.<\/p><p>Other fiction on the site is in the spirit of hard science fiction, and often involves taking the laws of a universe or the rules of a system to their extreme conclusions, and munchkining your way to become god (or something similar). They also share much of the parts of sci-fi that engage with difficult moral quandaries.<\/p><p>Fiction on this site also tends to have puns. Im so sorry.<\/p><p>Much more fiction can be found at <a href=\"https://www.reddit.com/r/rational\">r/Rational<\/a>, which is a subreddit devoted to rationalist fiction.<\/p><p>This is a tag for works of fiction, not for analysis or discussion of literature. For that see <a href=\"https://www.lesswrong.com/tag/fiction-topic\">Fiction (topic)<\/a>.<\/p><h2>Fiction Sequences<\/h2><ul><li><a href=\"https://www.lesswrong.com/hpmor\">HPMOR<\/a><\/li><li><a href=\"https://www.lesswrong.com/s/qWoFR4ytMpQ5vw3FT\">Three Worlds Collide<\/a><\/li><li><a href=\"https://www.lesswrong.com/s/LAop879LCQWrM5YnE\">The Bayesian Conspiracy<\/a><\/li><li><a href=\"https://www.lesswrong.com/s/4C33PKt2cQdA7oyfJ\">Murphy's Quest<\/a><\/li><li><a href=\"https://www.lesswrong.com/s/TF77XsD5PbucbJsG3\">Luna Lovegood and the Chamber of Secrets<\/a><\/li><li><a href=\"https://www.lesswrong.com/s/TjdhvTSptCYakw3Lc\">Bayeswatch<\/a><\/li><li><a href=\"https://www.lesswrong.com/s/qMtriMPLdriNkAfSJ\">Short stories<\/a> by lsusr<\/li><\/ul><h2>External links<\/h2><ul><li><a href=\"https://www.reddit.com/r/rational/\">/r/rational/<\/a> on <a href=\"https://lessestwrong.com/tag/reddit\">Reddit<\/a><\/li><li><a href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/RationalFic\">RationalFic<\/a> on TV Tropes<\/li><li><a href=\"http://yudkowsky.tumblr.com/writing\">Eliezer Yudkowsky's guide to writing intelligent characters<\/a><\/li><li><a href=\"http://rationalreads.com/\">rationalreads.com<\/a><\/li><\/ul>"},"Tag:etDohXtBrXd8WqCtR":{"_id":"etDohXtBrXd8WqCtR","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:etDohXtBrXd8WqCtR_description"},"userId":"qgdGA4ZEyW7zNdK84","name":"Fiction","slug":"fiction","core":null,"postCount":465,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":null,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-13T16:01:23.724Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:ZpG9rheyAkgCoEQea_description":{"_id":"ZpG9rheyAkgCoEQea_description","__typename":"Revision","htmlHighlight":"<p><strong>Practice and Philosophy of Science<\/strong> is for posts that discuss how science is done or should be done; examples include <a href=\"https://www.lesswrong.com/posts/tSemJckYr29Gnxod2/building-intuitions-on-non-empirical-arguments-in-science\">Building Intuitions on Non-Empirical Arguments in Science<\/a> and the <a href=\"https://www.lesswrong.com/s/fxynfGCSHpY4FmBZy\">Science and Rationality sequence<\/a>. (It is not for posts that simply report on a new scientific result.)<\/p>"},"Tag:ZpG9rheyAkgCoEQea":{"_id":"ZpG9rheyAkgCoEQea","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:ZpG9rheyAkgCoEQea_description"},"userId":"qxJ28GN72aiJu96iF","name":"Practice & Philosophy of Science","slug":"practice-and-philosophy-of-science","core":false,"postCount":189,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-10T11:53:33.735Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Tag:m4zvJHAiGBTjc5ZFt":{"_id":"m4zvJHAiGBTjc5ZFt","__typename":"Tag","parentTag":null,"subTags":[],"description":null,"userId":"nLbwLhBaQeG6tCNDN","name":"Babble and Prune","slug":"babble-and-prune","core":false,"postCount":29,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-27T22:17:52.483Z","wikiOnly":false,"deleted":false,"isSubforum":null},"User:nmk3nLpQE89dMRzzN":{"_id":"nmk3nLpQE89dMRzzN","__typename":"User","biography":null,"profileImageId":null,"moderationStyle":"reign-of-terror","bannedUserIds":["sBWszXPhPsNNemv4Q","YBHSPmZEfyyY2E2au"],"moderatorAssistance":true,"slug":"eliezer_yudkowsky","createdAt":"2009-02-23T21:58:56.739Z","username":"Eliezer_Yudkowsky","displayName":"Eliezer Yudkowsky","previousDisplayName":null,"fullName":null,"karma":127891,"afKarma":1639,"deleted":false,"isAdmin":false,"htmlBio":"","postCount":943,"commentCount":7516,"sequenceCount":37,"afPostCount":16,"afCommentCount":96,"spamRiskScore":1,"tagRevisionCount":324},"Post:ZxR8P8hBFQ9kC8wMy":{"_id":"ZxR8P8hBFQ9kC8wMy","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:ZxR8P8hBFQ9kC8wMy_"},"fmCrosspost":null,"readTimeMinutes":11,"moderationGuidelines":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:etDohXtBrXd8WqCtR"},{"__ref":"Tag:ZpG9rheyAkgCoEQea"},{"__ref":"Tag:m4zvJHAiGBTjc5ZFt"}],"url":null,"postedAt":"2008-05-12T10:32:06.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2018-01-30T00:32:03.501Z","meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":null,"commentCount":58,"voteCount":85,"baseScore":95,"extendedScore":null,"unlisted":false,"score":0.000126,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2022-12-13T20:53:23.159Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"rationality","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"nmk3nLpQE89dMRzzN","location":null,"googleLocation":null,"onlineEvent":null,"globalEvent":null,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":10,"afExtendedScore":null,"afCommentCount":null,"afLastCommentedAt":"2008-05-12T10:32:06.000Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":null,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":0,"reviewCount2019":null,"user":{"__ref":"User:nmk3nLpQE89dMRzzN"},"coauthors":[],"slug":"the-failures-of-eld-science","title":"The Failures of Eld Science","draft":false,"hideCommentKarma":null,"af":false,"currentUserReviewVote":null},"Sequence:pFatcKW3JJhTSxqAF":{"_id":"pFatcKW3JJhTSxqAF","__typename":"Sequence","title":"Replacing Guilt","gridImageId":"sequencesgrid/m0lpxsua2jmtwbmwlttp","canonicalCollectionSlug":null},"Revision:HqQ3CpMqQyaaLLKew_":{"_id":"HqQ3CpMqQyaaLLKew_","__typename":"Revision","htmlHighlight":"<p>My last few posts have been aimed at addressing what I call the \"listless guilt,\" the vague sense of guilt that stems from not doing anything in particular. I said:<\/p><blockquote><p><i>The listless guilt is a guilt about not doing anything. To remove it, we must first turn it into a guilt about not doing something in particular.<\/i><\/p><\/blockquote><p>If you didn't have a listless guilt, or if you did and the last few posts worked for you, then you may now find yourself wrestling with a very <i>pointed<\/i> sort of guilt that stems from not doing <i>particular<\/i> things. These next few posts will address the pointed guilts.<\/p><hr><p>One of the most common sources of pointed guilt that I encounter stems from neglected obligations. Imagine someone who thinks they should stop watching Netflix (because they <a href=\"http://mindingourway.com/caring-about-some/\">care about something important<\/a>, and watching Netflix isn't helping), but who can't seem to stop. Or imagine someone who thinks they should be spending more time working on their thesis, but can't make themselves do it. Or imagine someone who thinks they should be smarter, and that their homework shouldn't be taking them this long, and who feels worse and worse as they work. In each case, the pattern is the same: the subject thinks there's something they should be doing (or some way they should be), and they're not doing it (or aren't being it), and so they feel really guilty.<\/p><p>I claim that the word \"should\" is causing damage here.<\/p><p>In fact, as far as I can tell, the way that most people use the word \"should,\" most of the time, is harmful. People seem to use it to put themselves in direct and unnecessary conflict with themselves.<\/p><p>For example, imagine the person who wakes up feeling a bit sick. They may well say to themselves, \"ugh, I should go to the pharmacy and pick up medication before work.\" Now picking up meds feels like an obligation: if they don't get meds, then that's a little bit of evidence that they're incompetent, or akrasiatic, or bad. Now they <i>must<\/i> go get meds, if they want to be a competent person. In the lingo of <a href=\"http://rationality.org/\">CFAR<\/a>, this \"should\" is the exact opposite of an urge-propagation: it disconnects the reason from the task, it abolishes the \"why\". The person feeling sick now feels like they have an obligation to pick up medication, and so if they do it, they do it grudgingly, resenting the situation. (And if they don't, then they've failed, and they're at risk of <a href=\"http://mindingourway.com/failing-with-abandon/\">failing with abandon<\/a>.)<\/p><p>Now imagine they say this, instead: \"u... <\/p>","wordCount":1669,"version":"1.1.0"},"Revision:HqQ3CpMqQyaaLLKew_moderationGuidelines":{"_id":"HqQ3CpMqQyaaLLKew_moderationGuidelines","__typename":"Revision","html":""},"Revision:HqQ3CpMqQyaaLLKew_customHighlight":{"_id":"HqQ3CpMqQyaaLLKew_customHighlight","__typename":"Revision","html":""},"Post:HqQ3CpMqQyaaLLKew":{"_id":"HqQ3CpMqQyaaLLKew","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:HqQ3CpMqQyaaLLKew_"},"fmCrosspost":null,"readTimeMinutes":7,"moderationGuidelines":{"__ref":"Revision:HqQ3CpMqQyaaLLKew_moderationGuidelines"},"customHighlight":{"__ref":"Revision:HqQ3CpMqQyaaLLKew_customHighlight"},"lastPromotedComment":null,"bestAnswer":null,"tags":[],"url":"https://mindingourway.com/should-considered-harmful/","postedAt":"2015-05-25T03:00:00.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2022-03-03T18:10:06.906Z","meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":null,"commentCount":1,"voteCount":7,"baseScore":15,"extendedScore":null,"unlisted":false,"score":0.000043,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2022-08-26T22:06:09.716Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"xSfc2APSi8WzFxp7i","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"qgdGA4ZEyW7zNdK84","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":3,"afExtendedScore":null,"afCommentCount":null,"afLastCommentedAt":"2022-03-03T18:03:48.345Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"reviewCount":null,"reviewVoteCount":null,"positiveReviewVoteCount":null,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"user":{"__ref":"User:xSfc2APSi8WzFxp7i"},"coauthors":[],"slug":"should-considered-harmful","title":"\"Should\" considered harmful","draft":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null},"Sequence:PKKsrXtuptWzaKCjr":{"_id":"PKKsrXtuptWzaKCjr","__typename":"Sequence","title":"Alignment & Agency","gridImageId":"sequencesgrid/epcucjpxxhayxn91buxy","canonicalCollectionSlug":"bestoflesswrong"},"Revision:znfkdCoHMANwqc2WE_":{"_id":"znfkdCoHMANwqc2WE_","__typename":"Revision","htmlHighlight":"<p><em>This work was supported by OAK, a monastic community in the Berkeley hills. This document could not have been written without the daily love of living in this beautiful community. The work involved in writing this cannot be separated from the sitting, chanting, cooking, cleaning, crying, correcting, fundraising, listening, laughing, and teaching of the whole community.<\/em><\/p>\n<hr>\n<p>What is optimization? What is the relationship between a computational optimization process  say, a computer program solving an optimization problem  and a physical optimization process  say, a team of humans building a house?<\/p><p>We propose the concept of an optimizing system as a physically closed system containing both that which is being optimized and that which is doing the optimizing, and defined by a tendency to evolve from a broad basin of attraction towards a small set of target configurations despite perturbations to the system. We compare our definition to that proposed by Yudkowsky, and place our work in the context of work by Demski and Garrabrants <em>Embedded Agency<\/em>, and Drexlers <em>Comprehensive AI Services<\/em>. We show that our definition resolves difficult cases proposed by Daniel Filan. We work through numerous examples of biological, computational, and simple physical systems showing how our definition relates to each.<\/p>\n<h2>Introduction<\/h2>\n<p>In the field of computer science, an optimization algorithm is a computer program that outputs the solution, or an approximation thereof, to an optimization problem. An optimization problem consists of an objective function to be maximized or minimized, and a feasible region within which to search for a solution. For example we might take the objective function <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"(x^2 - 2)^2\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(<\/span><\/span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x<\/span><\/span><\/span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2<\/span><\/span><\/span><\/span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\"><\/span><\/span><span class=\"mjx-mn MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2<\/span><\/span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)<\/span><\/span><\/span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2<\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span> as a minimization problem and the whole real number line as the feasible region. The solution then would be <span class=\"mjpage\"><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"x=\\sqrt{2}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x<\/span><\/span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=<\/span><\/span><span class=\"mjx-msqrt MJXc-space3\"><span class=\"mjx-box\" style=\"padding-top: 0.045em;\"><span class=\"mjx-surd\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.519em; padding-bottom: 0.519em;\"><\/span><\/span><span class=\"mjx-box\" style=\"padding-top: 0.13em; border-top: 1px solid;\"><span class=\"mjx-mrow\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2<\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span> and a working optimization algorithm for this problem is one that outputs a close approximation to this value.<\/p><p>In the field of operations research and engineering more broadly, optimization involves improving some process or physical artifact so that it is fit for a certain purpose or fulfills some set of requirements. For example, we might choose to measure a nail factory by the rate at which it outputs nails, relative to the cost of production inputs. We can view this as a kind of objective function, with the factory as the object of optimization just as the variable x was the ob... <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n<\/style><\/p>","wordCount":8027,"version":"1.2.0"},"Revision:ac84EpK6mZbPLzmqj_description":{"_id":"ac84EpK6mZbPLzmqj_description","__typename":"Revision","htmlHighlight":"<p><strong>General Intelligence<\/strong> or <strong>Universal Intelligence<\/strong> is the ability to efficiently achieve goals in a wide range of domains.&nbsp;<\/p><p>This tag is specifically for discussing intelligence in the broad sense: for discussion of IQ testing and psychometric intelligence, see <a href=\"https://www.lesswrong.com/tag/iq-g-factor\">IQ / g-factor<\/a>; for discussion about e.g. specific results in artificial intelligence, see <a href=\"https://www.lesswrong.com/tag/ai\">AI<\/a>. These tags may overlap with this one to the extent that they discuss the nature of general intelligence.<\/p><p>Examples of posts that fall under this tag include <a href=\"https://www.lesswrong.com/posts/aiQabnugDhcrFtr9n/the-power-of-intelligence\">The Power of Intelligence<\/a>, <a href=\"https://www.lesswrong.com/posts/Q4hLMDrFd8fbteeZ8/measuring-optimization-power\">Measuring Optimization Power<\/a>, <a href=\"https://www.lesswrong.com/posts/XPErvb8m9FapXCjhA/adaptation-executers-not-fitness-maximizers\">Adaption-Executers not Fitness Maximizers<\/a>, <a href=\"https://www.lesswrong.com/posts/FbQ9Y9pBif5xZ7w2f/distinctions-in-types-of-thought\">Distinctions in Types of Thought<\/a>, <a href=\"https://www.lesswrong.com/posts/GMqZ2ofMnxwhoa7fD/the-octopus-the-dolphin-and-us-a-great-filter-tale\">The Octopus, the Dolphin and Us: a Great Filter tale<\/a>.<\/p><p>On the difference between psychometric intelligence (IQ) and general intelligence:<\/p><blockquote><p>But the word intelligence commonly evokes pictures of the starving professor with an IQ of 160 and the billionaire CEO with an IQ of merely 120. Indeed there are differences of individual ability apart from book smarts which contribute to relative success in the human world: enthusiasm, social skills, education, musical talent, rationality. Note that each factor I listed is cognitive. Social skills reside in the brain, not the liver. And jokes aside, you will not find many CEOs, nor yet professors of academia, who are chimpanzees. You will not find many acclaimed rationalists, nor artists, nor poets, nor leaders, nor engineers, nor skilled networkers, nor martial artists, nor musical composers who are mice. Intelligence is the foundation of human power, the strength that fuels our other arts.<\/p><\/blockquote><blockquote><p>-- Eliezer Yudkowsky, <a href=\"https://intelligence.org/files/AIPosNegFactor.pdf\">Artificial Intelligence as a Positive and Negative Factor in Global Risk<\/a><\/p><\/blockquote><h2>Definitions of General Intelligence<\/h2><p>After reviewing extensive literature on the subject, Legg and Hutter<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefosnb04qur8\"><sup><a href=\"#fnosnb04qur8\">[1]<\/a><\/sup><\/span>&nbsp;summarizes the many possible valuable definitions in the informal statement Intelligence measures an agents ability to achieve goals in a wide range of environments. They then show this definition can be mathematically formalized given reasonable mathematical definitions of its terms. They use <a href=\"https://lessestwrong.com/tag/solomonoff-induction\">Solomonoff induction<\/a> - a formalization of <a href=\"https://lessestwrong.com/tag/occam-s-razor\">Occam's razor<\/a> - to construct an <a href=\"https://lessestwrong.com/tag/aixi\">universal artificial intelligence<\/a> with a embedded <a href=\"https://lessestwrong.com/tag/utility-functions\">utility function<\/a> which assigns less <a href=\"https://lessestwrong.com/tag/expected-utility\">utility<\/a> to those actions based on theories with higher <a href=\"https://wiki.lesswrong.com/wiki/Kolmogorov_complexity\">complexity<\/a>. They argue this final formalization is a valid, meaningful, informative, general, u... <\/p>"},"Tag:ac84EpK6mZbPLzmqj":{"_id":"ac84EpK6mZbPLzmqj","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:ac84EpK6mZbPLzmqj_description"},"userId":"qxJ28GN72aiJu96iF","name":"General Intelligence","slug":"general-intelligence","core":false,"postCount":91,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-12T10:37:24.800Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:nvKzwpiranwy29HFJ_description":{"_id":"nvKzwpiranwy29HFJ_description","__typename":"Revision","htmlHighlight":"<p>An <strong>optimization process<\/strong> is any kind of process that systematically comes up with solutions that are better than the solution used before. More technically, this kind of process moves the world into a specific and unexpected set of states by searching through a large search space, hitting small and low probability targets. When this process is gradually guided by some agent into some specific state, through searching specific targets, we can say it <a href=\"https://www.lesswrong.com/tag/preference\">prefers<\/a> that state.<\/p><p>The best way to exemplify an optimization process is through a simple example: <a href=\"https://www.lesswrong.com/tag/eliezer-yudkowsky\">Eliezer Yudkowsky<\/a> suggests natural selection is such a process. Through an implicit preference  better replicators  natural selection searches all the genetic landscape space and hit small targets: efficient mutations.<\/p><p>Consider the human being. We are a highly complex object with a low probability to have been created by chance - natural selection, however, over millions of years, built up the infrastructure needed to build such a functioning body. This body, as well as other organisms, had the chance (was <i>selected<\/i>) to develop because it is in itself a rather efficient replicator suitable for the environment where it came up.<\/p><p>Or consider the famous chessplaying computer, <a href=\"https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)\">Deep Blue<\/a>. Outside of the narrow domain of selecting moves for chess games, it can't do anything impressive: but <i>as<\/i> a chessplayer, it was massively more effective than virtually all humans. It has a high optimization power in the chess domain but almost none in any other field. Humans or evolution, on the other hand, are more domain-general optimization processes than Deep Blue, but that doesn't mean they're more effective at chess specifically. (Although note in what contexts this <i>optimization process<\/i> abstraction is useful and where it fails to be useful: it's not obvious what it would mean for \"evolution\" to play chess, and yet it is useful to talk about the optimization power of natural selection, or of Deep Blue.)<\/p><h2>Measuring Optimization Power<\/h2><p>One way to think mathematically about optimization, like <a href=\"https://www.lesswrong.com/tag/amount-of-evidence\">evidence<\/a>, is in information-theoretic bits. The optimization power is the amount of <a href=\"http://en.wikipedia.org/wiki/Self-information\">surprise<\/a> we would have in the result if there were no optimization process present. Therefore we take the base-two logarithm of the reciprocal of the probability of the result. A one-in-a-million solution (a solution so good relative to your preference ordering that it woul... <\/p>"},"Tag:nvKzwpiranwy29HFJ":{"_id":"nvKzwpiranwy29HFJ","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:nvKzwpiranwy29HFJ_description"},"userId":"EQNTWXLKMeWMp2FQS","name":"Optimization","slug":"optimization","core":false,"postCount":99,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-17T05:29:19.922Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:urfLuDdvfqGeTfccP_description":{"_id":"urfLuDdvfqGeTfccP_description","__typename":"Revision","htmlHighlight":"<p>\"Selection vs Control\" is an attempt to further clarify the notion of \"optimization process\" which has become common on LessWrong, by splitting it into several analogous-but-distinct concepts.<\/p>"},"Tag:urfLuDdvfqGeTfccP":{"_id":"urfLuDdvfqGeTfccP","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:urfLuDdvfqGeTfccP_description"},"userId":"Q7NW4XaWQmfPfdcFj","name":"Selection vs Control","slug":"selection-vs-control","core":false,"postCount":8,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2021-04-20T18:15:03.681Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:cmNDLF7cCX9P7Fqtu_description":{"_id":"cmNDLF7cCX9P7Fqtu_description","__typename":"Revision","htmlHighlight":""},"Tag:cmNDLF7cCX9P7Fqtu":{"_id":"cmNDLF7cCX9P7Fqtu","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:cmNDLF7cCX9P7Fqtu_description"},"userId":"5wu9jG4pm9q6xjZ9R","name":"Dynamical systems","slug":"dynamical-systems","core":false,"postCount":10,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2022-12-09T21:06:27.597Z","wikiOnly":false,"deleted":false,"isSubforum":false},"Revision:ifEGDHySkAejhCFDf_biography":{"_id":"ifEGDHySkAejhCFDf_biography","__typename":"Revision","version":"1.2.0","updateType":"minor","editedAt":"2022-09-30T00:19:30.163Z","userId":"ifEGDHySkAejhCFDf","html":"<p>Independent AI alignment researcher<\/p>","wordCount":4,"htmlHighlight":"<p>Independent AI alignment researcher<\/p>","plaintextDescription":"Independent AI alignment researcher"},"User:ifEGDHySkAejhCFDf":{"_id":"ifEGDHySkAejhCFDf","__typename":"User","biography":{"__ref":"Revision:ifEGDHySkAejhCFDf_biography"},"profileImageId":null,"moderationStyle":"norm-enforcing","bannedUserIds":["tcc43uZCmpnLsnxaG"],"moderatorAssistance":true,"slug":"alexflint","createdAt":"2009-07-17T10:07:09.115Z","username":"alexflint","displayName":"Alex Flint","previousDisplayName":"alexflint","fullName":"Alex Flint","karma":3669,"afKarma":974,"deleted":false,"isAdmin":false,"htmlBio":"<p>Independent AI alignment researcher<\/p>","postCount":75,"commentCount":543,"sequenceCount":1,"afPostCount":35,"afCommentCount":153,"spamRiskScore":1,"tagRevisionCount":1},"Post:znfkdCoHMANwqc2WE":{"_id":"znfkdCoHMANwqc2WE","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:znfkdCoHMANwqc2WE_"},"fmCrosspost":null,"readTimeMinutes":32,"moderationGuidelines":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:sYm3HiWcfZvrGu3ui"},{"__ref":"Tag:3uE2pXvbcnS9nnZRE"},{"__ref":"Tag:ac84EpK6mZbPLzmqj"},{"__ref":"Tag:nvKzwpiranwy29HFJ"},{"__ref":"Tag:urfLuDdvfqGeTfccP"},{"__ref":"Tag:cmNDLF7cCX9P7Fqtu"}],"url":null,"postedAt":"2020-06-20T00:38:15.521Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2020-06-20T02:09:42.936Z","meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":null,"commentCount":74,"voteCount":85,"baseScore":223,"extendedScore":null,"unlisted":false,"score":0.002228,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2022-03-31T13:09:21.562Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"bestoflesswrong","curatedDate":"2020-06-22T22:20:15.652Z","commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"ifEGDHySkAejhCFDf","location":null,"googleLocation":null,"onlineEvent":null,"globalEvent":null,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"r38pkCm7wF4M44MDQ","suggestForCuratedUserIds":["EQNTWXLKMeWMp2FQS","fD4ATtTkdQJ4aSpGH"],"suggestForCuratedUsernames":"Ben Pace, Vaniver","reviewForCuratedUserId":"EQNTWXLKMeWMp2FQS","authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":85,"afExtendedScore":null,"afCommentCount":43,"afLastCommentedAt":"2021-12-16T14:21:27.334Z","afSticky":false,"hideAuthor":false,"moderationStyle":"easy-going","submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":null,"reviewCount":1,"reviewVoteCount":29,"positiveReviewVoteCount":20,"reviewVoteScoreAllKarma":55,"reviewVotesAllKarma":[9,9,4,4,4,4,4,4,4,4,4,1,0],"reviewVoteScoreHighKarma":51,"reviewVotesHighKarma":[9,9,4,4,4,4,4,4,4,4,1,0],"reviewVoteScoreAF":29,"reviewVotesAF":[9,9,4,4,4,4,4,4,4,1,-9,-9],"finalReviewVoteScoreHighKarma":55.7,"finalReviewVotesHighKarma":[9,9,9,9,4,4,4,4,4,4,4,4,4,1,0.9,0.8,0,0,0,-1,-9,-9],"finalReviewVoteScoreAllKarma":73.9,"finalReviewVotesAllKarma":[9,9,9,9,9,9,4,4,4,4,4,4,4,4,4,4,1,1,0.9,0.8,0,0,0,-0.8,-1,-4,-9,-9],"finalReviewVoteScoreAF":24.699999999999996,"finalReviewVotesAF":[9,9,4,4,4,4,4,4,0.9,0.8,-1,-9,-9],"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":0,"reviewCount2019":null,"user":{"__ref":"User:ifEGDHySkAejhCFDf"},"coauthors":[],"slug":"the-ground-of-optimization-1","title":"The ground of optimization","draft":false,"hideCommentKarma":false,"af":true,"currentUserReviewVote":null},"Sequence:onCRFFN7rGXTg3jyc":{"_id":"onCRFFN7rGXTg3jyc","__typename":"Sequence","title":"Model Comparison","gridImageId":"sequencesgrid/nzjkcyvey3hvevcpnrks","canonicalCollectionSlug":null},"Revision:9BqvY7tpqrD4BC6dL_":{"_id":"9BqvY7tpqrD4BC6dL_","__typename":"Revision","htmlHighlight":"<p>The last <a href=\"https://www.lesswrong.com/s/onCRFFN7rGXTg3jyc/p/zd89utY4afA59p58k\">couple<\/a> <a href=\"https://www.lesswrong.com/posts/QKnbbGDd2LbAPfgBh/wolf-s-dice-ii-what-asymmetry\">posts<\/a> compared some specific models for 20000 rolls of a die. This post will step back, and talk about more general theory for Bayesian model comparison.<\/p><p>The main problem is to calculate <span><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"P[data | model]\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a<\/span><\/span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">|<\/span><\/span><\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">o<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">e<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">l<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]<\/span><\/span><\/span><\/span><\/span><\/span> for some model. The model will typically give the probability of observed data <span><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"x\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x<\/span><\/span><\/span><\/span><\/span><\/span> (e.g. die rolls) based on some unobserved parameter values <span><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\theta\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\"><\/span><\/span><\/span><\/span><\/span><\/span> (e.g. the <span><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"p\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.446em;\">p<\/span><\/span><\/span><\/span><\/span><\/span>&#x27;s in the last two posts), along with a prior distribution over <span><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\theta\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\"><\/span><\/span><\/span><\/span><\/span><\/span>. We then need to compute<\/p><p> <span><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"P[data|model] = \\int_{\\theta} P[data|\\theta] dP[\\theta]\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a<\/span><\/span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">|<\/span><\/span><\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">o<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">e<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">l<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]<\/span><\/span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=<\/span><\/span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.138em;\"><span class=\"mjx-mo\" style=\"padding-right: 0.138em;\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.593em; padding-bottom: 0.593em;\"><\/span><\/span><\/span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.517em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\"><\/span><\/span><\/span><\/span><\/span><\/span><span class=\"mjx-mi MJXc-space1\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a<\/span><\/span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">|<\/span><\/span><\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\"><\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\"><\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]<\/span><\/span><\/span><\/span><\/span><\/span> <\/p><p>which will be a hairy high-dimensional integral.<\/p><p>Some special model structures allow us to simplify the problem, typically by factoring the integral into a product of one-dimensional integrals. But in general, we need some method for approximating these integrals.<\/p><p>The two most common approximation methods used in practice are <a href=\"https://en.wikipedia.org/wiki/Laplace%27s_method\">Laplace approximation<\/a> around the maximum-likelihood point, and <a href=\"https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo\">MCMC<\/a> (see e.g. <a href=\"https://www.researchgate.net/profile/Cong_Han3/publication/4986746_Markov_Chain_Monte_Carlo_Methods_for_Computing_Bayes_Factors_A_Comparative_Review/links/5614298308ae4ce3cc638b8b/Markov-Chain-Monte-Carlo-Methods-for-Computing-Bayes-Factors-A-Comparative-Review.pdf\">here<\/a> for application of MCMC to Bayes factors). We&#x27;ll mainly talk about Laplace approximation here - in practice MCMC mostly works well in the same cases, assuming the unobserved parameters are continuous.<\/p><h2>Laplace Approximation<\/h2><p>Here&#x27;s the idea of Laplace approximation. First, posterior distributions tend to be very pointy. This is mainly because independent probabilities multiply, so probabilities tend to scale exponentially with the number of data points. Think of the probabilities we calculated in the last two posts, with values like <span><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"10^{-70}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">10<\/span><\/span><\/span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\"><\/span><\/span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">70<\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span> or <span><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"10^{-20}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">10<\/span><\/span><\/span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\"><\/span><\/span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">20<\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span> - that&#x27;s the typical case. If we&#x27;re integrating over a function with values like that, we can basically just pay attention to the region around the highest value - other regions will have exponentially small weight.<\/p><p>Laplace&#x27; trick is to use a second-order approximation within that high-valued region.  Specifically, since probabilities naturally live on a log scale, we&#x27;ll take a second order-approximation of the log likelihood around its maximum point. Thus:<\/p><p> <span><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\int_{\\theta} e^{lnP[data|\\theta]} dP[\\theta] \\approx \\int_{\\theta} e^{lnP[data|\\theta_{max}] + \\frac{1}{2}(\\theta-\\theta_{max})^T (\\frac{d^2lnP}{d\\theta^2}|_{\\theta_{max}})(\\theta-\\theta_{max})} dP[\\theta]\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.138em;\"><span class=\"mjx-mo\" style=\"padding-right: 0.138em;\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.593em; padding-bottom: 0.593em;\"><\/span><\/span><\/span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.517em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\"><\/span><\/span><\/span><\/span><\/span><\/span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">e<\/span><\/span><\/span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">l<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a<\/span><\/span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">|<\/span><\/span><\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\"><\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]<\/span><\/span><\/span><\/span><\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\"><\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]<\/span><\/span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\"><\/span><\/span><span class=\"mjx-msubsup MJXc-space3\"><span class=\"mjx-base\" style=\"margin-right: -0.138em;\"><span class=\"mjx-mo\" style=\"padding-right: 0.138em;\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.593em; padding-bottom: 0.593em;\"><\/span><\/span><\/span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.517em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\"><\/span><\/span><\/span><\/span><\/span><\/span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">e<\/span><\/span><\/span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.979em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">l<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.372em; padding-bottom: 0.298em;\">t<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a<\/span><\/span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">|<\/span><\/span><\/span><\/span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\"><\/span><\/span><\/span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.18em; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x<\/span><\/span><\/span><\/span><\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">+<\/span><\/span><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 0.583em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 83.3%; width: 0.7em; top: -1.288em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1<\/span><\/span><\/span><span class=\"mjx-denominator\" style=\"font-size: 83.3%; width: 0.7em; bottom: -0.688em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2<\/span><\/span><\/span><span style=\"border-bottom: 1px solid; top: -0.296em; width: 0.583em;\" class=\"mjx-line\"><\/span><\/span><span style=\"height: 1.647em; vertical-align: -0.573em;\" class=\"mjx-vsize\"><\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\"><\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\"><\/span><\/span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\"><\/span><\/span><\/span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.18em; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x<\/span><\/span><\/span><\/span><\/span><\/span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)<\/span><\/span><\/span><span class=\"mjx-sup\" style=\"font-size: 83.3%; vertical-align: 0.435em; padding-left: 0px; padding-right: 0.06em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.12em;\">T<\/span><\/span><\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(<\/span><\/span><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 2.478em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"font-size: 83.3%; width: 2.973em; top: -1.662em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.003em;\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d<\/span><\/span><\/span><span class=\"mjx-sup\" style=\"vertical-align: 0.363em; padding-left: 0.054em; padding-right: 0.05em;\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2<\/span><\/span><\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">l<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><\/span><\/span><span class=\"mjx-denominator\" style=\"font-size: 83.3%; width: 2.973em; bottom: -0.987em;\"><span class=\"mjx-mrow\" style=\"\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d<\/span><\/span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\"><\/span><\/span><\/span><span class=\"mjx-sup\" style=\"vertical-align: 0.289em; padding-left: 0px; padding-right: 0.05em;\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2<\/span><\/span><\/span><\/span><\/span><\/span><span style=\"border-bottom: 1px solid; top: -0.296em; width: 2.478em;\" class=\"mjx-line\"><\/span><\/span><span style=\"height: 2.207em; vertical-align: -0.822em;\" class=\"mjx-vsize\"><\/span><\/span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">|<\/span><\/span><\/span><\/span><\/span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.379em; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\"><\/span><\/span><\/span><span class=\"mjx-sub\" style=\"vertical-align: -0.15em; padding-right: 0.05em;\"><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x<\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\"><\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\"><\/span><\/span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\"><\/span><\/span><\/span><span class=\"mjx-sub\" style=\"font-size: 83.3%; vertical-align: -0.18em; padding-right: 0.06em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x<\/span><\/span><\/span><\/span><\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)<\/span><\/span><\/span><\/span><\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\"><\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]<\/span><\/span><\/span><\/span><\/span><\/span> <\/p><p>If we assume that the prior <span><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"dP[\\theta]\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\"><\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]<\/span><\/span><\/span><\/span><\/span><\/span> is uniform (i.e. <span><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"dP[\\theta] = d\\theta\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\"><\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]<\/span><\/span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=<\/span><\/span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\"><\/span><\/span><\/span><\/span><\/span><\/span>), then this looks like a normal distribution on <span><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\theta\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\"><\/span><\/span><\/span><\/span><\/span><\/span> with mean <span><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\theta_{max}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\"><\/span><\/span><\/span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x<\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span> and variance given by the inverse Hessian matrix of the log-likelihood. (It turns out that, even for non-uniform <span><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"dP[\\theta]\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;\">d<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\"><\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">]<\/span><\/span><\/span><\/span><\/span><\/span>, we can just transform <span><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\theta\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\"><\/span><\/span><\/span><\/span><\/span><\/span> so that the prior looks uniform near <span><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\theta_{max}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\"><\/span><\/span><\/span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">m<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">a<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x<\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span>, and transform it back when we&#x27;re done.) The result:<\/p><p> <span><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"\\int_{\\theta} e^{lnP[data|\\theta]} dP[\\theta] \\approx P[data|\\theta_{max}] p[\\theta_{max}] (2\\pi)^{\\frac{k}{2}}det(-\\frac{d^2lnP}{d\\theta^2}|_{\\theta_{max}})^{-\\frac{1}{2}}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\" style=\"margin-right: -0.138em;\"><span class=\"mjx-mo\" style=\"padding-right: 0.138em;\"><span class=\"mjx-char MJXc-TeX-size1-R\" style=\"padding-top: 0.593em; padding-bottom: 0.593em;\"><\/span><\/span><\/span><span class=\"mjx-sub\" style=\"font-size: 70.7%; vertical-align: -0.517em; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\"><\/span><\/span><\/span><\/span><\/span><\/span><span class=\"mjx-msubsup MJXc-space1\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">e<\/span><\/span><\/span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-texatom\" style=\"\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">l<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">[<\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/span>... <style>.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}\n.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}\n.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}\n.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}\n.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}\n.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}\n.mjx-numerator {display: block; text-align: center}\n.mjx-denominator {display: block; text-align: center}\n.MJXc-stacked {height: 0; position: relative}\n.MJXc-stacked > * {position: absolute}\n.MJXc-bevelled > * {display: inline-block}\n.mjx-stack {display: inline-block}\n.mjx-op {display: block}\n.mjx-under {display: table-cell}\n.mjx-over {display: block}\n.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}\n.mjx-stack > .mjx-sup {display: block}\n.mjx-stack > .mjx-sub {display: block}\n.mjx-prestack > .mjx-presup {display: block}\n.mjx-prestack > .mjx-presub {display: block}\n.mjx-delim-h > .mjx-char {display: inline-block}\n.mjx-surd {vertical-align: top}\n.mjx-mphantom * {visibility: hidden}\n.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}\n.mjx-annotation-xml {line-height: normal}\n.mjx-menclose > svg {fill: none; stroke: currentColor}\n.mjx-mtr {display: table-row}\n.mjx-mlabeledtr {display: table-row}\n.mjx-mtd {display: table-cell; text-align: center}\n.mjx-label {display: table-row}\n.mjx-box {display: inline-block}\n.mjx-block {display: block}\n.mjx-span {display: inline}\n.mjx-char {display: block; white-space: pre}\n.mjx-itable {display: inline-table; width: auto}\n.mjx-row {display: table-row}\n.mjx-cell {display: table-cell}\n.mjx-table {display: table; width: 100%}\n.mjx-line {display: block; height: 0}\n.mjx-strut {width: 0; padding-top: 1em}\n.mjx-vsize {width: 0}\n.MJXc-space1 {margin-left: .167em}\n.MJXc-space2 {margin-left: .222em}\n.MJXc-space3 {margin-left: .278em}\n.mjx-test.mjx-test-display {display: table!important}\n.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}\n.mjx-test.mjx-test-default {display: block!important; clear: both}\n.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}\n.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}\n.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}\n.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}\n.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}\n.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}\n.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}\n.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}\n.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}\n.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}\n.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}\n.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}\n.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}\n.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}\n.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}\n.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}\n.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}\n.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}\n.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}\n.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}\n.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}\n.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}\n.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}\n.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}\n.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}\n.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}\n.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}\n.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}\n.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}\n@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}\n@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}\n@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}\n@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}\n@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}\n@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}\n@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}\n@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}\n@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}\n@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}\n@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}\n@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}\n@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}\n@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}\n@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}\n@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}\n@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}\n@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}\n@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}\n@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}\n@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}\n@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}\n@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}\n@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}\n@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}\n@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}\n@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}\n@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}\n<\/style><\/p>","wordCount":987,"version":"1.0.0"},"Revision:6nS8oYmSMuFMaiowF_description":{"_id":"6nS8oYmSMuFMaiowF_description","__typename":"Revision","htmlHighlight":"<p><strong>Logic and Mathematics<\/strong> are deductive systems, where the conclusion of a successful argument follows necessarily from its premises, given the axioms of the system youre using: number theory, geometry, predicate logic, etc.<\/p><h2>See also<\/h2><ul><li><a href=\"https://www.lesswrong.com/tag/valid-argument\">Valid argument<\/a> - An argument is valid when it contains no logical fallacies.<\/li><li><a href=\"https://www.lesswrong.com/tag/sound-argument\">Sound argument<\/a> - An argument that is valid and whose premises are all true. In other words, the premises are true and the conclusion necessarily follows from them, making the conclusion true as well.<\/li><li><a href=\"https://www.lesswrong.com/tag/formal-proof\">Formal proof<\/a> - A set of steps from axiom(s) and previous proof(s) which follows the rules of induction of a mathematical system.<\/li><li><a href=\"https://www.lesswrong.com/tag/logical-uncertainty\">Logical Uncertainty<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/logical-induction\">Logical Induction<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/probability-and-statistics\">Probability &amp; Statistics<\/a><\/li><\/ul>"},"Tag:6nS8oYmSMuFMaiowF":{"_id":"6nS8oYmSMuFMaiowF","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:6nS8oYmSMuFMaiowF_description"},"userId":"qxJ28GN72aiJu96iF","name":"Logic & Mathematics ","slug":"logic-and-mathematics","core":false,"postCount":324,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-15T12:40:36.752Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Tag:bh7uxTTqmsQ8jZJdB":{"_id":"bh7uxTTqmsQ8jZJdB","__typename":"Tag","parentTag":null,"subTags":[],"description":null,"userId":"qgdGA4ZEyW7zNdK84","name":"Probability & Statistics","slug":"probability-and-statistics","core":false,"postCount":241,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":null,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-08T04:32:58.906Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:LhX3F2SvGDarZCuh6_description":{"_id":"LhX3F2SvGDarZCuh6_description","__typename":"Revision","htmlHighlight":"<p><strong>Bayes&apos; Theorem<\/strong> (also known as Bayes&apos; Law) is a law of probability that describes the proper way to incorporate new evidence into prior probabilities to form an updated probability estimate. It is commonly regarded as the foundation of consistent rational reasoning under uncertainty. Bayes Theorem is named after Reverend Thomas Bayes who proved the theorem in 1763.<\/p><p><em>See also: <\/em><a href=\"https://www.lesswrong.com/tag/bayesian-probability\">Bayesian probability<\/a>, <a href=\"https://www.lesswrong.com/tag/priors\">Priors<\/a>, <a href=\"https://www.lesswrong.com/tag/likelihood-ratio\">Likelihood ratio<\/a>, <a href=\"https://www.lesswrong.com/tag/belief-update\">Belief update<\/a>, <a href=\"https://www.lesswrong.com/tag/probability-and-statistics\">Probability and statistics<\/a>, <a href=\"https://www.lesswrong.com/tag/epistemology\">Epistemology<\/a>, <a href=\"https://www.lesswrong.com/tag/bayesianism\">Bayesianism<\/a><\/p><p>Bayes&apos; theorem commonly takes the form:<\/p><div><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"P(A|B)={\\frac{P(B|A)\\,P(A)}{P(B)}}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A<\/span><\/span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">|<\/span><\/span><\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)<\/span><\/span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=<\/span><\/span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 5.962em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 5.962em; top: -1.59em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B<\/span><\/span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">|<\/span><\/span><\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)<\/span><\/span><span class=\"mjx-mspace\" style=\"width: 0.167em; height: 0px;\"><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)<\/span><\/span><\/span><\/span><span class=\"mjx-denominator\" style=\"width: 5.962em; bottom: -1.09em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)<\/span><\/span><\/span><\/span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 5.962em;\" class=\"mjx-line\"><\/span><\/span><span style=\"height: 2.68em; vertical-align: -1.09em;\" class=\"mjx-vsize\"><\/span><\/span><\/span><\/span><\/span><\/span><\/span><\/div><p>where A is the proposition of interest, B is the observed evidence, P(A) and P(B) are prior probabilities, and P(A|B) is the posterior probability of A.<\/p><p>With the posterior odds, the prior odds and the <a href=\"https://www.lesswrong.com/tag/likelihood-ratio\">likelihood ratio<\/a> written explicitly, the theorem reads:<\/p><div><span class=\"mjx-chtml MJXc-display\" style=\"text-align: center;\"><span class=\"mjx-math\" aria-label=\"\\frac{P(A|B)}{P(\\neg{} A|B)}=\\frac{P(A)}{P(\\neg{} A)}\\cdot\\frac{P(B|A)}{P(B|\\neg{} A)}\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mfrac\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 4.183em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 4.183em; top: -1.59em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A<\/span><\/span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">|<\/span><\/span><\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)<\/span><\/span><\/span><\/span><span class=\"mjx-denominator\" style=\"width: 4.183em; bottom: -1.09em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">&#xAC;<\/span><\/span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A<\/span><\/span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">|<\/span><\/span><\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)<\/span><\/span><\/span><\/span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 4.183em;\" class=\"mjx-line\"><\/span><\/span><span style=\"height: 2.68em; vertical-align: -1.09em;\" class=\"mjx-vsize\"><\/span><\/span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">=<\/span><\/span><span class=\"mjx-mfrac MJXc-space3\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 3.146em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 3.146em; top: -1.59em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)<\/span><\/span><\/span><\/span><span class=\"mjx-denominator\" style=\"width: 3.146em; bottom: -1.09em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">&#xAC;<\/span><\/span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)<\/span><\/span><\/span><\/span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 3.146em;\" class=\"mjx-line\"><\/span><\/span><span style=\"height: 2.68em; vertical-align: -1.09em;\" class=\"mjx-vsize\"><\/span><\/span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.004em; padding-bottom: 0.298em;\">&#x22C5;<\/span><\/span><span class=\"mjx-mfrac MJXc-space2\"><span class=\"mjx-box MJXc-stacked\" style=\"width: 4.183em; padding: 0px 0.12em;\"><span class=\"mjx-numerator\" style=\"width: 4.183em; top: -1.59em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B<\/span><\/span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">|<\/span><\/span><\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)<\/span><\/span><\/span><\/span><span class=\"mjx-denominator\" style=\"width: 4.183em; bottom: -1.09em;\"><span class=\"mjx-mrow\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.109em;\">P<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(<\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">B<\/span><\/span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">|<\/span><\/span><\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.298em;\">&#xAC;<\/span><\/span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><\/span><\/span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">A<\/span><\/span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)<\/span><\/span><\/span><\/span><span style=\"border-bottom: 1.3px solid; top: -0.296em; width: 4.183em;\" class=\"mjx-line\"><\/span><\/span><span style=\"height: 2.68em; vertical-align: -1.09em;\" class=\"mjx-vsize\"><\/span><\/span><\/span><\/span><\/span><\/div><h2> Visualization of Bayes&apos; Rule<\/h2><span><figure><img src=\"https://wiki.lesswrong.com/images/7/74/Bayes.png\" class=\"draft-image \" style=\"width:40%\"><\/figure><\/span><h2>External links<\/h2><ul><li><a href=\"https://arbital.com/p/bayes_rule_guide/\">Arbital Guide to Bayes&apos; Rule<\/a><\/li><li><a href=\"http://yudkowsky.net/rational/bayes\">An Intuitive Explanation of Bayes&apos; Theorem<\/a> by Eliezer Yudkowsky<\/li><li><a href=\"http://blog.oscarbonilla.com/2009/05/visualizing-bayes-theorem/\">Visualizing Bayes&apos; theorem<\/a> by Oscar Bonilla<\/li><li><a href=\"http://oracleaide.wordpress.com/2012/12/26/a-venn-pie/\">Using Venn pies to illustrate Bayes&apos; theorem<\/a> by <a href=\"https://www.lesswrong.com/users/oracleaide\">oracleaide<\/a><\/li><li><a href=\"http://kruel.co/2010/02/27/a-guide-to-bayes-theorem-a-few-links/\">A Guide to Bayes&#x2019; Theorem &#x2013; A few links<\/a> by Alexander Kruel<\/li><li><a href=\"https://en.wikipedia.org/wiki/Bayes%27_theorem\">Bayes&apos; Theorem<\/a>, Wikipedia<\/li><\/ul>"},"Tag:LhX3F2SvGDarZCuh6":{"_id":"LhX3F2SvGDarZCuh6","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:LhX3F2SvGDarZCuh6_description"},"userId":"nLbwLhBaQeG6tCNDN","name":"Bayes' Theorem","slug":"bayes-theorem","core":false,"postCount":144,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-04-29T02:02:50.973Z","wikiOnly":false,"deleted":false,"isSubforum":null},"User:MEu8MdhruX5jfGsFQ":{"_id":"MEu8MdhruX5jfGsFQ","__typename":"User","biography":null,"profileImageId":null,"moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":null,"slug":"johnswentworth","createdAt":"2011-02-19T16:54:09.598Z","username":"johnswentworth","displayName":"johnswentworth","previousDisplayName":null,"fullName":null,"karma":34352,"afKarma":4555,"deleted":false,"isAdmin":false,"htmlBio":"","postCount":274,"commentCount":2424,"sequenceCount":7,"afPostCount":104,"afCommentCount":606,"spamRiskScore":1,"tagRevisionCount":0},"Post:9BqvY7tpqrD4BC6dL":{"_id":"9BqvY7tpqrD4BC6dL","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:9BqvY7tpqrD4BC6dL_"},"fmCrosspost":null,"readTimeMinutes":4,"moderationGuidelines":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:6nS8oYmSMuFMaiowF"},{"__ref":"Tag:bh7uxTTqmsQ8jZJdB"},{"__ref":"Tag:LhX3F2SvGDarZCuh6"}],"url":null,"postedAt":"2019-07-18T15:23:28.140Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2019-07-18T16:55:18.348Z","meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":null,"commentCount":3,"voteCount":10,"baseScore":28,"extendedScore":null,"unlisted":false,"score":0.000273,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2019-08-21T10:51:28.647Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"MEu8MdhruX5jfGsFQ","location":null,"googleLocation":null,"onlineEvent":null,"globalEvent":null,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":0,"afExtendedScore":null,"afCommentCount":null,"afLastCommentedAt":"2019-07-13T19:57:18.870Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":null,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":0,"reviewCount2019":null,"user":{"__ref":"User:MEu8MdhruX5jfGsFQ"},"coauthors":[],"slug":"laplace-approximation","title":"Laplace Approximation","draft":false,"hideCommentKarma":null,"af":false,"currentUserReviewVote":null},"Sequence:aek5ksSs2FHTeofsf":{"_id":"aek5ksSs2FHTeofsf","__typename":"Sequence","title":"Agency: What it is and why it matters","gridImageId":"sequencesgrid/jzecciql3lon4euljay8","canonicalCollectionSlug":null},"Revision:oiftkZnFBqyHGALwv_":{"_id":"oiftkZnFBqyHGALwv_","__typename":"Revision","htmlHighlight":"<p><i><strong>tl;dr: <\/strong>Sometimes planners successfully <\/i><a href=\"https://www.lesswrong.com/posts/CAwwFpbteYBQw2Gkp/p-b-plan-to-p-b-better\"><i><u>P<\/u><sub><u>2<\/u><\/sub><u>B<\/u><\/i><\/a><i>, kicking off a self-sustaining chain reaction / feedback loop of better and better plans (made possible by better and better world-models, more and more resources, etc.) Whereas fire takes a concentration of heat as input and produces a greater concentration of heat as output, agents take a concentration of convergent instrumental resources (e.g. data, money, power) as input and produce a greater concentration as output.<\/i><\/p><p>Previously we described the Convergent-Instrumental-Goal-to-rule-them-all, <a href=\"https://www.lesswrong.com/posts/CAwwFpbteYBQw2Gkp/p-b-plan-to-p-b-better\"><u>P2B: Plan to P2B Better<\/u><\/a>. The most common way to P<sub>2<\/sub>B is to plan to plan again, in the immediate future, but with some new relevant piece of data. For example, suppose I am walking somewhere. I look up from my phone to glance at the door. Why? Because without data about the location of the doorknob, I cant guide my hands to open the door. This sort of thing doesnt just happen on short timescales, though; humans (and all realistic agents, Id wager) are <a href=\"https://www.lesswrong.com/posts/6ayQbR5opoTN4AgFb/hierarchical-planning-context-agents\"><u>hierarchical planners<\/u><\/a> and medium and long-term plans usually involve acquiring new relevant data as well.<\/p><figure class=\"image\"><img src=\"https://lh5.googleusercontent.com/6g15G5_6PxoAhEKnV6OpMf0Yc_cVq33v5Un2gZYYz1gCtrXF4QJ3V7yqj2hLqti0Z1DGRYjDUlfnI9EfI7omwyr0SdSCNiODQ_5Cl3uTYGf6Py9yuO1t6LZAg_bpLJePts5N703v\"><\/figure><p>This image just talks about collecting good new data, but there are other important convergent instrumental goals too. Such as staying alive, propagating your goals to other agents, and acquiring money. One could modify the diagram to include these other feedback loops as well  more data <i>and money and power<\/i> being recruited by sensor-learner-planners to acquire more data <i>and money and power<\/i>. Its not that all of these metrics will go up with every cycle around the loop; its that some goals/resources are instrumentally convergent in that they tend to show up frequently in most real-world P<sub>2<\/sub>B loops.<\/p><p>Agents, I say, are <i>P<sub>2<\/sub>B chain reactions / P<sub>2<\/sub>B feedback loops.<\/i> They are what happens when planners successfully P<sub>2<\/sub>B. Whereas fire is a chain reaction that inputs heat + fuel + oxygen and outputs more heat (and often more oxygen and fuel too, as it expands to envelop more such) agents are chain reactions that input sensor-learner-planners with some amount of data, knowledge, power, money, etc. and output more, better sensor-learner-planners with greater amounts of data, knowledge, power, money, etc.<\/p><p>(I dont I think this definition fully captures our intuitive concept of agency. Rather, P<sub>2<\/sub>B chain reactions seem like a big deal, an important concept worth talking about, and close enoug... <\/p>","wordCount":591,"version":"1.2.0"},"Revision:GDGYkF29pxEQNWjYc_description":{"_id":"GDGYkF29pxEQNWjYc_description","__typename":"Revision","htmlHighlight":"<p><strong>Agency <\/strong>or <strong>Agenticness <\/strong>is the property of effectively acting with an environment to achieve one's goals. &nbsp;A key property of agents is that the more agentic a being is, the more you can predict its actions from its goals since its actions will be whatever will maximize the chances of achieving its goals. Agency has sometimes been contrasted with&nbsp;<i>sphexishness, <\/i>the blind execution of cached algorithms without regard for effectiveness.&nbsp;<br><br>One might lack agency for internal reasons, e.g., being a rock that has no goals and no ability to act, or for external reasons, e.g., being a child who is granted no freedom to act as they choose.<\/p><h2>See Also<\/h2><ul><li><a href=\"https://www.lesswrong.com/tag/robust-agents\">Robust Agency<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/free-energy-principle\">Free Energy Principle/Active Inference<\/a>: a theory of agency and a prospective architecture of artificial agents.<\/li><li><a href=\"https://www.lesswrong.com/tag/reinforcement-learning\">Reinforcement Learning<\/a>: the leading practical paradigm of creating artificial agents.<\/li><\/ul>"},"Tag:GDGYkF29pxEQNWjYc":{"_id":"GDGYkF29pxEQNWjYc","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:GDGYkF29pxEQNWjYc_description"},"userId":"r38pkCm7wF4M44MDQ","name":"Agency","slug":"agency","core":false,"postCount":80,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-08-16T20:40:16.224Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:YLFQfGzNdGA4NFcKS_biography":{"_id":"YLFQfGzNdGA4NFcKS_biography","__typename":"Revision","version":"1.3.0","updateType":"minor","editedAt":"2022-09-02T18:54:49.726Z","userId":"YLFQfGzNdGA4NFcKS","html":"<p>Philosophy PhD student, worked at AI Impacts, then Center on Long-Term Risk, now OpenAI Futures/Governance team. Views are my own &amp; do not represent those of my employer. I subscribe to Crocker's Rules and am especially interested to hear unsolicited constructive criticism. <a href=\"http://sl4.org/crocker.html\">http://sl4.org/crocker.html<\/a><\/p>","wordCount":43,"htmlHighlight":"<p>Philosophy PhD student, worked at AI Impacts, then Center on Long-Term Risk, now OpenAI Futures/Governance team. Views are my own &amp; do not represent those of my employer. I subscribe to Crocker's Rules and am especially interested to hear unsolicited constructive criticism. <a href=\"http://sl4.org/crocker.html\">http://sl4.org/crocker.html<\/a><\/p>","plaintextDescription":"Philosophy PhD student, worked at AI Impacts, then Center on Long-Term Risk, now OpenAI Futures/Governance team. Views are my own & do not represent those of my employer. I subscribe to Crocker's Rules and am especially interested to hear unsolicited constructive criticism. http://sl4.org/crocker.html"},"User:YLFQfGzNdGA4NFcKS":{"_id":"YLFQfGzNdGA4NFcKS","__typename":"User","biography":{"__ref":"Revision:YLFQfGzNdGA4NFcKS_biography"},"profileImageId":null,"moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":true,"slug":"daniel-kokotajlo","createdAt":"2018-03-05T19:59:32.269Z","username":"daniel-kokotajlo","displayName":"Daniel Kokotajlo","previousDisplayName":null,"fullName":"Daniel Kokotajlo","karma":13205,"afKarma":2302,"deleted":null,"isAdmin":false,"htmlBio":"<p>Philosophy PhD student, worked at AI Impacts, then Center on Long-Term Risk, now OpenAI Futures/Governance team. Views are my own &amp; do not represent those of my employer. I subscribe to Crocker's Rules and am especially interested to hear unsolicited constructive criticism. <a href=\"http://sl4.org/crocker.html\">http://sl4.org/crocker.html<\/a><\/p>","postCount":91,"commentCount":1963,"sequenceCount":3,"afPostCount":37,"afCommentCount":579,"spamRiskScore":1,"tagRevisionCount":0},"Post:oiftkZnFBqyHGALwv":{"_id":"oiftkZnFBqyHGALwv","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:oiftkZnFBqyHGALwv_"},"fmCrosspost":null,"readTimeMinutes":2,"moderationGuidelines":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:GDGYkF29pxEQNWjYc"},{"__ref":"Tag:Ng8Gice9KNkncxqcj"}],"url":null,"postedAt":"2021-12-04T21:35:06.403Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2021-12-05T00:40:44.969Z","meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":null,"commentCount":null,"voteCount":8,"baseScore":18,"extendedScore":null,"unlisted":false,"score":0.00091,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2021-12-04T21:35:06.403Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"YLFQfGzNdGA4NFcKS","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"r38pkCm7wF4M44MDQ","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":13,"afExtendedScore":null,"afCommentCount":null,"afLastCommentedAt":"2021-12-04T21:35:06.408Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"reviewCount":null,"reviewVoteCount":null,"positiveReviewVoteCount":null,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"user":{"__ref":"User:YLFQfGzNdGA4NFcKS"},"coauthors":[],"slug":"agents-as-p-b-chain-reactions","title":"Agents as PB Chain Reactions","draft":false,"hideCommentKarma":false,"af":true,"currentUserReviewVote":null},"Sequence:dT7CKGXwq9vt76CeX":{"_id":"dT7CKGXwq9vt76CeX","__typename":"Sequence","title":"Alignment Newsletter","gridImageId":"sequencesgrid/b7vwrndrypohpwvcfkpc","canonicalCollectionSlug":null},"Revision:CsMQ7zsprBqWaeSvk_":{"_id":"CsMQ7zsprBqWaeSvk_","__typename":"Revision","htmlHighlight":"<h1><strong>Highlights<\/strong><\/h1><p><strong><u><a href=\"https://vkrakovna.wordpress.com/2018/04/02/specification-gaming-examples-in-ai/\">Specification gaming examples in AI<\/a><\/u><\/strong> <em>(Victoria Krakovna)<\/em>: A list of examples of specification gaming, where an algorithm figures out a way to literally satisfy the given specification which does not match the designer&#x27;s intent.<\/p><p><strong>Should you read it?<\/strong>There were several examples I hadn&#x27;t heard of before, which were pretty entertaining. Also, if you have any examples that aren&#x27;t already listed, it would be great to send them via the<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSeQEguZg4JfvpTywgZa3j-1J-4urrnjBVeoAO7JHIH53nrBTA/viewform\">form<\/a>so that we can have a canonical list of specification gaming examples.<\/p><p><strong><u><a href=\"https://www.lesswrong.com/posts/xCpuSfT5Lt6kkR3po/my-take-on-agent-foundations-formalizing-metaphilosophical\">My take on agent foundations: formalizing metaphilosophical competence<\/a><\/u><\/strong> <em>(Alex Zhu)<\/em>: Argues that the point of Agent Foundations is to create conceptual clarity for fuzzy concepts that we can&#x27;t formalize yet (such as logical uncertainty). We can then verify whether our ML algorithms have these desirable properties. It is decidedly<em>not<\/em>a goal to build a friendly AI using modules that Agent Foundations develop.<\/p><p><strong>Should you read it?<\/strong>I don&#x27;t know much about MIRI and Agent Foundations, but this made sense to me and felt like it clarified things for me.<\/p><p><strong><u><a href=\"https://arxiv.org/abs/1804.00097\">Adversarial Attacks and Defences Competition<\/a><\/u><\/strong> <em>(Alexey Kurakin et al)<\/em>: This is a report on a competition held at NIPS 2017 for the best adversarial attacks and defences. It includes a summary of the field and then shows the results from the competition.<\/p><p><strong>Should you read it?<\/strong>I&#x27;m not very familiar with the literature on adversarial examples and so I found this very useful as an overview of the field, especially since it talks about the advantages and disadvantages of different methods, which are hard to find by reading individual papers. The actual competition results are also quite interesting -- they find that the best attacks and defences are both quite successful on average, but have very bad worst-case performance (that is, the best defence is still very weak against at least one attack, and the best attack fails to attack at least one defence). Overall, this paints a bleak picture for defence, at least if the attacker has access to enough compute to actually try out different attack methods, and has a way of verifying whether the attacks succeed.<\/p><h1><strong>Technical AI alignment<\/strong><\/h1><h2><strong>Problems<\/strong><\/h2><p><strong><u><a href=\"https://vkrakovna.wordpress.com/2018/04/02/specification-gaming-examples-in-ai/\">Specification gaming examples in AI<\/a><\/u><\/strong> <em>(Victoria Krakovna)<\/em>: Summarized in the highlights!<\/p><p><u><a href=\"https://www.lesswrong.com/posts/CCgvJHpbvc7Lm8ZS8/metaphilosophical-competence-can-t-be-disentangled-from\">Metaphilosophical competence can&#x27;t be disentangled from alignment<\/a><\/u> <em>(Alex Zhu)<\/em>: Would you be comfortable taking a single human... <\/p>","wordCount":1262,"version":"1.0.0"},"Revision:8byoqYZfdwHffYLZ6_description":{"_id":"8byoqYZfdwHffYLZ6_description","__typename":"Revision","htmlHighlight":"<p><strong>Newsletters<\/strong> are collected summaries of recent events, posts, and academic papers.<\/p><p>The most prolific newsletter on Less Wrong is Rohin Shah&apos;s weekly Alignment Newsletter.<\/p>"},"Tag:8byoqYZfdwHffYLZ6":{"_id":"8byoqYZfdwHffYLZ6","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:8byoqYZfdwHffYLZ6_description"},"userId":"r38pkCm7wF4M44MDQ","name":"Newsletters","slug":"newsletters","core":false,"postCount":214,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-07-01T18:44:14.645Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:du6SPHKnnPrPmxWNT_biography":{"_id":"du6SPHKnnPrPmxWNT_biography","__typename":"Revision","version":null,"updateType":null,"editedAt":"2023-02-10T16:22:42.149Z","userId":null,"html":"<p>Research Scientist at DeepMind. Creator of the Alignment Newsletter. <a href=\"http://rohinshah.com/\">http://rohinshah.com/<\/a><\/p>\n","wordCount":null,"htmlHighlight":"<p>Research Scientist at DeepMind. Creator of the Alignment Newsletter. <a href=\"http://rohinshah.com/\">http://rohinshah.com/<\/a><\/p>","plaintextDescription":"Research Scientist at DeepMind. Creator of the Alignment Newsletter. http://rohinshah.com/"},"User:du6SPHKnnPrPmxWNT":{"_id":"du6SPHKnnPrPmxWNT","__typename":"User","biography":{"__ref":"Revision:du6SPHKnnPrPmxWNT_biography"},"profileImageId":null,"moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":false,"slug":"rohinmshah","createdAt":"2015-05-26T23:46:04.336Z","username":"rohinmshah","displayName":"Rohin Shah","previousDisplayName":"rohinmshah","fullName":"Rohin Shah","karma":12596,"afKarma":4828,"deleted":false,"isAdmin":false,"htmlBio":"<p>Research Scientist at DeepMind. Creator of the Alignment Newsletter. <a href=\"http://rohinshah.com/\">http://rohinshah.com/<\/a><\/p>\n","postCount":204,"commentCount":2054,"sequenceCount":2,"afPostCount":104,"afCommentCount":1283,"spamRiskScore":1,"tagRevisionCount":1},"Post:CsMQ7zsprBqWaeSvk":{"_id":"CsMQ7zsprBqWaeSvk","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:CsMQ7zsprBqWaeSvk_"},"fmCrosspost":null,"readTimeMinutes":5,"moderationGuidelines":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:8byoqYZfdwHffYLZ6"},{"__ref":"Tag:sYm3HiWcfZvrGu3ui"}],"url":null,"postedAt":"2018-04-09T16:00:38.889Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2018-06-28T21:21:53.053Z","meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":null,"commentCount":3,"voteCount":5,"baseScore":12,"extendedScore":null,"unlisted":false,"score":0.000072,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2018-11-22T03:35:03.562Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"du6SPHKnnPrPmxWNT","location":null,"googleLocation":null,"onlineEvent":null,"globalEvent":null,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"EQNTWXLKMeWMp2FQS","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":3,"afExtendedScore":null,"afCommentCount":null,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":null,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":0,"reviewCount2019":null,"user":{"__ref":"User:du6SPHKnnPrPmxWNT"},"coauthors":[],"slug":"the-alignment-newsletter-1-04-09-18","title":"The Alignment Newsletter #1: 04/09/18","draft":false,"hideCommentKarma":null,"af":true,"currentUserReviewVote":null},"Sequence:HXkpm9b8o964jbQ89":{"_id":"HXkpm9b8o964jbQ89","__typename":"Sequence","title":"Slack and the Sabbath ","gridImageId":"sequencesgrid/rqnuxewffasun6tvdkng","canonicalCollectionSlug":null},"Revision:ENBzEkoyvdakz4w5d_":{"_id":"ENBzEkoyvdakz4w5d_","__typename":"Revision","htmlHighlight":"<p>Epistemic Status: Reference.<\/p><p>Expanded From: <a href=\"https://thezvi.wordpress.com/2017/04/22/against-facebook/\">Against Facebook<\/a>, as the post originally intended.<\/p><p>Some things are fundamentally Out to Get You. <\/p><p>They seek resources at your expense. Fees are hidden. Extra options are foisted upon you. Things are made intentionally worse, forcing you to pay to make it less worse. Least bad deals require careful search. Experiences are not as advertised. What you want is buried underneath stuff you dont want. Everything is data to sell you something, rather than an opportunity to help you.<\/p><p>When you deal with Out to Get You, you know it in your gut. Your brain cannot relax. You lookout for tricks and traps. Everything is a scheme.<\/p><p>They want you not to notice. To blind you from the truth. <a href=\"https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiBlZvxmLjTAhXHRCYKHVXIBUQQtwIIIzAA&url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DTbYirSi08m4&usg=AFQjCNHjigokAukGU43eFj87EAB_ZeeR3w&sig2=duzb8zMsZdVS2ATUQB6m-w\">You can feel it when you go to work. When you go to church. When you pay your taxes.<\/a> It is bad government and bad capitalism. It is many bad relationships, groups and cultures.<\/p><p>When you listen to a political speech, you feel it. Dealing with your wireless or cable company, you feel it. At the car dealership, you feel it. When you deal with that one would-be friend, you feel it. Thinking back on that one ex, you feel it. <a href=\"https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiJs_PpmbjTAhVNgiYKHfmMA18QyCkIJTAA&url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D4F4qzPbcFiA&usg=AFQjCNFb9mk_lO6gTddFXnK8LvAwPVv7_w&sig2=c5sS3jHomcNyx9cxrCzuQQ\">Its a trap<\/a>.<\/p><h2><strong>Get Gone, Get Got, Get Compact or Get Ready<\/strong><\/h2><p>There are four responses to Out to Get You.<\/p><p>You can Get Gone. Walk away. Breathe a sigh of relief.<\/p><p>You can Get Got. Give the thing everything it wants. Pay up, relax, enjoy the show.<\/p><p>You can Get Compact. Find a rule limiting what everything it wants means in context. Then Get Got, relax and enjoy the show.<\/p><p>You can Get Ready. Do battle. Get what you want.<\/p><h2><strong>When to Get Got<\/strong><\/h2><p>Get Got when the deal is Worth It.<\/p><p>This is a difficult lesson for everyone in <em>at least<\/em> one direction.<\/p><p>I am among those with a natural hatred of <em>Getting Got<\/em>. I needed to learn to relax and enjoy the show when the deal is Worth It. Getting Got imposes a large emotional cost for people like me. I have worked to put this aside when its time to Get Got, while preserving my instincts as a defense. Thats hard.<\/p><p>Others make the mistake of <em>not<\/em> hating Getting Got. They might not even notice. This is bad. If you Get Got without realizing, youll Get Got often for large amounts. Bad habits will form. Deals wont be Worth It. Reasonable is insufficient: Out to Get You is engineered to fool. Only accept capital letters Worth It.<\/p><p><strong>When you Get Got, <em>do it on purpose<\/em>.<\/strong><\/p><p>Never Get Got without saying to yourself I am Getting Got. It is Worth It.... <\/p>","wordCount":1922,"version":"1.0.0"},"Revision:b8FHrKqyXuYGWc6vn_description":{"_id":"b8FHrKqyXuYGWc6vn_description","__typename":"Revision","htmlHighlight":"<p><strong>Game theory<\/strong> is the formal study of how rational actors interact to pursue incentives. It investigates situations of conflict and cooperation.<\/p><p><i>See also: <\/i><a href=\"https://www.lesswrong.com/tag/coordination-cooperation?showPostCount=true&amp;useTagName=true\">Coalition/coordination<\/a>, <a href=\"https://www.lesswrong.com/tag/coalitional-instincts?showPostCount=true&amp;useTagName=true\">Coalitional Instincts<\/a>, <a href=\"https://www.lesswrong.com/tag/decision-theory\">Decision theory<\/a>, <a href=\"https://www.lesswrong.com/tag/moloch?showPostCount=true&amp;useTagName=true\">Moloch<\/a>, <a href=\"https://www.lesswrong.com/tag/utility-functions\">Utility functions<\/a>, <a href=\"https://lessestwrong.com/tag/decision-theory\">Decision Theory<\/a>, <a href=\"https://lessestwrong.com/tag/prisoner-s-dilemma\">Prisoner's Dilemma<\/a><\/p><p>Game theory is an extremely powerful and robust tool in analyzing much more complex situations, such as: mergers and acquisitions, political economy, voting systems, war bargaining and biological evolution. Eight game-theorists have won the Nobel Prize in Economic Sciences.<\/p><h2>References<\/h2><ul><li><a href=\"http://levine.sscnet.ucla.edu/general/whatis.htm\">Nave introduction to Game Theory<\/a><\/li><li><a href=\"http://plato.stanford.edu/entries/game-theory/\">Stanford Encyclopedia entry on Game Theory<\/a><\/li><\/ul>"},"Tag:b8FHrKqyXuYGWc6vn":{"_id":"b8FHrKqyXuYGWc6vn","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:b8FHrKqyXuYGWc6vn_description"},"userId":"r38pkCm7wF4M44MDQ","name":"Game Theory","slug":"game-theory","core":null,"postCount":199,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":null,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-14T06:03:25.225Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:mf8wHrMrJR73uyDLQ_description":{"_id":"mf8wHrMrJR73uyDLQ_description","__typename":"Revision","htmlHighlight":"<p><strong>Moral Mazes <\/strong>is a term for businesses where middle managers spend most of their time and energy on internal status competitions rather than improving the company's products. The phrase comes from <a href=\"https://www.amazon.com/Moral-Mazes-World-Corporate-Managers/dp/0199729883\">the book of the same name<\/a> by Robert Jackall.<\/p><p>See also: <a href=\"https://www.lesswrong.com/tag/moloch\">Moloch<\/a> tag, and the <a href=\"https://www.lesswrong.com/s/kNANcHLNtJt5qeuSS\">Immoral Mazes sequence<\/a><\/p>"},"Tag:mf8wHrMrJR73uyDLQ":{"_id":"mf8wHrMrJR73uyDLQ","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:mf8wHrMrJR73uyDLQ_description"},"userId":"nLbwLhBaQeG6tCNDN","name":"Moral Mazes","slug":"moral-mazes","core":null,"postCount":42,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":null,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-05-24T03:24:45.912Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Tag:KoXbd2HmbdRfqLngk":{"_id":"KoXbd2HmbdRfqLngk","__typename":"Tag","parentTag":null,"subTags":[],"description":null,"userId":"qgdGA4ZEyW7zNdK84","name":"Planning & Decision-Making","slug":"planning-and-decision-making","core":false,"postCount":95,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-17T21:17:27.266Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:YSyvvi4uXvxAARX2D_description":{"_id":"YSyvvi4uXvxAARX2D_description","__typename":"Revision","htmlHighlight":"<p><strong>Slack<\/strong> is absence of binding constraints on behavior. The term is usually capitalized to distinguish it from the ordinary English meaning. Not to be confused with the communication app by the same name.<\/p><p>From the post which introduced this usage, <a href=\"https://www.lessestwrong.com/posts/yLLkWMDbC9ZNKbjDG/slack\">Slack<\/a><strong>:<\/strong><\/p><blockquote><p><i>Poor is the person without Slack. Lack of Slack compounds and traps.<\/i><\/p><p><i>Slack means margin for error. You can relax.<\/i><\/p><p><i>Slack allows pursuing opportunities. You can explore. You can trade.<\/i><\/p><p><i>Slack prevents desperation. You can avoid bad trades and wait for better spots. You can be efficient.<\/i><\/p><p><i>Slack permits planning for the long term. You can invest.<\/i><\/p><p><i>Slack enables doing things for your own amusement. You can play games. You can have fun.<\/i><\/p><p><i>Slack enables doing the right thing. Stand by your friends. Reward the worthy. Punish the wicked. You can have a code.<\/i><\/p><p><i>Slack presents things as they are without concern for how things look or what others think. You can be honest.<\/i><\/p><p><i>You can do some of these things, and choose not to do others. Because you dont have to.<\/i><\/p><p><i>Only with slack can one be a righteous dude.<\/i><\/p><p><i>Slack is life.<\/i><\/p><\/blockquote><p><strong>Related Sequence:<\/strong> <a href=\"https://www.lesswrong.com/s/HXkpm9b8o964jbQ89\">Slack and the Sabbath<\/a><\/p>"},"Tag:YSyvvi4uXvxAARX2D":{"_id":"YSyvvi4uXvxAARX2D","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:YSyvvi4uXvxAARX2D_description"},"userId":"nLbwLhBaQeG6tCNDN","name":"Slack","slug":"slack","core":null,"postCount":36,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":null,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-07T20:41:59.282Z","wikiOnly":false,"deleted":false,"isSubforum":null},"User:N9zj5qpTfqmbn9dro":{"_id":"N9zj5qpTfqmbn9dro","__typename":"User","biography":null,"profileImageId":null,"moderationStyle":"norm-enforcing","bannedUserIds":null,"moderatorAssistance":true,"slug":"zvi","createdAt":"2009-03-31T20:54:54.077Z","username":"Zvi","displayName":"Zvi","previousDisplayName":null,"fullName":null,"karma":29380,"afKarma":68,"deleted":false,"isAdmin":false,"htmlBio":"","postCount":526,"commentCount":1266,"sequenceCount":3,"afPostCount":1,"afCommentCount":2,"spamRiskScore":1,"tagRevisionCount":0},"Post:ENBzEkoyvdakz4w5d":{"_id":"ENBzEkoyvdakz4w5d","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:ENBzEkoyvdakz4w5d_"},"fmCrosspost":null,"readTimeMinutes":8,"moderationGuidelines":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:b8FHrKqyXuYGWc6vn"},{"__ref":"Tag:mf8wHrMrJR73uyDLQ"},{"__ref":"Tag:KoXbd2HmbdRfqLngk"},{"__ref":"Tag:YSyvvi4uXvxAARX2D"}],"url":null,"postedAt":"2017-09-23T10:50:00.185Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2018-01-30T00:32:03.501Z","meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":null,"commentCount":13,"voteCount":72,"baseScore":87,"extendedScore":null,"unlisted":false,"score":0.00038,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2022-05-01T17:59:31.043Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":false,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"N9zj5qpTfqmbn9dro","location":null,"googleLocation":null,"onlineEvent":null,"globalEvent":null,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":11,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":"2017-09-23T10:50:00.185Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":null,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":0,"reviewCount2019":null,"user":{"__ref":"User:N9zj5qpTfqmbn9dro"},"coauthors":[],"slug":"out-to-get-you","title":"Out to Get You","draft":false,"hideCommentKarma":null,"af":false,"currentUserReviewVote":null},"User:rx7xLaHCh3m7Po385":{"_id":"rx7xLaHCh3m7Po385","__typename":"User","displayName":"Buck","slug":"buck"},"Post:4QemtxDFaGXyGSrGD":{"_id":"4QemtxDFaGXyGSrGD","__typename":"Post","title":"\"Other people are wrong\" vs \"I am right\"","slug":"other-people-are-wrong-vs-i-am-right","user":{"__ref":"User:rx7xLaHCh3m7Po385"}},"Spotlight:arHKkuEjGdyfRnRoA":{"_id":"arHKkuEjGdyfRnRoA","__typename":"Spotlight","document":{"__ref":"Post:4QemtxDFaGXyGSrGD"},"description":{"__typename":"Revision","html":"<p>Concerningly, it can be much easier to spot holes in the arguments of others than it is in your own arguments. The author of this post reflects that historically, he's been too hasty to go from \"other people seem very wrong on this topic\" to \"I am right on this topic\".&nbsp;<\/p>"},"documentId":"4QemtxDFaGXyGSrGD","documentType":"Post","spotlightImageId":"xts2usk0njqacpww5fcr","spotlightDarkImageId":null,"draft":false,"position":2,"lastPromotedAt":"2023-02-10T12:00:00.000Z","customTitle":null,"customSubtitle":null,"duration":4,"showAuthor":true},"Revision:fqha7yX28KyN7eK6v_":{"_id":"fqha7yX28KyN7eK6v_","__typename":"Revision","htmlHighlight":"<p>We are inviting people who could foreseeably take a day trip to Philadelphia to an unconference on February 11th. Travel support is not in the budget this time around, but fill out the form anyway if that's a dealbreaker for you and we'll see what we can do.<\/p>\n<p>By unconference, we mean there will be around four separate areas with whiteboards, a blank grid at the beginning of the day where the rows are timeslots and the columns are the whiteboard areas, and people fill in the schedule on the fly with their sessions.<\/p>\n<p>By AI alignment, we roughly mean threatmodel-driven research agendas, people trying to prevent software from doing really bad things. We're expecting mostly CS and math people, but welcome more governancey people as well.<\/p>\n<p>Food is funded by <a href=\"https://www.alignmentforum.org/posts/LCypC3mdEPxXmHLGg/ai-safety-microgrant-initiative\">the recent microgrant round<\/a>.<\/p>\n<p>We are mildly gatekeeping this, and RSVPs are critical due to keycard access to venue. Please fill out <a href=\"https://forms.gle/2Gwo5axhZRehqVBi6\">this<\/a> form if you'd like to attend or are considering it. <s>Please fill out the form by January 25th<\/s> we still have slots, so are accepting late submissions.<\/p>","wordCount":181,"version":"1.1.0"},"Revision:fqha7yX28KyN7eK6v_moderationGuidelines":{"_id":"fqha7yX28KyN7eK6v_moderationGuidelines","__typename":"Revision","html":""},"Revision:qqwfzAYaLsfmkwbsK_biography":{"_id":"qqwfzAYaLsfmkwbsK_biography","__typename":"Revision","version":null,"updateType":null,"editedAt":"2023-02-10T16:22:42.187Z","userId":null,"html":"<p><a href=\"https://quinnd.net\">https://quinnd.net<\/a><\/p>\n","wordCount":null,"htmlHighlight":"<p><a href=\"https://quinnd.net\">https://quinnd.net<\/a><\/p>","plaintextDescription":"https://quinnd.net"},"User:qqwfzAYaLsfmkwbsK":{"_id":"qqwfzAYaLsfmkwbsK","__typename":"User","biography":{"__ref":"Revision:qqwfzAYaLsfmkwbsK_biography"},"profileImageId":null,"moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":null,"slug":"quinn-dougherty","createdAt":"2018-10-26T19:49:00.287Z","username":"quinn-dougherty","displayName":"Quinn","previousDisplayName":null,"fullName":"Quinn Dougherty","karma":574,"afKarma":15,"deleted":null,"isAdmin":false,"htmlBio":"<p><a href=\"https://quinnd.net\">https://quinnd.net<\/a><\/p>\n","postCount":26,"commentCount":119,"sequenceCount":0,"afPostCount":1,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":1},"Post:fqha7yX28KyN7eK6v":{"_id":"fqha7yX28KyN7eK6v","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:fqha7yX28KyN7eK6v_"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":1,"moderationGuidelines":{"__ref":"Revision:fqha7yX28KyN7eK6v_moderationGuidelines"},"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:sYm3HiWcfZvrGu3ui"},{"__ref":"Tag:izp6eeJJEg9v5zcur"}],"url":null,"postedAt":"2023-01-13T20:33:33.389Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"commentCount":1,"voteCount":2,"baseScore":7,"extendedScore":null,"unlisted":false,"score":0.004126590183976384,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2023-01-14T16:43:13.286Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"qqwfzAYaLsfmkwbsK","location":"Fishtown, Philadelphia, PA, USA","googleLocation":{"address_components":[{"long_name":"Fishtown","short_name":"Fishtown","types":["neighborhood","political"]},{"long_name":"Philadelphia","short_name":"Philadelphia","types":["locality","political"]},{"long_name":"Philadelphia County","short_name":"Philadelphia County","types":["administrative_area_level_2","political"]},{"long_name":"Pennsylvania","short_name":"PA","types":["administrative_area_level_1","political"]},{"long_name":"United States","short_name":"US","types":["country","political"]}],"adr_address":"Fishtown, <span class=\"locality\">Philadelphia<\/span>, <span class=\"region\">PA<\/span>, <span class=\"country-name\">USA<\/span>","formatted_address":"Fishtown, Philadelphia, PA, USA","geometry":{"location":{"lat":39.9709764,"lng":-75.1284805},"viewport":{"south":39.96293782995907,"west":-75.13737163464697,"north":39.98139336688968,"east":-75.11997784173452}},"icon":"https://maps.gstatic.com/mapfiles/place_api/icons/v1/png_71/geocode-71.png","icon_background_color":"#7B9EB0","icon_mask_base_uri":"https://maps.gstatic.com/mapfiles/place_api/icons/v2/generic_pinlet","name":"Fishtown","photos":[{"height":3024,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/106342486987386166301\">Celeste Peterson<\/a>"],"width":4032},{"height":3000,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/114778771960034673651\">HEY DRONIE&#39;S!<\/a>"],"width":4000},{"height":2268,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/115246051581383103475\">CT Trevor Weichmann<\/a>"],"width":4032},{"height":3780,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/102484166950880209733\">Yeho Bostick<\/a>"],"width":3024},{"height":3000,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/114778771960034673651\">HEY DRONIE&#39;S!<\/a>"],"width":4000},{"height":3780,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/102484166950880209733\">Yeho Bostick<\/a>"],"width":3024},{"height":3565,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/108114307597706562624\">Leanne M<\/a>"],"width":2968},{"height":2268,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/105494230675860525733\">J Robb<\/a>"],"width":2925},{"height":4032,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/108114307597706562624\">Leanne M<\/a>"],"width":3024},{"height":3761,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/102484166950880209733\">Yeho Bostick<\/a>"],"width":3009}],"place_id":"ChIJRUM_ZEHIxokRQtad17sEpIs","reference":"ChIJRUM_ZEHIxokRQtad17sEpIs","types":["neighborhood","political"],"url":"https://maps.google.com/?q=Fishtown,+Philadelphia,+PA,+USA&ftid=0x89c6c841643f4345:0x8ba404bbd79dd642","utc_offset":-300,"vicinity":"Philadelphia","html_attributions":[],"utc_offset_minutes":-300},"onlineEvent":false,"globalEvent":false,"startTime":"2023-02-11T17:00:00.000Z","endTime":"2023-02-11T23:00:00.000Z","localStartTime":"2023-02-11T12:00:00.000Z","localEndTime":"2023-02-11T18:00:00.000Z","eventRegistrationLink":"https://forms.gle/2Gwo5axhZRehqVBi6","joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":"brittany.gelb@rutgers.edu","isEvent":true,"eventImageId":null,"eventType":"conference","types":[],"groupId":null,"reviewedByUserId":"r38pkCm7wF4M44MDQ","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"afBaseScore":3,"afExtendedScore":null,"afCommentCount":null,"afLastCommentedAt":"2023-01-13T20:33:33.616Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":false,"shortform":false,"onlyVisibleToLoggedIn":false,"reviewCount":null,"reviewVoteCount":null,"positiveReviewVoteCount":null,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"user":{"__ref":"User:qqwfzAYaLsfmkwbsK"},"coauthors":[],"slug":"mid-atlantic-ai-alignment-alliance-unconference","title":"Mid-Atlantic AI Alignment Alliance Unconference","draft":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null},"Revision:ixdDmjQs3akxNfvFJ_":{"_id":"ixdDmjQs3akxNfvFJ_","__typename":"Revision","htmlHighlight":"<p>Come join us for our ongoing series of LessWrong Rationalist meetups on the Riverwalk!&nbsp;<\/p><p>Every fortnight, we'll be gathering at a different bar along the Riverwalk for an evening of stimulating discussion and networking. Each meetup will feature a discussion spotlight led by one of our members, where we'll delve deeper into a particular topic related to rationality, or just a topic of interest. Whether you're a seasoned veteran or new to the community, you'll find plenty to learn and share. Don't miss this opportunity to explore the concepts of rationality in a casual and relaxed setting, while enjoying the beautiful Riverwalk scenery. Come and join us and make connections with like-minded individuals.<\/p>","wordCount":113,"version":"1.0.0"},"Localgroup:CEPoFETJXADdriPGt":{"_id":"CEPoFETJXADdriPGt","__typename":"Localgroup","name":"San Antonio LessWrong","organizerIds":["5AtHSy3bWGCjpDN3v","yqtQDKCLsWG5yuy7j"]},"Revision:yqtQDKCLsWG5yuy7j_biography":{"_id":"yqtQDKCLsWG5yuy7j_biography","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2023-01-10T21:53:16.580Z","userId":"yqtQDKCLsWG5yuy7j","html":"","wordCount":0,"htmlHighlight":"","plaintextDescription":null},"User:yqtQDKCLsWG5yuy7j":{"_id":"yqtQDKCLsWG5yuy7j","__typename":"User","biography":{"__ref":"Revision:yqtQDKCLsWG5yuy7j_biography"},"profileImageId":null,"moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":null,"slug":"olivia-g","createdAt":"2021-07-26T01:41:22.219Z","username":"Ziviana","displayName":"Olivia G","previousDisplayName":"Ziviana","fullName":null,"karma":1,"afKarma":null,"deleted":null,"isAdmin":false,"htmlBio":"","postCount":2,"commentCount":null,"sequenceCount":null,"afPostCount":null,"afCommentCount":0,"spamRiskScore":0.9,"tagRevisionCount":null},"Post:ixdDmjQs3akxNfvFJ":{"_id":"ixdDmjQs3akxNfvFJ","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:ixdDmjQs3akxNfvFJ_"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":1,"moderationGuidelines":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[],"url":null,"postedAt":"2023-01-30T00:10:28.946Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"commentCount":null,"voteCount":1,"baseScore":1,"extendedScore":null,"unlisted":false,"score":0.0018615075225445823,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2023-01-30T00:10:28.946Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"yqtQDKCLsWG5yuy7j","location":"Elsewhere Garden Bar & Kitchen, East Jones Avenue, San Antonio, TX, USA","googleLocation":{"address_components":[{"long_name":"103","short_name":"103","types":["street_number"]},{"long_name":"East Jones Avenue","short_name":"E Jones Ave","types":["route"]},{"long_name":"Downtown","short_name":"Downtown","types":["neighborhood","political"]},{"long_name":"San Antonio","short_name":"San Antonio","types":["locality","political"]},{"long_name":"Bexar County","short_name":"Bexar County","types":["administrative_area_level_2","political"]},{"long_name":"Texas","short_name":"TX","types":["administrative_area_level_1","political"]},{"long_name":"United States","short_name":"US","types":["country","political"]},{"long_name":"78215","short_name":"78215","types":["postal_code"]},{"long_name":"1318","short_name":"1318","types":["postal_code_suffix"]}],"adr_address":"<span class=\"street-address\">103 E Jones Ave<\/span>, <span class=\"locality\">San Antonio<\/span>, <span class=\"region\">TX<\/span> <span class=\"postal-code\">78215-1318<\/span>, <span class=\"country-name\">USA<\/span>","business_status":"OPERATIONAL","current_opening_hours":{"open_now":false,"periods":[{"close":{"date":"2023-01-29","day":0,"time":"2200"},"open":{"date":"2023-01-29","day":0,"time":"1200"}},{"close":{"date":"2023-01-30","day":1,"time":"2200"},"open":{"date":"2023-01-30","day":1,"time":"1600"}},{"close":{"date":"2023-01-25","day":3,"time":"0000"},"open":{"date":"2023-01-24","day":2,"time":"1600"}},{"close":{"date":"2023-01-26","day":4,"time":"0000"},"open":{"date":"2023-01-25","day":3,"time":"1600"}},{"close":{"date":"2023-01-27","day":5,"time":"0000"},"open":{"date":"2023-01-26","day":4,"time":"1600"}},{"close":{"date":"2023-01-28","day":6,"time":"0000"},"open":{"date":"2023-01-27","day":5,"time":"1400"}},{"close":{"date":"2023-01-29","day":0,"time":"0100"},"open":{"date":"2023-01-28","day":6,"time":"1200"}}],"weekday_text":["Monday: 4:0010:00PM","Tuesday: 4:00PM12:00AM","Wednesday: 4:00PM12:00AM","Thursday: 4:00PM12:00AM","Friday: 2:00PM12:00AM","Saturday: 12:00PM1:00AM","Sunday: 12:0010:00PM"]},"formatted_address":"103 E Jones Ave, San Antonio, TX 78215, USA","formatted_phone_number":"(210) 446-9303","geometry":{"location":{"lat":29.4362751,"lng":-98.480581},"viewport":{"south":29.4349492197085,"west":-98.48181418029151,"north":29.4376471802915,"east":-98.47911621970849}},"icon":"https://maps.gstatic.com/mapfiles/place_api/icons/v1/png_71/bar-71.png","icon_background_color":"#FF9E67","icon_mask_base_uri":"https://maps.gstatic.com/mapfiles/place_api/icons/v2/bar_pinlet","international_phone_number":"+1 210-446-9303","name":"Elsewhere Garden Bar & Kitchen","opening_hours":{"open_now":false,"periods":[{"close":{"day":0,"time":"2200","hours":22,"minutes":0,"nextDate":1675051200000},"open":{"day":0,"time":"1200","hours":12,"minutes":0,"nextDate":1675015200000}},{"close":{"day":1,"time":"2200","hours":22,"minutes":0,"nextDate":1675137600000},"open":{"day":1,"time":"1600","hours":16,"minutes":0,"nextDate":1675116000000}},{"close":{"day":3,"time":"0000","hours":0,"minutes":0,"nextDate":1674626400000},"open":{"day":2,"time":"1600","hours":16,"minutes":0,"nextDate":1674597600000}},{"close":{"day":4,"time":"0000","hours":0,"minutes":0,"nextDate":1674712800000},"open":{"day":3,"time":"1600","hours":16,"minutes":0,"nextDate":1674684000000}},{"close":{"day":5,"time":"0000","hours":0,"minutes":0,"nextDate":1674799200000},"open":{"day":4,"time":"1600","hours":16,"minutes":0,"nextDate":1674770400000}},{"close":{"day":6,"time":"0000","hours":0,"minutes":0,"nextDate":1674885600000},"open":{"day":5,"time":"1400","hours":14,"minutes":0,"nextDate":1674849600000}},{"close":{"day":0,"time":"0100","hours":1,"minutes":0,"nextDate":1674975600000},"open":{"day":6,"time":"1200","hours":12,"minutes":0,"nextDate":1674928800000}}],"weekday_text":["Monday: 4:0010:00PM","Tuesday: 4:00PM12:00AM","Wednesday: 4:00PM12:00AM","Thursday: 4:00PM12:00AM","Friday: 2:00PM12:00AM","Saturday: 12:00PM1:00AM","Sunday: 12:0010:00PM"]},"photos":[{"height":1450,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/108026866471065539226\">Elsewhere Garden Bar &amp; Kitchen<\/a>"],"width":1170},{"height":768,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/108026866471065539226\">Elsewhere Garden Bar &amp; Kitchen<\/a>"],"width":960},{"height":3330,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/105419370524117873721\">Eva<\/a>"],"width":2821},{"height":659,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/108026866471065539226\">Elsewhere Garden Bar &amp; Kitchen<\/a>"],"width":1170},{"height":3024,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/105419370524117873721\">Eva<\/a>"],"width":4032},{"height":1984,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/105125482756553221339\">miguel pineda<\/a>"],"width":3132},{"height":2539,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/108026866471065539226\">Elsewhere Garden Bar &amp; Kitchen<\/a>"],"width":3806},{"height":4161,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/108026866471065539226\">Elsewhere Garden Bar &amp; Kitchen<\/a>"],"width":6238},{"height":3024,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/108026866471065539226\">Elsewhere Garden Bar &amp; Kitchen<\/a>"],"width":3024},{"height":3024,"html_attributions":["<a href=\"https://maps.google.com/maps/contrib/107879449203961975658\">Wendi the Wanderer<\/a>"],"width":4032}],"place_id":"ChIJ6Yjw6Iz1XIYRKShmHy0Qz_U","plus_code":{"compound_code":"CGP9+GQ San Antonio, TX, USA","global_code":"76X3CGP9+GQ"},"price_level":2,"rating":4.5,"reference":"ChIJ6Yjw6Iz1XIYRKShmHy0Qz_U","reviews":[{"author_name":"Megan Rokoski","author_url":"https://www.google.com/maps/contrib/117739738008190002054/reviews","language":"en","profile_photo_url":"https://lh3.googleusercontent.com/a-/AD5-WCmfnl0spV_1LzTK9fHK2GrZY5-pXjd2_lYlZsgidA=s128-c0x00000000-cc-rp-mo-ba6","rating":5,"relative_time_description":"4 months ago","text":"Super unique place with good vibes. Lots of cute art pieces that make great photos. HUGE amount of alcoholic drinks to choose from including beers, seltzers, and a few mixed drinks. We had two appetizers and they were both great. Loved the cauliflower wings. They had vegetarian options as well. You do order the food at one spot and the drinks at another spot. Loved the swings as seating options along the river. Overall had a great experience.","time":1662935480},{"author_name":"Alejo R","author_url":"https://www.google.com/maps/contrib/102439631933335107422/reviews","language":"en","profile_photo_url":"https://lh3.googleusercontent.com/a-/AD5-WCkWNQJVcAcdtGccctBAmbvPPGVlsXHro8XHfQr59yg=s128-c0x00000000-cc-rp-mo-ba5","rating":3,"relative_time_description":"9 months ago","text":"The place is like fairy tail, great ambiance, the view to the river is great. Also, the swings are a great addition. Colorful and the music is at perfect tone. The drinks are just drinks, they sell drinks on a different cute shack, I did not try any cocktails but the service was fast and courteous.\nThe food is terrible, this is the aspect that really get this place under the water. I ordered a salad and I truly believe they did not make any effort at all to create something that could speak for the place. Thats why I rated 3 stars.","time":1650896154},{"author_name":"Lynda Ramos","author_url":"https://www.google.com/maps/contrib/108898954129207877458/reviews","language":"en","profile_photo_url":"https://lh3.googleusercontent.com/a-/AD5-WCnCwsI3d4AN_grh1xHEKlmrR5Uo5409tIhj6YJlmWo=s128-c0x00000000-cc-rp-mo-ba4","rating":5,"relative_time_description":"8 months ago","text":"Great place to hangout with friends, family or your pet. Nice backgrounds for pics. Beautiful view of the San Antonio River. Plenty of covered seating. You order food on one side and drinks on the other. 5 min wait time for food, they text you when food is ready. You can order drinks while seated at table by scanning the bar code. We ordered a grilled chicken sandwich and Philly Cheese Steak sandwich, both were tasty. Pricing was reasonable. Parking is limited.","time":1651606753},{"author_name":"LeWayne Ballard","author_url":"https://www.google.com/maps/contrib/110664422027476548628/reviews","language":"en","profile_photo_url":"https://lh3.googleusercontent.com/a/AEdFTp7GavU1wQRriihpgLAQROYoag8DKZD3g-yWrk1D=s128-c0x00000000-cc-rp-mo-ba6","rating":5,"relative_time_description":"a year ago","text":"Been here several times from a weekend afternoon and weekday night.  Either time it is the same experience.  Nice outdoor area with many tables  in the central area and some overlooking the water.  It is usually pretty crowded, but the tables open up quickly.  There's usually live music that isn't too loud and allows you to have conversations at the table.  There are 2 walk-up bar areas with very friendly staff and great customer service.  One time they recognized me in line with an open tab, so came out and took my order in line.  That was very impressive customer service.  There is a wide range of beers and cocktails at a reasonable price.\n\nThe food truck on the side serves up a wide range of food from sandwiches, burgers, finger foods.  This is a great place to enjoy the outdoors over some food, drinks, and live music.  Great staff and always nicely decorated.  Not sure if all the time, but there's often vendors they support by allowing them to set-up their tables on their property.  Great way to support the local, small businesses.","time":1637204976},{"author_name":"Roy D","author_url":"https://www.google.com/maps/contrib/116543386022513665319/reviews","language":"en","profile_photo_url":"https://lh3.googleusercontent.com/a-/AD5-WCmpTkx71hnYhjezGl7YMWF43N0Qmlww9IeYAMbBUA=s128-c0x00000000-cc-rp-mo-ba4","rating":5,"relative_time_description":"5 months ago","text":"Amazing outdoor venue right on the Riverwalk. Huge selection of craft brews and signature cocktails as well as an awesome kitchen. This only has five stars because six was not an option. The Nashville Hot chicken was the best Ive had since Hattie Bs in Nashville itself. Margaritas were excellent too!  Im am definitely making this a must do stop when friends and family come to town.","time":1659214761}],"types":["bar","restaurant","food","point_of_interest","establishment"],"url":"https://maps.google.com/?cid=17712393645457811497","user_ratings_total":1113,"utc_offset":-360,"vicinity":"103 East Jones Avenue, San Antonio","website":"http://www.elsewheretexas.com/","html_attributions":[],"utc_offset_minutes":-360},"onlineEvent":false,"globalEvent":false,"startTime":"2023-02-12T01:00:00.000Z","endTime":"2023-02-12T04:00:00.000Z","localStartTime":"2023-02-11T19:00:00.000Z","localEndTime":"2023-02-11T22:00:00.000Z","eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":"https://www.meetup.com/rationality-san-antonio/events/291277879/","website":null,"contactInfo":null,"isEvent":true,"eventImageId":null,"eventType":null,"types":["LW","SSC","EA"],"groupId":"CEPoFETJXADdriPGt","reviewedByUserId":null,"suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"afBaseScore":0,"afExtendedScore":null,"afCommentCount":null,"afLastCommentedAt":"2023-01-30T00:10:29.110Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":false,"shortform":false,"onlyVisibleToLoggedIn":false,"reviewCount":null,"reviewVoteCount":null,"positiveReviewVoteCount":null,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":{"__ref":"Localgroup:CEPoFETJXADdriPGt"},"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"user":{"__ref":"User:yqtQDKCLsWG5yuy7j"},"coauthors":[],"slug":"fortnightly-meetup","title":"Fortnightly Meetup","draft":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null},"Revision:f4c3ku2haDWTLbEzX_":{"_id":"f4c3ku2haDWTLbEzX_","__typename":"Revision","html":"<p>Something to consider:<\/p>\n<p>Deep learning optimises over network parameter space directly.<\/p>\n<p>Evolution optimises over the genome, and our genome is highly compressed wrt e.g. exact synaptic connections and cell makeup of our brains.<\/p>\n<p>Optimising over a configuration space vs optimising over programs that produces configurations drawn from said space.<\/p>\n<p>That seems like a very important difference, and meaningfully affects the selection pressures exerted on the models<sup class=\"footnote-ref\"><a href=\"#fn-wvdoWEqYTc5dN2Po6-1\" id=\"fnref-wvdoWEqYTc5dN2Po6-1\">[1]<\/a><\/sup>.<\/p>\n<p>Furthermore, evolution does its optimisation via <em>unbounded<\/em> consequentialism in the real world.<\/p>\n<p>As far as I'm aware, the fitness horizon for the genes is indefinite and evaluations are based on the actual/exact consequences.<\/p>\n<p>&nbsp;<br>\nModern ML techniques seem disanalogous to evolution on multiple, important levels.<\/p>\n<p>And I get the sense that forecasts of AI timelines based on such analogies are mostly illegitimate.<\/p>\n<p>(I could also just be an idiot; I don't understand evolution or ML well.)<\/p>\n<p>&nbsp;<br>\nI don't actually know what all these means for timelines, takeoff or whether deep learning scales to AGI.<\/p>\n<p>But it seems plausible to me that the effective optimisation applied by evolution in creating humans is grossly underestimated (wrong meta order of magnitude).<\/p>\n<p>&nbsp;<\/p>\n<blockquote><\/blockquote>\n<hr class=\"footnotes-sep\">\n<section class=\"footnotes\">\n<ol class=\"footnotes-list\">\n<li id=\"fn-wvdoWEqYTc5dN2Po6-1\" class=\"footnote-item\"><p>By selecting on the genome instead of on parameter space, evolution is selecting heavily for minimising description length and hence highly compressed versions of generally capable agent policies. This seems to  exert stronger effective selection pressure for policies that contain optimisers than is exerted in deep learning.<br>\nThis might be a contributing factor wrt sample efficiency of human brains vs deep learning. <a href=\"#fnref-wvdoWEqYTc5dN2Po6-1\" class=\"footnote-backref\"><\/a><\/p>\n<\/li>\n<\/ol>\n<\/section>\n","plaintextMainText":"Something to consider:\n\nDeep learning optimises over network parameter space directly.\n\nEvolution optimises over the genome, and our genome is highly compressed wrt\ne.g. exact synaptic connections and cell makeup of our brains.\n\nOptimising over a configuration space vs optimising over programs that produces\nconfigurations drawn from said space.\n\nThat seems like a very important difference, and meaningfully affects the\nselection pressures exerted on the models[1].\n\nFurthermore, evolution does its optimisation via unbounded consequentialism in\nthe real world.\n\nAs far as I'm aware, the fitness horizon for the genes is indefinite and\nevaluations are based on the actual/exact consequences.\n\n\nModern ML techniques seem disanalogous to evolution on multiple, important\nlevels.\n\nAnd I get the sense that forecasts of AI timelines based on such analogies are\nmostly illegitimate.\n\n(I could also just be an idiot; I don't understand evolution or ML well.)\n\n\nI don't actually know what all these means for timelines, takeoff or whether\ndeep learning scales to AGI.\n\nBut it seems plausible to me that the effective optimisation applied by\nevolution in creating humans is grossly underestimated (wrong meta order of\nmagnitude).\n\n\n\n--------------------------------------------------------------------------------\n\n 1. By selecting on the genome instead of on parameter space, evolution is\n    selecting heavily for minimising description length and hence highly\n    compressed versions of generally capable agent policies. This seems to exert\n    stronger effective selection pressure for policies that contain optimisers\n    than is exerted in deep learning.\n    This might be a contributing factor wrt sample efficiency of human brains vs\n    deep learning. ","wordCount":250},"User:quAoHT9X7qMDBmA3z":{"_id":"quAoHT9X7qMDBmA3z","__typename":"User","slug":"dragongod","createdAt":"2017-03-22T19:17:42.674Z","username":"DragonGod","displayName":"DragonGod","previousDisplayName":"","fullName":"Cinera Verinia","karma":1504,"afKarma":23,"deleted":false,"isAdmin":false,"htmlBio":"<p>Theoretical Computer Science Msc student at the University of [Redacted] in the United Kingdom.&nbsp;<br><br>I'm an aspiring alignment theorist; my<a href=\"https://www.lesswrong.com/posts/4jqmjuzpZS8s5XnvB/why-theorems-a-personal-perspective\"> research vibes<\/a> are <a href=\"https://www.lesswrong.com/posts/nzRh8yQHi3bx9bLsD/normative-vs-descriptive-models-of-agency-2\">descriptive<\/a> <i>formal<\/i> theories of intelligent systems (and their safety properties) with a bias towards constructive theories.<br><br>I think it's important that our theories of intelligent systems remain rooted in the characteristics of real world intelligent systems; <a href=\"https://www.lesswrong.com/posts/zhhYwM7gk8LZsDzxj/dragongod-s-shortform?commentId=s3SGkk7m9EFJjCoBh\">we cannot develop adequate theory from the null string as input<\/a>.<\/p>","postCount":72,"commentCount":630,"sequenceCount":null,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":4,"biography":{"__ref":"Revision:quAoHT9X7qMDBmA3z_biography"},"profileImageId":null,"moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":true},"Comment:f4c3ku2haDWTLbEzX":{"_id":"f4c3ku2haDWTLbEzX","__typename":"Comment","postId":"zhhYwM7gk8LZsDzxj","tagId":null,"tag":null,"tagCommentType":"DISCUSSION","parentCommentId":null,"topLevelCommentId":null,"descendentCount":0,"title":null,"contents":{"__ref":"Revision:f4c3ku2haDWTLbEzX_"},"postedAt":"2023-02-10T16:20:07.467Z","repliesBlockedUntil":null,"userId":"quAoHT9X7qMDBmA3z","deleted":false,"deletedPublic":false,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:quAoHT9X7qMDBmA3z"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":2,"extendedScore":null,"score":35.98010089928569,"voteCount":1,"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"needsReview":null,"answer":false,"parentAnswerId":null,"retracted":false,"postVersion":"1.0.0","reviewedByUserId":null,"shortform":true,"lastSubthreadActivity":"2023-02-10T16:20:07.661Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":null,"votingSystem":"default","isPinnedOnProfile":false},"Revision:rKiZcEeFK9cp9zJ9f_":{"_id":"rKiZcEeFK9cp9zJ9f_","__typename":"Revision","html":"<h1>Revealed Timelines<\/h1>\n<p>Shorter timelines feel real to me.<\/p>\n<p>I don't think I expect AGI pre 2030, but I notice that my life plans are not premised on ignoring/granting minimal weight to pre 2030 timelines (e.g. I don't know if I'll pursue a PhD despite planning to last year and finding the prospect of a PhD very appealing [I really enjoy the student life (especially the social contact) and getting paid to learn/research is appealing]).<\/p>\n<p>After completing my TCS masters, I (currently) plan to take a year or two to pursue independent research and see how much progress I make. I might decide to pursue a PhD afterwards if I judge it beneficial in order to make progress on my research agendas (broadly, <a href=\"https://www.lesswrong.com/posts/nzRh8yQHi3bx9bLsD/normative-vs-descriptive-models-of-agency-2\">descriptive<\/a> <a href=\"https://www.lesswrong.com/posts/nzRh8yQHi3bx9bLsD/normative-vs-descriptive-models-of-agency-2\"><em>formal<\/em> theories<\/a> of intelligent systems with the hope of iterating towards constructive theories) [and expect to have enough time] but it's not an opportunity cost I want to pay upfront.<\/p>\n<p>This suggests my revealed timelines are shorter than I'd have guessed. <\/p>\n<p>&nbsp;<br>\n[A caveat to the above is that my immigration status may force the choice upon me if e.g. I need to legibly be a very high skilled worker, though maybe an Msc is enough?]<\/p>\n","plaintextMainText":"REVEALED TIMELINES\n\nShorter timelines feel real to me.\n\nI don't think I expect AGI pre 2030, but I notice that my life plans are not\npremised on ignoring/granting minimal weight to pre 2030 timelines (e.g. I don't\nknow if I'll pursue a PhD despite planning to last year and finding the prospect\nof a PhD very appealing [I really enjoy the student life (especially the social\ncontact) and getting paid to learn/research is appealing]).\n\nAfter completing my TCS masters, I (currently) plan to take a year or two to\npursue independent research and see how much progress I make. I might decide to\npursue a PhD afterwards if I judge it beneficial in order to make progress on my\nresearch agendas (broadly, descriptive\n[https://www.lesswrong.com/posts/nzRh8yQHi3bx9bLsD/normative-vs-descriptive-models-of-agency-2]\nformal theories\n[https://www.lesswrong.com/posts/nzRh8yQHi3bx9bLsD/normative-vs-descriptive-models-of-agency-2]\nof intelligent systems with the hope of iterating towards constructive theories)\n[and expect to have enough time] but it's not an opportunity cost I want to pay\nupfront.\n\nThis suggests my revealed timelines are shorter than I'd have guessed. \n\n\n[A caveat to the above is that my immigration status may force the choice upon\nme if e.g. I need to legibly be a very high skilled worker, though maybe an Msc\nis enough?]","wordCount":201},"Comment:rKiZcEeFK9cp9zJ9f":{"_id":"rKiZcEeFK9cp9zJ9f","__typename":"Comment","postId":"zhhYwM7gk8LZsDzxj","tagId":null,"tag":null,"tagCommentType":"DISCUSSION","parentCommentId":null,"topLevelCommentId":null,"descendentCount":0,"title":null,"contents":{"__ref":"Revision:rKiZcEeFK9cp9zJ9f_"},"postedAt":"2023-02-10T02:02:08.668Z","repliesBlockedUntil":null,"userId":"quAoHT9X7qMDBmA3z","deleted":false,"deletedPublic":false,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:quAoHT9X7qMDBmA3z"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":2,"extendedScore":null,"score":0.2822572978591796,"voteCount":1,"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"needsReview":null,"answer":false,"parentAnswerId":null,"retracted":false,"postVersion":"1.0.0","reviewedByUserId":null,"shortform":true,"lastSubthreadActivity":"2023-02-10T02:02:08.671Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":null,"votingSystem":"default","isPinnedOnProfile":false},"Revision:quAoHT9X7qMDBmA3z_biography":{"_id":"quAoHT9X7qMDBmA3z_biography","__typename":"Revision","version":"1.14.0","updateType":"minor","editedAt":"2023-02-10T08:19:15.525Z","userId":"quAoHT9X7qMDBmA3z","html":"<p>Theoretical Computer Science Msc student at the University of [Redacted] in the United Kingdom.&nbsp;<br><br>I'm an aspiring alignment theorist; my<a href=\"https://www.lesswrong.com/posts/4jqmjuzpZS8s5XnvB/why-theorems-a-personal-perspective\"> research vibes<\/a> are <a href=\"https://www.lesswrong.com/posts/nzRh8yQHi3bx9bLsD/normative-vs-descriptive-models-of-agency-2\">descriptive<\/a> <i>formal<\/i> theories of intelligent systems (and their safety properties) with a bias towards constructive theories.<br><br>I think it's important that our theories of intelligent systems remain rooted in the characteristics of real world intelligent systems; <a href=\"https://www.lesswrong.com/posts/zhhYwM7gk8LZsDzxj/dragongod-s-shortform?commentId=s3SGkk7m9EFJjCoBh\">we cannot develop adequate theory from the null string as input<\/a>.<\/p>","wordCount":70,"htmlHighlight":"<p>Theoretical Computer Science Msc student at the University of [Redacted] in the United Kingdom.&nbsp;<br><br>I'm an aspiring alignment theorist; my<a href=\"https://www.lesswrong.com/posts/4jqmjuzpZS8s5XnvB/why-theorems-a-personal-perspective\"> research vibes<\/a> are <a href=\"https://www.lesswrong.com/posts/nzRh8yQHi3bx9bLsD/normative-vs-descriptive-models-of-agency-2\">descriptive<\/a> <i>formal<\/i> theories of intelligent systems (and their safety properties) with a bias towards constructive theories.<br><br>I think it's important that our theories of intelligent systems remain rooted in the characteristics of real world intelligent systems; <a href=\"https://www.lesswrong.com/posts/zhhYwM7gk8LZsDzxj/dragongod-s-shortform?commentId=s3SGkk7m9EFJjCoBh\">we cannot develop adequate theory from the null string as input<\/a>.<\/p>","plaintextDescription":"Theoretical Computer Science Msc student at the University of [Redacted] in the United Kingdom.\n\nI'm an aspiring alignment theorist; my research vibes are descriptive formal theories of intelligent systems (and their safety properties) with a bias towards constructive theories.\n\nI think it's important that our theories of intelligent systems remain rooted in the characteristics of real world intelligent systems; we cannot develop adequate theory from the null string as input."},"Post:zhhYwM7gk8LZsDzxj":{"_id":"zhhYwM7gk8LZsDzxj","__typename":"Post","recentComments({\"af\":false,\"commentsLimit\":4,\"maxAgeHours\":18})":[{"__ref":"Comment:f4c3ku2haDWTLbEzX"},{"__ref":"Comment:rKiZcEeFK9cp9zJ9f"}],"deletedDraft":false,"contents":null,"fmCrosspost":null,"readTimeMinutes":1,"moderationGuidelines":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[],"url":null,"postedAt":"2022-05-31T19:01:29.511Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":null,"commentCount":113,"voteCount":1,"baseScore":4,"extendedScore":null,"unlisted":false,"score":0.0006771921410190577,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2023-02-10T16:20:09.067Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"quAoHT9X7qMDBmA3z","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":null,"suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":0,"afExtendedScore":null,"afCommentCount":null,"afLastCommentedAt":"2022-05-31T19:01:29.511Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":true,"shortform":true,"onlyVisibleToLoggedIn":false,"reviewCount":null,"reviewVoteCount":null,"positiveReviewVoteCount":null,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"user":{"__ref":"User:quAoHT9X7qMDBmA3z"},"coauthors":[],"slug":"dragongod-s-shortform","title":"DragonGod's Shortform","draft":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null},"Revision:v89Qcvq3at9M3vxm5_":{"_id":"v89Qcvq3at9M3vxm5_","__typename":"Revision","html":"<p>Paid Twitter blue seems to be quite competitive. The algorithm could just weigh paid Twitter blue users more highly than users that aren't Twitter blue.<\/p><p>As far as Megacorps go, Youtube likely wouldn't want this for its video ranking, but it might want it for the comment sections of videos. If the EigenKarma from the owner of a Youtube channel would set the ranking of comments within Youtube that would increase the comment quality by a lot.&nbsp;<\/p>","plaintextMainText":"Paid Twitter blue seems to be quite competitive. The algorithm could just weigh\npaid Twitter blue users more highly than users that aren't Twitter blue.\n\nAs far as Megacorps go, Youtube likely wouldn't want this for its video ranking,\nbut it might want it for the comment sections of videos. If the EigenKarma from\nthe owner of a Youtube channel would set the ranking of comments within Youtube\nthat would increase the comment quality by a lot.","wordCount":77},"User:vbDMpDA5A35329Ju5":{"_id":"vbDMpDA5A35329Ju5","__typename":"User","slug":"christiankl","createdAt":"2009-10-13T22:32:16.589Z","username":"ChristianKl","displayName":"ChristianKl","previousDisplayName":null,"fullName":"Christian Kleineidam","karma":31941,"afKarma":7,"deleted":false,"isAdmin":false,"htmlBio":"","postCount":206,"commentCount":14892,"sequenceCount":5,"afPostCount":1,"afCommentCount":1,"spamRiskScore":1,"tagRevisionCount":7},"Comment:v89Qcvq3at9M3vxm5":{"_id":"v89Qcvq3at9M3vxm5","__typename":"Comment","postId":"Fu7bqAyCMjfcMzBah","tagId":null,"tag":null,"tagCommentType":"DISCUSSION","parentCommentId":"AhtrRBxiwxLckJNFx","topLevelCommentId":"naASNRpWuuDd34Fwe","descendentCount":0,"title":null,"contents":{"__ref":"Revision:v89Qcvq3at9M3vxm5_"},"postedAt":"2023-02-10T16:07:38.855Z","repliesBlockedUntil":null,"userId":"vbDMpDA5A35329Ju5","deleted":false,"deletedPublic":false,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:vbDMpDA5A35329Ju5"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":2,"extendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"score":26.301300341904938,"voteCount":1,"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"needsReview":null,"answer":false,"parentAnswerId":null,"retracted":false,"postVersion":"1.3.1","reviewedByUserId":null,"shortform":false,"lastSubthreadActivity":"2023-02-10T16:07:38.858Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":null,"votingSystem":"twoAxis","isPinnedOnProfile":false},"Revision:gFizekRRMG8aHusAk_":{"_id":"gFizekRRMG8aHusAk_","__typename":"Revision","html":"<p>I am not sure if the unified \"trust\", let alone \"transitive trust\" makes sense. People can be experts on something, and uninformed about something else. There are people I trust in the sense \"they wouldn't stab me in the back\", but I do not trust their trust in homeopathics or Jesus. In context of LessWrong, I would hate to see my upvotes of someone's articles on math translated as my indirect support of Buddhism.<\/p>","plaintextMainText":"I am not sure if the unified \"trust\", let alone \"transitive trust\" makes sense.\nPeople can be experts on something, and uninformed about something else. There\nare people I trust in the sense \"they wouldn't stab me in the back\", but I do\nnot trust their trust in homeopathics or Jesus. In context of LessWrong, I would\nhate to see my upvotes of someone's articles on math translated as my indirect\nsupport of Buddhism.","wordCount":74},"User:yGwDggdsbvyLf49wm":{"_id":"yGwDggdsbvyLf49wm","__typename":"User","slug":"viliam","createdAt":"2015-04-03T12:09:31.950Z","username":"Viliam","displayName":"Viliam","previousDisplayName":null,"fullName":null,"karma":18084,"afKarma":1,"deleted":false,"isAdmin":false,"htmlBio":"","postCount":44,"commentCount":4155,"sequenceCount":null,"afPostCount":0,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0},"Comment:gFizekRRMG8aHusAk":{"_id":"gFizekRRMG8aHusAk","__typename":"Comment","postId":"Fu7bqAyCMjfcMzBah","tagId":null,"tag":null,"tagCommentType":"DISCUSSION","parentCommentId":null,"topLevelCommentId":null,"descendentCount":0,"title":null,"contents":{"__ref":"Revision:gFizekRRMG8aHusAk_"},"postedAt":"2023-02-10T14:31:47.044Z","repliesBlockedUntil":null,"userId":"yGwDggdsbvyLf49wm","deleted":false,"deletedPublic":false,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:yGwDggdsbvyLf49wm"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":4,"extendedScore":{"approvalVoteCount":2,"agreement":0,"agreementVoteCount":0},"score":8.414461919992373,"voteCount":2,"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":2,"afExtendedScore":{"approvalVoteCount":2,"agreement":0,"agreementVoteCount":0},"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"needsReview":null,"answer":false,"parentAnswerId":null,"retracted":false,"postVersion":"1.3.1","reviewedByUserId":null,"shortform":false,"lastSubthreadActivity":"2023-02-10T14:31:47.114Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":null,"votingSystem":"twoAxis","isPinnedOnProfile":false},"Revision:NpuB4goe6TBvwEoqQ_":{"_id":"NpuB4goe6TBvwEoqQ_","__typename":"Revision","html":"<p>There have been experiments with attack-resistant trust metrics before. One notable project was <a href=\"https://en.wikipedia.org/wiki/Advogato\">Advogato<\/a>. It failed and I'm not sure why. It's archived now. Maybe because it didn't create individual graphs. It might be worthwhile to look into <a href=\"http://5go.es/trust-metric.html\">Advogato's Trust Metric<\/a>.<\/p>","plaintextMainText":"There have been experiments with attack-resistant trust metrics before. One\nnotable project was Advogato [https://en.wikipedia.org/wiki/Advogato]. It failed\nand I'm not sure why. It's archived now. Maybe because it didn't create\nindividual graphs. It might be worthwhile to look into Advogato's Trust Metric\n[http://5go.es/trust-metric.html].","wordCount":41},"User:qmJFRN7jitjPsuF3f":{"_id":"qmJFRN7jitjPsuF3f","__typename":"User","slug":"gunnar_zarncke","createdAt":"2013-07-20T15:40:42.323Z","username":"Gunnar_Zarncke","displayName":"Gunnar_Zarncke","previousDisplayName":null,"fullName":"Gunnar Zarncke","karma":8500,"afKarma":16,"deleted":false,"isAdmin":false,"htmlBio":"<p>Software engineering, parenting, cognition, meditation, other<br><a href=\"https://www.linkedin.com/in/gunnar-zarncke-952134163/\">Linkedin<\/a>, <a href=\"https://www.facebook.com/gunnar.zarncke/ \">Facebook<\/a>, <a href=\"https://www.admonymous.co/gunnar_zarncke \">Admonymous<\/a> (anonymous feedback)<\/p>","postCount":121,"commentCount":3190,"sequenceCount":null,"afPostCount":1,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":22},"Comment:NpuB4goe6TBvwEoqQ":{"_id":"NpuB4goe6TBvwEoqQ","__typename":"Comment","postId":"Fu7bqAyCMjfcMzBah","tagId":null,"tag":null,"tagCommentType":"DISCUSSION","parentCommentId":null,"topLevelCommentId":null,"descendentCount":0,"title":null,"contents":{"__ref":"Revision:NpuB4goe6TBvwEoqQ_"},"postedAt":"2023-02-10T08:24:45.051Z","repliesBlockedUntil":null,"userId":"qmJFRN7jitjPsuF3f","deleted":false,"deletedPublic":false,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:qmJFRN7jitjPsuF3f"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":2,"extendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"score":0.4981870219193022,"voteCount":1,"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"needsReview":null,"answer":false,"parentAnswerId":null,"retracted":false,"postVersion":"1.3.1","reviewedByUserId":null,"shortform":false,"lastSubthreadActivity":"2023-02-10T08:24:45.056Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":null,"votingSystem":"twoAxis","isPinnedOnProfile":false},"Revision:yGnkKyQf5iA6fc4Pk_":{"_id":"yGnkKyQf5iA6fc4Pk_","__typename":"Revision","html":"<p>The EigenKarma method doesn't depend on upvotes as a means to define the trust graph. Upvotes are just a very easy way to collect it. Maybe too easy. The core idea of EigenKarma seems to be the individual graphs and its combination and the provisioning as a service. Maybe the distinction could be made more clear.&nbsp;<\/p>","plaintextMainText":"The EigenKarma method doesn't depend on upvotes as a means to define the trust\ngraph. Upvotes are just a very easy way to collect it. Maybe too easy. The core\nidea of EigenKarma seems to be the individual graphs and its combination and the\nprovisioning as a service. Maybe the distinction could be made more clear.","wordCount":56},"Comment:yGnkKyQf5iA6fc4Pk":{"_id":"yGnkKyQf5iA6fc4Pk","__typename":"Comment","postId":"Fu7bqAyCMjfcMzBah","tagId":null,"tag":null,"tagCommentType":"DISCUSSION","parentCommentId":"knq2vtyjTYmjuWTvY","topLevelCommentId":"knq2vtyjTYmjuWTvY","descendentCount":0,"title":null,"contents":{"__ref":"Revision:yGnkKyQf5iA6fc4Pk_"},"postedAt":"2023-02-10T08:23:43.404Z","repliesBlockedUntil":null,"userId":"qmJFRN7jitjPsuF3f","deleted":false,"deletedPublic":false,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:qmJFRN7jitjPsuF3f"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":4,"extendedScore":{"approvalVoteCount":2,"agreement":0,"agreementVoteCount":0},"score":0.6386474896193503,"voteCount":2,"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":2,"afExtendedScore":{"approvalVoteCount":2,"agreement":0,"agreementVoteCount":0},"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"needsReview":null,"answer":false,"parentAnswerId":null,"retracted":false,"postVersion":"1.3.1","reviewedByUserId":null,"shortform":false,"lastSubthreadActivity":"2023-02-10T08:23:43.409Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":null,"votingSystem":"twoAxis","isPinnedOnProfile":false},"Revision:Fu7bqAyCMjfcMzBah_":{"_id":"Fu7bqAyCMjfcMzBah_","__typename":"Revision","htmlHighlight":"<p>Upvotes or likes have become a standard way to filter information online. The quality of this filter is determined by the users handing out the upvotes.&nbsp;<\/p><p>For this reason, the archetypal pattern of online communities is one of gradual decay. People are more likely to join communities where users are more skilled than they are. As communities grow, the skill of the median user goes down. The capacity to filter for quality deteriorates. Simpler, more memetic content drives out more complex thinking. Malicious actors manipulate the rankings through fake votes and the like.<\/p><p>This is a problem that will get&nbsp;<a href=\"https://maggieappleton.com/ai-dark-forest#a-generated-web\"><u>increasingly pressing<\/u><\/a> as powerful AI models start coming online. To ensure our capacity to make intellectual progress under those conditions, we should take measures to future-proof our public communication channels.<\/p><p>One solution is redesigning the karma system in such a way that you can decide whose upvotes you see.<\/p><p>In this post, Im going to detail a prototype of this type of karma system, which has been built by volunteers in&nbsp;<a href=\"https://alignment.dev/\"><u>Alignment Ecosystem Development<\/u><\/a>. EigenKarma allows each user to define a&nbsp;<i>personal trust graph<\/i> based on their upvote history.&nbsp;<\/p><h2>EigenKarma<\/h2><p>At first glance, EigenKarma behaves like normal karma. If you like something, you upvote it.&nbsp;<\/p><p>The key difference is that in EigenKarma, every user has a&nbsp;<i>personal trust graph<\/i>. If you look at my profile, you will see the karma assigned to me by the people in your trust network. There is no global karma score.&nbsp;<\/p><p>If we imagine this trust graph powering a feed, and I have gamed the algorithm and gotten a million upvotes, that doesnt matter; my blog post wont filter through to you anyway, since you do not put any weight on the judgment of the anonymous masses.<\/p><p>If you upvote someone you dont know, they are attached to your trust graph. This can be interpreted as a tiny signal that you trust them:&nbsp;<\/p><p><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675882345/mirroredImages/Fu7bqAyCMjfcMzBah/cynppujeckuklgvzpppi.png\"><\/p><p>That trust will also spread to the users they trust in turn. If they trust user X, for example, you too trust Xa little:<\/p><p><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675882345/mirroredImages/Fu7bqAyCMjfcMzBah/pfahw4lriqjijgpmv6vh.png\"><\/p><p>This is how we intuitively reason about trust when thinking about our friends and the friends of our friends. Only EigenKarma being a database, it can remember and compile more data than you, so it can keep track of more than a Dunbars number of relationships. It scales trust. Karma propagates outward through the network from trusted node to trusted node.<\/p><p>Once y... <\/p>","wordCount":1395,"version":"1.3.1"},"Revision:Fu7bqAyCMjfcMzBah_moderationGuidelines":{"_id":"Fu7bqAyCMjfcMzBah_moderationGuidelines","__typename":"Revision","html":""},"Revision:KN9KEMgyBHjcAyc26_description":{"_id":"KN9KEMgyBHjcAyc26_description","__typename":"Revision","htmlHighlight":"<p><strong>Trust and reputation&nbsp;<\/strong><\/p><p><strong>Related Pages: <\/strong><a href=\"https://www.lesswrong.com/tag/expertise-topic\">Expertise (topic)<\/a>, <a href=\"https://www.lesswrong.com/tag/courage\">Courage<\/a>, <a href=\"https://www.lesswrong.com/tag/groupthink\">Groupthink<\/a>, <a href=\"https://www.lesswrong.com/tag/relationships-interpersonal\">Relationships (Interpersonal)<\/a>, <a href=\"https://www.lesswrong.com/tag/social-and-cultural-dynamics\">Social &amp; Cultural Dynamics<\/a>&nbsp;<\/p>"},"Tag:KN9KEMgyBHjcAyc26":{"_id":"KN9KEMgyBHjcAyc26","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:KN9KEMgyBHjcAyc26_description"},"userId":"SsduPgHwY2zeZpmKT","name":"Trust and Reputation","slug":"trust-and-reputation","core":false,"postCount":21,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-08-19T22:28:49.172Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:TkZ7MFwCi4D63LJ5n_description":{"_id":"TkZ7MFwCi4D63LJ5n_description","__typename":"Revision","htmlHighlight":"<p>Specific pieces of software (downloadable or cloud/browser-based) that may be of interest to people on this site. The focus is on software with a practical application: for games, see <a href=\"https://www.lesswrong.com/tag/gaming-videogames-tabletop\">Gaming (videogames/tabletop)<\/a>.<\/p><p><strong>Related Sequences:<\/strong> <a href=\"https://www.lesswrong.com/s/vz9Zrj3oBGsttG3Jh\">Kickstarter for Coordinated Action<\/a><\/p>"},"Tag:TkZ7MFwCi4D63LJ5n":{"_id":"TkZ7MFwCi4D63LJ5n","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:TkZ7MFwCi4D63LJ5n_description"},"userId":"qxJ28GN72aiJu96iF","name":"Software Tools","slug":"software-tools","core":false,"postCount":138,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-12T16:58:17.212Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:ipJwbLxhR83ZksN6Z_description":{"_id":"ipJwbLxhR83ZksN6Z_description","__typename":"Revision","htmlHighlight":"<p><strong>Mechanism Design<\/strong> is the theory of how to design <a href=\"https://www.lesswrong.com/tag/incentives\">incentives<\/a> for strategic agents, such that the agents acting according to their selfish interests will result in a desired outcome. It can be applied to things like institution design, <a href=\"https://www.lesswrong.com/tag/voting-theory\">voting systems<\/a>, school admissions, regulation of monopolists, market design, and auction design. Think of it as the engineering side of game theory, thinking backward from a desired goal, and designing structures that lead strategic agents to behave in a way that achieves that goal.<\/p><h3>Important Concepts<\/h3><ul><li><strong>Incentive Compatibility:<\/strong> <a href=\"https://en.wikipedia.org/wiki/Incentive_compatibility\">Wikipedia<\/a>, <a href=\"https://www.lesswrong.com/s/Yh4YsGDD9WYiZqRnf/p/N4gDA5HPpGC4mbTEZ\">LessWrong<\/a><\/li><li><strong>Revelation Principle:<\/strong> <a href=\"https://en.wikipedia.org/wiki/Revelation_principle\">Wikipedia<\/a>, <a href=\"https://www.lesswrong.com/s/Yh4YsGDD9WYiZqRnf/p/N4gDA5HPpGC4mbTEZ\">LessWrong<\/a><\/li><\/ul><p><strong>Related Pages:<\/strong> <a href=\"https://www.lesswrong.com/tag/game-theory\">Game Theory<\/a>, <a href=\"https://www.lesswrong.com/tag/incentives\">Incentives<\/a>, <a href=\"https://www.lesswrong.com/tag/principal-agent-problems\">Principal-Agent Problems<\/a>, <a href=\"https://www.lesswrong.com/tag/cryptocurrency-and-blockchain\">Cryptocurrencies and blockchain<\/a>, <a href=\"https://www.lesswrong.com/tag/public-discourse\">Public discourse<\/a><\/p><p><strong>Related Sequences: <\/strong><a href=\"https://www.lesswrong.com/s/Yh4YsGDD9WYiZqRnf\">Mechanism Design<\/a><\/p>"},"Tag:ipJwbLxhR83ZksN6Z":{"_id":"ipJwbLxhR83ZksN6Z","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:ipJwbLxhR83ZksN6Z_description"},"userId":"r38pkCm7wF4M44MDQ","name":"Mechanism Design","slug":"mechanism-design","core":false,"postCount":107,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-26T19:23:55.835Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:mpsskhizpeqNqZgkZ_biography":{"_id":"mpsskhizpeqNqZgkZ_biography","__typename":"Revision","version":null,"updateType":null,"editedAt":"2023-02-10T16:22:42.350Z","userId":null,"html":"<p><a href=\"https://escapingflatland.substack.com/\">https://escapingflatland.substack.com/<\/a><\/p>\n<p><a href=\"https://twitter.com/phokarlsson\">https://twitter.com/phokarlsson<\/a><\/p>\n","wordCount":null,"htmlHighlight":"<p><a href=\"https://escapingflatland.substack.com/\">https://escapingflatland.substack.com/<\/a><\/p>\n<p><a href=\"https://twitter.com/phokarlsson\">https://twitter.com/phokarlsson<\/a><\/p>","plaintextDescription":"https://escapingflatland.substack.com/\n\nhttps://twitter.com/phokarlsson"},"User:mpsskhizpeqNqZgkZ":{"_id":"mpsskhizpeqNqZgkZ","__typename":"User","biography":{"__ref":"Revision:mpsskhizpeqNqZgkZ_biography"},"profileImageId":null,"moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":null,"slug":"henrik-karlsson","createdAt":"2021-04-20T16:26:31.210Z","username":"henrik-karlsson","displayName":"Henrik Karlsson","previousDisplayName":null,"fullName":null,"karma":1057,"afKarma":null,"deleted":null,"isAdmin":false,"htmlBio":"<p><a href=\"https://escapingflatland.substack.com/\">https://escapingflatland.substack.com/<\/a><\/p>\n<p><a href=\"https://twitter.com/phokarlsson\">https://twitter.com/phokarlsson<\/a><\/p>\n","postCount":15,"commentCount":67,"sequenceCount":null,"afPostCount":null,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0},"Post:Fu7bqAyCMjfcMzBah":{"_id":"Fu7bqAyCMjfcMzBah","__typename":"Post","recentComments({\"af\":false,\"commentsLimit\":4,\"maxAgeHours\":18})":[{"__ref":"Comment:v89Qcvq3at9M3vxm5"},{"__ref":"Comment:gFizekRRMG8aHusAk"},{"__ref":"Comment:NpuB4goe6TBvwEoqQ"},{"__ref":"Comment:yGnkKyQf5iA6fc4Pk"}],"deletedDraft":false,"contents":{"__ref":"Revision:Fu7bqAyCMjfcMzBah_"},"fmCrosspost":{"isCrosspost":false,"hostedHere":true},"readTimeMinutes":6,"moderationGuidelines":{"__ref":"Revision:Fu7bqAyCMjfcMzBah_moderationGuidelines"},"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:KN9KEMgyBHjcAyc26"},{"__ref":"Tag:xexCWMyds6QLWognu"},{"__ref":"Tag:TkZ7MFwCi4D63LJ5n"},{"__ref":"Tag:ipJwbLxhR83ZksN6Z"}],"url":null,"postedAt":"2023-02-08T18:52:24.490Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2023-02-08T20:25:29.565Z","meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"commentCount":33,"voteCount":68,"baseScore":147,"extendedScore":null,"unlisted":false,"score":2.0289884933308495,"lastVisitedAt":"2023-02-10T12:26:19.261Z","isFuture":false,"isRead":true,"lastCommentedAt":"2023-02-10T16:07:39.063Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"mpsskhizpeqNqZgkZ","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"qgdGA4ZEyW7zNdK84","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"afBaseScore":36,"afExtendedScore":null,"afCommentCount":null,"afLastCommentedAt":"2023-02-08T18:52:24.493Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"reviewCount":null,"reviewVoteCount":null,"positiveReviewVoteCount":null,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"user":{"__ref":"User:mpsskhizpeqNqZgkZ"},"coauthors":[],"slug":"eigenkarma-trust-at-scale","title":"EigenKarma: trust at scale","draft":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null},"Revision:x4ixSh3stv9oESH3a_":{"_id":"x4ixSh3stv9oESH3a_","__typename":"Revision","html":"<p>\"Cut the red wire\" is not an instruction that you would find in a textbook on bomb defusal, precisely because it is not robust.<\/p>","plaintextMainText":"\"Cut the red wire\" is not an instruction that you would find in a textbook on\nbomb defusal, precisely because it is not robust.","wordCount":24},"User:GyW8aLqyhmbkto3DQ":{"_id":"GyW8aLqyhmbkto3DQ","__typename":"User","slug":"adamb","createdAt":"2022-06-14T13:11:53.238Z","username":"adam-bliss","displayName":"AdamB","previousDisplayName":"Adam Bliss","fullName":null,"karma":4,"afKarma":null,"deleted":null,"isAdmin":false,"htmlBio":"","postCount":null,"commentCount":3,"sequenceCount":null,"afPostCount":null,"afCommentCount":0,"spamRiskScore":0.9,"tagRevisionCount":null},"Comment:x4ixSh3stv9oESH3a":{"_id":"x4ixSh3stv9oESH3a","__typename":"Comment","postId":"uMQ3cqWDPHhjtiesc","tagId":null,"tag":null,"tagCommentType":"DISCUSSION","parentCommentId":"Gq8kR3TY2XqRMMdPi","topLevelCommentId":"Yew8zrf3XcrEvYDi9","descendentCount":0,"title":null,"contents":{"__ref":"Revision:x4ixSh3stv9oESH3a_"},"postedAt":"2023-02-10T16:04:56.303Z","repliesBlockedUntil":null,"userId":"GyW8aLqyhmbkto3DQ","deleted":false,"deletedPublic":false,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:GyW8aLqyhmbkto3DQ"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":1,"extendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"score":24.621573721988565,"voteCount":1,"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":0,"afExtendedScore":{"approvalVoteCount":0,"agreement":0,"agreementVoteCount":0},"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"needsReview":null,"answer":false,"parentAnswerId":null,"retracted":false,"postVersion":"1.3.0","reviewedByUserId":null,"shortform":false,"lastSubthreadActivity":"2023-02-10T16:04:56.308Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":null,"votingSystem":"twoAxis","isPinnedOnProfile":false},"Revision:uMQ3cqWDPHhjtiesc_":{"_id":"uMQ3cqWDPHhjtiesc_","__typename":"Revision","htmlHighlight":"<h3><strong>Preamble:<\/strong><\/h3><p>(If you're already familiar with all basics and don't want any preamble, skip ahead to&nbsp;<a href=\"#Section_B_\"><u>Section B<\/u><\/a> for technical difficulties of alignment proper.)<\/p><p>I have several times failed to write up a well-organized list of reasons why AGI will kill you.&nbsp; People come in with different ideas about why AGI would be survivable, and want to hear different&nbsp;<i>obviously key&nbsp;<\/i>points addressed first.&nbsp; Some fraction of those people are loudly upset with me if the obviously most important points aren't addressed immediately, and I address different points first instead.<\/p><p>Having failed to solve this problem in any good way, I now give up and solve it poorly with a poorly organized list of individual rants.&nbsp; I'm not particularly happy with this list; the alternative was publishing nothing, and publishing this seems marginally more <a href=\"https://www.lesswrong.com/posts/j9Q8bRmwCgXRYAgcJ/miri-announces-new-death-with-dignity-strategy\">dignified<\/a>.<\/p><p>Three points about the general subject matter of discussion here, numbered so as not to conflict with the list of lethalities:<\/p><p><strong>-3<\/strong>.&nbsp; I'm assuming you are already familiar with some basics, and already know what '<a href=\"https://arbital.com/p/orthogonality/\"><u>orthogonality<\/u><\/a>' and '<a href=\"https://arbital.com/p/instrumental_convergence/\"><u>instrumental convergence<\/u><\/a>' are and why they're true.&nbsp; People occasionally claim to me that I need to stop fighting old wars here, because, those people claim to me, those wars have already been won within the important-according-to-them parts of the current audience.&nbsp; I suppose it's at least true that none of the current major EA funders seem to be visibly in denial about orthogonality or instrumental convergence as such; so, fine.&nbsp; If you don't know what 'orthogonality' or 'instrumental convergence' are, or don't see for yourself why they're true, you need a different introduction than this one.<\/p><p><strong>-2<\/strong>.&nbsp; When I say that alignment is lethally difficult, I am not talking about ideal or perfect goals of 'provable' alignment, nor total alignment of superintelligences on exact human values, nor getting AIs to produce satisfactory arguments about moral dilemmas which sorta-reasonable humans disagree about, nor attaining an absolute certainty of an AI not killing everyone.&nbsp; When I say that alignment is difficult, I mean that in practice, using the techniques we actually have, \"please don't disassemble literally everyone with probability roughly 1\" is an overly large ask that we are not on course to get.&nbsp; So far as I'm concerned,&nbsp;<a href=\"https://twitter.com/ESYudkowsky/status/1070095112791715846\"><u>if you can get a powerful AGI tha<\/u><\/a>... <\/p>","wordCount":8921,"version":"1.3.0"},"Revision:uMQ3cqWDPHhjtiesc_moderationGuidelines":{"_id":"uMQ3cqWDPHhjtiesc_moderationGuidelines","__typename":"Revision","html":"<p>I will enforce the same standards here as I would on my personal Facebook garden.  If it looks like it would be unhedonic to spend time interacting with you, I will ban you from commenting on my posts.<\/p>\n<p>Specific guidelines:<\/p>\n<ul>\n<li>Argue against ideas rather than people.<\/li>\n<li>Don't accuse others of committing the Being Wrong Fallacy (\"Wow, I can't believe you're so wrong!  And you believe you're right!  That's even more wrong!\").<\/li>\n<li>I consider tone-policing to be a self-fulfilling prophecy and will delete it.<\/li>\n<li>If I think your own tone is counterproductive, I will try to remember to politely delete your comment instead of rudely saying so in a public reply.<\/li>\n<li>If you have helpful personal advice to someone that could perhaps be taken as lowering their status, say it to them in private rather than in a public comment.<\/li>\n<li>The censorship policy of the Reign of Terror is not part of the content of the post itself and may not be debated on the post.  If you think Censorship!! is a terrible idea and invalidates discussion, feel free not to read the comments section.<\/li>\n<li>The Internet is full of things to read that will not make you angry.  If it seems like you choose to spend a lot of time reading things that will give you a chance to be angry and push down others so you can be above them, you're not an interesting plant to have in my garden and you will be weeded.  I don't consider it fun to get angry at such people, and I will choose to read something else instead.<\/li>\n<\/ul>\n"},"Revision:uMQ3cqWDPHhjtiesc_customHighlight":{"_id":"uMQ3cqWDPHhjtiesc_customHighlight","__typename":"Revision","html":""},"Revision:ZFrgTgzwEfStg26JL_description":{"_id":"ZFrgTgzwEfStg26JL_description","__typename":"Revision","htmlHighlight":"<p><strong>AI Risk<\/strong> is analysis of the risks associated with building powerful AI systems.<\/p><p><i>Related: <\/i><a href=\"https://www.lesswrong.com/tag/ai\"><i>AI<\/i><\/a><i>, <\/i><a href=\"https://www.lesswrong.com/tag/orthogonality-thesis\"><i>Orthogonality thesis<\/i><\/a><i>, <\/i><a href=\"https://www.lesswrong.com/tag/complexity-of-value\"><i>Complexity of value<\/i><\/a><i>, <\/i><a href=\"https://www.lesswrong.com/tag/goodhart-s-law\"><i>Goodhart's law<\/i><\/a><i>, <\/i><a href=\"https://www.lesswrong.com/tag/paperclip-maximizer\"><i>Paperclip maximiser<\/i><\/a><\/p>"},"Tag:ZFrgTgzwEfStg26JL":{"_id":"ZFrgTgzwEfStg26JL","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:ZFrgTgzwEfStg26JL_description"},"userId":"EQNTWXLKMeWMp2FQS","name":"AI Risk","slug":"ai-risk","core":false,"postCount":595,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-16T10:29:25.410Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:JX69nZB8tfxnx5nGH_description":{"_id":"JX69nZB8tfxnx5nGH_description","__typename":"Revision","htmlHighlight":"<p>A <strong>threat model<\/strong> is a story of how a particular risk (e.g. AI) plays out.<\/p><p>In the <a href=\"https://lesswrong.com/tag/ai-risk\">AI risk<\/a> case, <a href=\"https://ssconlinemeetup.substack.com/p/video-from-rohins-talk\">according to Rohin Shah<\/a>, a threat model is ideally:<\/p><blockquote><p>Combination of a development model that says how we get AGI and a risk model that says how AGI leads to existential catastrophe.<\/p><\/blockquote>"},"Tag:JX69nZB8tfxnx5nGH":{"_id":"JX69nZB8tfxnx5nGH","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:JX69nZB8tfxnx5nGH_description"},"userId":"qqwfzAYaLsfmkwbsK","name":"Threat Models","slug":"threat-models","core":false,"postCount":33,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2021-04-20T21:57:13.125Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Post:uMQ3cqWDPHhjtiesc":{"_id":"uMQ3cqWDPHhjtiesc","__typename":"Post","recentComments({\"af\":false,\"commentsLimit\":4,\"maxAgeHours\":18})":[{"__ref":"Comment:x4ixSh3stv9oESH3a"}],"deletedDraft":true,"contents":{"__ref":"Revision:uMQ3cqWDPHhjtiesc_"},"fmCrosspost":null,"readTimeMinutes":36,"moderationGuidelines":{"__ref":"Revision:uMQ3cqWDPHhjtiesc_moderationGuidelines"},"customHighlight":{"__ref":"Revision:uMQ3cqWDPHhjtiesc_customHighlight"},"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:ZFrgTgzwEfStg26JL"},{"__ref":"Tag:sYm3HiWcfZvrGu3ui"},{"__ref":"Tag:JX69nZB8tfxnx5nGH"}],"url":null,"postedAt":"2022-06-05T22:05:52.224Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2022-06-05T22:36:03.837Z","meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":null,"commentCount":654,"voteCount":406,"baseScore":742,"extendedScore":null,"unlisted":false,"score":0.034438,"lastVisitedAt":"2022-08-13T08:32:59.953Z","isFuture":false,"isRead":true,"lastCommentedAt":"2023-02-10T16:04:56.585Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":"2022-06-08T19:02:49.778Z","commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"nmk3nLpQE89dMRzzN","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"r38pkCm7wF4M44MDQ","suggestForCuratedUserIds":["XtphY3uYHwruKqDyG","qxJ28GN72aiJu96iF"],"suggestForCuratedUsernames":"habryka, Kaj_Sotala","reviewForCuratedUserId":"r38pkCm7wF4M44MDQ","authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":126,"afExtendedScore":null,"afCommentCount":111,"afLastCommentedAt":"2022-06-29T18:41:15.481Z","afSticky":false,"hideAuthor":false,"moderationStyle":"reign-of-terror","submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"reviewCount":null,"reviewVoteCount":null,"positiveReviewVoteCount":null,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"user":{"__ref":"User:nmk3nLpQE89dMRzzN"},"coauthors":[],"slug":"agi-ruin-a-list-of-lethalities","title":"AGI Ruin: A List of Lethalities","draft":false,"hideCommentKarma":false,"af":true,"currentUserReviewVote":null},"Revision:3ymYHzcqqn7rspgve_":{"_id":"3ymYHzcqqn7rspgve_","__typename":"Revision","html":"<p>(Some very rough thoughts I sent in DM, putting them up publicly on request for posterity, almost definitely not up to my epistemic standards for posting on LW).<\/p><p>So I think some confusion might come from connotations of word choices. I interpret adversarial robustness' importance in terms of alignment <i>targets<\/i>, not <i>properties<\/i> (the two aren't entirely different, but I think they aren't exactly the same, and evoke different images in my mind). Like, the naive example here is just Goodharting on outer objectives that aren't aligned at the limit, where optimization pressure is AGI powerful enough to achieve it at very late stages on a logarithmic curve, which runs into edge cases if you aren't adversarially robust. So for outer alignment, you need a true name target. It's worth noting that I think John considers a bulk of the alignment problem to be contained in outer alignment (or whatever the analogue is in your ontology of the problem), hence the focus on adversarial robustness - it's not a term I hear very commonly apart from narrower contexts where its implication is obvious.<\/p><p>With inner alignment, I think it's more confused, because adversarial robustness isn't a term I would really use in that context. I <i>have<\/i> heard it used by others though - for example, someone I know is primarily working on designing training procedures that make adversarial robustness less of a problem (think debate). In that context I'm less certain about the inference to draw because it's pretty far removed from my ontology, but my take would be that it removes problems where your training processes aren't robust in holding to their training goal as things change, with scale, inner optimizers, etc. I think (although I'm far less sure of my memory here, this was a long conversation) he also mentioned it in the context of gradient hacking. So it's used pretty broadly here if I'm remembering this correctly.<\/p><p>TL;DR: I've mainly heard it used in the context of outer alignment or the targets you want, which some people think is the bulk of the problem.<\/p><p>I <i>can<\/i> think of a bunch of different things that could feasibly fall under the term adversarial robustness in inner alignment as well (training processes robust to proxy-misaligned mesa-optimizers, processes robust to gradient hackers, etc), but it wouldn't really feel intuitive to me, like you're not asking questions framed the best way.<\/p>","plaintextMainText":"(Some very rough thoughts I sent in DM, putting them up publicly on request for\nposterity, almost definitely not up to my epistemic standards for posting on\nLW).\n\nSo I think some confusion might come from connotations of word choices. I\ninterpret adversarial robustness' importance in terms of alignment targets, not\nproperties (the two aren't entirely different, but I think they aren't exactly\nthe same, and evoke different images in my mind). Like, the naive example here\nis just Goodharting on outer objectives that aren't aligned at the limit, where\noptimization pressure is AGI powerful enough to achieve it at very late stages\non a logarithmic curve, which runs into edge cases if you aren't adversarially\nrobust. So for outer alignment, you need a true name target. It's worth noting\nthat I think John considers a bulk of the alignment problem to be contained in\nouter alignment (or whatever the analogue is in your ontology of the problem),\nhence the focus on adversarial robustness - it's not a term I hear very commonly\napart from narrower contexts where its implication is obvious.\n\nWith inner alignment, I think it's more confused, because adversarial robustness\nisn't a term I would really use in that context. I have heard it used by others\nthough - for example, someone I know is primarily working on designing training\nprocedures that make adversarial robustness less of a problem (think debate). In\nthat context I'm less certain about the inference to draw because it's pretty\nfar removed from my ontology, but my take would be that it removes problems\nwhere your training processes aren't robust in holding to their training goal as\nthings change, with scale, inner optimizers, etc. I think (although I'm far less\nsure of my memory here, this was a long conversation) he also mentioned it in\nthe context of gradient hacking. So it's used pretty broadly here if I'm\nremembering this correctly.\n\nTL;DR: I've mainly heard it used in the context of outer alignment or the\ntargets you w","wordCount":398},"User:e9ToWWzhwWp5GSE7P":{"_id":"e9ToWWzhwWp5GSE7P","__typename":"User","slug":"jozdien","createdAt":"2020-01-11T07:28:42.450Z","username":"Jozdien","displayName":"Jozdien","previousDisplayName":null,"fullName":"Arun Jose","karma":522,"afKarma":100,"deleted":null,"isAdmin":false,"htmlBio":"","postCount":8,"commentCount":118,"sequenceCount":1,"afPostCount":4,"afCommentCount":12,"spamRiskScore":1,"tagRevisionCount":2},"Comment:3ymYHzcqqn7rspgve":{"_id":"3ymYHzcqqn7rspgve","__typename":"Comment","postId":"2ew4NFZovxCLsvHKS","tagId":null,"tag":null,"tagCommentType":"DISCUSSION","parentCommentId":null,"topLevelCommentId":null,"descendentCount":0,"title":null,"contents":{"__ref":"Revision:3ymYHzcqqn7rspgve_"},"postedAt":"2023-02-10T15:52:33.200Z","repliesBlockedUntil":null,"userId":"e9ToWWzhwWp5GSE7P","deleted":false,"deletedPublic":false,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:e9ToWWzhwWp5GSE7P"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":1,"extendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"score":20.05288130745732,"voteCount":1,"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"needsReview":null,"answer":true,"parentAnswerId":null,"retracted":false,"postVersion":"1.6.0","reviewedByUserId":null,"shortform":false,"lastSubthreadActivity":"2023-02-10T15:52:33.203Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":null,"votingSystem":"twoAxis","isPinnedOnProfile":false},"Revision:xbEGmBZTqXQapfXqG_":{"_id":"xbEGmBZTqXQapfXqG_","__typename":"Revision","html":"<p>In order to do what has worked well in the past, you need some robust retrospective measure of what it means to \"work well\", so you don't accidentally start thinking that the times it went poorly in the past were actually times where it went well.<\/p>\n","plaintextMainText":"In order to do what has worked well in the past, you need some robust\nretrospective measure of what it means to \"work well\", so you don't accidentally\nstart thinking that the times it went poorly in the past were actually times\nwhere it went well.","wordCount":46},"User:mfgrYb4LMk7NWXsSB":{"_id":"mfgrYb4LMk7NWXsSB","__typename":"User","slug":"tailcalled","createdAt":"2015-01-27T20:50:11.327Z","username":"tailcalled","displayName":"tailcalled","previousDisplayName":null,"fullName":null,"karma":2883,"afKarma":45,"deleted":false,"isAdmin":false,"htmlBio":"","postCount":41,"commentCount":944,"sequenceCount":null,"afPostCount":null,"afCommentCount":5,"spamRiskScore":1,"tagRevisionCount":0},"Comment:xbEGmBZTqXQapfXqG":{"_id":"xbEGmBZTqXQapfXqG","__typename":"Comment","postId":"2ew4NFZovxCLsvHKS","tagId":null,"tag":null,"tagCommentType":"DISCUSSION","parentCommentId":"S9WMpmPq3nGTP7Jkn","topLevelCommentId":"6qSk7XodzwNeux6vb","descendentCount":0,"title":null,"contents":{"__ref":"Revision:xbEGmBZTqXQapfXqG_"},"postedAt":"2023-02-10T08:14:10.518Z","repliesBlockedUntil":null,"userId":"mfgrYb4LMk7NWXsSB","deleted":false,"deletedPublic":false,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:mfgrYb4LMk7NWXsSB"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":2,"extendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"score":0.48777049394861305,"voteCount":1,"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"needsReview":null,"answer":false,"parentAnswerId":"6qSk7XodzwNeux6vb","retracted":false,"postVersion":"1.6.0","reviewedByUserId":null,"shortform":false,"lastSubthreadActivity":"2023-02-10T08:14:10.521Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":null,"votingSystem":"twoAxis","isPinnedOnProfile":false},"Revision:Ft5KzABbWd9z4qFiS_":{"_id":"Ft5KzABbWd9z4qFiS_","__typename":"Revision","html":"<p>Yeah, so by \"planning module\", pretty much all I mean is this method of the <code>Agent<\/code> class, it's not a Cartesian theatre deal at all:<\/p>\n<pre><code>def get_next_action(self, ...):\n    ...\n<\/code><\/pre>\n<p>Like, presumably it's okay for agents to be designed out of identifiable sub-components without there being any incoherence or any kind of \"inner observer\" resulting from that. In the example I gave in my original answer, the planning module made calls to the action network, world model network, and value network, which you'll note is all of the networks comprising that particular agent, so it's definitely a very interconnected thing. I think it's fair to say that when we call this method, we're in some sense kicking off an optimization procedure that \"tries\" to optimize the value function.<\/p>\n<p>With terminology hopefully nailed down, let's move on to the topic at hand.<\/p>\n<p>If I'm getting your point right here, the basic idea is that the world model network is just being trained to get correct predictions, so that's all okay, but the action network is not being trained to search out weird hacky exploits of the value function, because whenever it found one of those during training, the humans sent a negative reward, which caused the value function to self-correct, so then the action network didn't get the reward it was hoping for.<\/p>\n<p>Obstacles to this as an alignment solution:<\/p>\n<ol>\n<li>\n<p>You're not going to keep training the other networks in the agent after you've finished training the value network right? Right? Okay, good, 'cause that would totally wreck everything. Moving along...<\/p>\n<\/li>\n<li>\n<p>Most central concern: The deployment environment is generally not going to be identical to the training environment, and could be quite different. Basic scenario: The value network mostly learns to assign the right values to things in the context of the training environment, maybe it fails in a few places. The planning module's search algorithms are adapted to work around those failures and not run into them while picking actions. Other than those patches, the planning module generally performs well, i.e. it acts like something that can reason about the world and select courses of action that are most likely to lead to a high score from the value function. Then switch to deployment. The value function suddenly has lots more holes that the planning module hasn't developed patches to work around. Plus maybe some of the existing patches don't generalize to the new environment. \"Maybe we can engineer a type-X Liemond\" is going to be an obvious thought to the planning module, when only type-Y Liemonds were possible in the training environment, and thus the planning module's search process only has patches preventing it from discovering type-Y Liemonds.<\/p>\n<\/li>\n<li>\n<p>Actually, probably the value function will just correctly value type-Y Liemonds at 0, and there won't be any patches made to planning. It seems likely that, purely as a matter of training dynamics, gradient descent is going to prefer to just fix the value network, rather than coming up with patches that limit the ability of the planning module to do certain searches. The basic model here is: Let's say the actor finds a weird value-function bug about every 100 training steps, and then exploits it to get an abnormally high score. This results in reinforcement to the circuits that recommended the action, since the action it's suggesting has a high expected value according to the value network. Humans label the outcomes as bad, the value function is corrected by gradient descent, say this takes about 50 training steps. The \"try weird hacks\" circuit stops getting reinforced, since the value function no longer recommends it, but there's never any negative feedback against it, all the negative feedback happened in the value network, since that's where gradients coming from human labels flow. Then in another 50 steps or so, it stumbles across another hack, and gets more reinforcement. Depending on details, this intermittent reinforcement could be enough to preserve the circuit from weight decay.<\/p>\n<\/li>\n<\/ol>\n<p>Anyway, I upvoted your comment, since point 3 does suggest a direction for modifying our existing RL agent designs to try and ensure they learn patches to their search process, rather than only corrections to their value function. We could try and finagle the gradient flows so that when humans label an outcome as bad despite a high score from the value-network, negative reinforcement also flows into the action network, to discourage producing outcomes where the value network is wrong. This would probably be terrible for exploration during training, and thus for generalization. Plus I don't expect patches to generalize any better than I expect the value-network to generalize. Maybe there's a way to make it work, though?<\/p>\n","plaintextMainText":"Yeah, so by \"planning module\", pretty much all I mean is this method of the\nAgent class, it's not a Cartesian theatre deal at all:\n\ndef get_next_action(self, ...):\n    ...\n\n\nLike, presumably it's okay for agents to be designed out of identifiable\nsub-components without there being any incoherence or any kind of \"inner\nobserver\" resulting from that. In the example I gave in my original answer, the\nplanning module made calls to the action network, world model network, and value\nnetwork, which you'll note is all of the networks comprising that particular\nagent, so it's definitely a very interconnected thing. I think it's fair to say\nthat when we call this method, we're in some sense kicking off an optimization\nprocedure that \"tries\" to optimize the value function.\n\nWith terminology hopefully nailed down, let's move on to the topic at hand.\n\nIf I'm getting your point right here, the basic idea is that the world model\nnetwork is just being trained to get correct predictions, so that's all okay,\nbut the action network is not being trained to search out weird hacky exploits\nof the value function, because whenever it found one of those during training,\nthe humans sent a negative reward, which caused the value function to\nself-correct, so then the action network didn't get the reward it was hoping\nfor.\n\nObstacles to this as an alignment solution:\n\n 1. You're not going to keep training the other networks in the agent after\n    you've finished training the value network right? Right? Okay, good, 'cause\n    that would totally wreck everything. Moving along...\n\n 2. Most central concern: The deployment environment is generally not going to\n    be identical to the training environment, and could be quite different.\n    Basic scenario: The value network mostly learns to assign the right values\n    to things in the context of the training environment, maybe it fails in a\n    few places. The planning module's search algorithms are adapted to work\n    around those failures and not run","wordCount":784},"User:Ei73H4RbCT5TTaXNa":{"_id":"Ei73H4RbCT5TTaXNa","__typename":"User","slug":"daemonicsigil","createdAt":"2020-02-14T19:10:16.309Z","username":"DaemonicSigil","displayName":"DaemonicSigil","previousDisplayName":null,"fullName":null,"karma":520,"afKarma":95,"deleted":null,"isAdmin":false,"htmlBio":"","postCount":2,"commentCount":72,"sequenceCount":null,"afPostCount":null,"afCommentCount":14,"spamRiskScore":1,"tagRevisionCount":0},"Comment:Ft5KzABbWd9z4qFiS":{"_id":"Ft5KzABbWd9z4qFiS","__typename":"Comment","postId":"2ew4NFZovxCLsvHKS","tagId":null,"tag":null,"tagCommentType":"DISCUSSION","parentCommentId":"zaCojffTGbNaRtyE7","topLevelCommentId":"6qSk7XodzwNeux6vb","descendentCount":0,"title":null,"contents":{"__ref":"Revision:Ft5KzABbWd9z4qFiS_"},"postedAt":"2023-02-10T08:09:40.630Z","repliesBlockedUntil":null,"userId":"Ei73H4RbCT5TTaXNa","deleted":false,"deletedPublic":false,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:Ei73H4RbCT5TTaXNa"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":1,"extendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"score":0.41495116287214684,"voteCount":1,"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"needsReview":null,"answer":false,"parentAnswerId":"6qSk7XodzwNeux6vb","retracted":false,"postVersion":"1.6.0","reviewedByUserId":null,"shortform":false,"lastSubthreadActivity":"2023-02-10T08:09:40.810Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":null,"votingSystem":"twoAxis","isPinnedOnProfile":false},"Revision:zaCojffTGbNaRtyE7_":{"_id":"zaCojffTGbNaRtyE7_","__typename":"Revision","html":"<blockquote><p>Once you've read it: Under your model, it sounds like producing lots of Diamonds is normal and good agent behaviour, but producing lots of Liemonds is probing weird quirks of my value function that I have no reason to care about pursuing. What's the difference between these two cases? What's the mechanism for how that manifests in a reasonably-designed agent?<\/p><\/blockquote><p>We are assuming that the agent has already learned a correct-but-not-adversarially-robust value function for Diamonds. That means that it makes correct distinctions in ordinary circumstances to pick out plans actually leading to Diamonds, but won't correctly distinguish between plans that were deceptively constructed so they merely look like they'll produce Diamonds but actually produce Liemonds vs. plans that actually produce Diamonds.<\/p><p>But given that, the agent <i>has no particular reason<\/i> to raise thoughts to consideration like \"probe my value function to find weird quirks in it\" in the first place, or to regard them as any more promising than \"study geology to figure out a better versions of Diamond-producing-causal-pathways\", which is a thought that the existing circuits within the agent have an actual mechanistic reason to be raising, on the basis of past reinforcement around \"what were the robust common factors in Diamonds-as-I-have-experienced-them\" and \"what general planning strategies actually helped me produce Diamonds better in the past\" etc. and <i>will in fact<\/i> generally lead to Diamonds rather than Liemonds, <a href=\"https://www.lesswrong.com/posts/JLyWP2Y9LAruR2gi9/can-we-efficiently-distinguish-different-mechanisms\">because the two are presumably produced via different mechanisms<\/a>. Inspecting its own value function, looking for flaws in it, is not generally an effective strategy for actually producing Diamonds (or whatever else is the veridical source of reinforcement) in the distribution of scenarios it encountered during the broad-but-not-adversarially-tuned distribution of training inputs.<\/p><p>So the mechanistic difference between the scenario I'm suggesting and the one you are is that I think there will be lots of strong circuits that, downstream of the reinforcement events that produced the correct-but-not-adversarially-robust value function oriented towards Diamonds, will fire based on features that differentially pick out Diamonds (as well as, say, Liemonds) against the background of possible plan-targets by attending to historically relevant features like \"does it look like a Diamond\" and \"is its fine-grained structure like a Diamond\" etc. and effectively upweight the logits of the corresponding actions, but that there will not be correspondingly strong circuits that fire based on features that <i>differentially<\/i> <i>pick out Liemonds over Diamonds<\/i>.<\/p><blockquote><p>Also, I'm not sure we're using terminology in the same way here. Under my terminology, \"planning module\" is the thing doing the optimization. It's the function we call when it's time to figure out what's the next action the agent should take. So from that perspective \"the planning module is not an independent agent\" goes without saying, but \"optimizing hard against the planning module\" doesn't make sense: The planning module is generally the thing that does the optimizing, and it's not a function with a real number output, so it's not really a thing that can be optimized at all.<\/p><\/blockquote><p>Generally speaking I'm uncomfortable with the \"planning module\" distinction, because I think the whole agent is doing optimization, and the totality of the agent's learning-based circuits will be oriented around the optimization it does. That's what coherence entails. If it were any other way, you'd have one part of the agent optimizing for what the agent wants and another part of the agent optimizing for something way different. In the same way, there's no \"sentence planning\" module within GPT: the whole thing is doing that function, distributed across thousands of circuits. <s>See \"Cartesian theater\" etc.<\/s><\/p><p>EDIT: I said \"Cartesian theater\" but the appropriate pointer was <a href=\"https://www.lesswrong.com/tag/homunculus-fallacy\">\"homunculus fallacy\"<\/a>.<\/p>","plaintextMainText":"We are assuming that the agent has already learned a\ncorrect-but-not-adversarially-robust value function for Diamonds. That means\nthat it makes correct distinctions in ordinary circumstances to pick out plans\nactually leading to Diamonds, but won't correctly distinguish between plans that\nwere deceptively constructed so they merely look like they'll produce Diamonds\nbut actually produce Liemonds vs. plans that actually produce Diamonds.\n\nBut given that, the agent has no particular reason to raise thoughts to\nconsideration like \"probe my value function to find weird quirks in it\" in the\nfirst place, or to regard them as any more promising than \"study geology to\nfigure out a better versions of Diamond-producing-causal-pathways\", which is a\nthought that the existing circuits within the agent have an actual mechanistic\nreason to be raising, on the basis of past reinforcement around \"what were the\nrobust common factors in Diamonds-as-I-have-experienced-them\" and \"what general\nplanning strategies actually helped me produce Diamonds better in the past\" etc.\nand will in fact generally lead to Diamonds rather than Liemonds, because the\ntwo are presumably produced via different mechanisms\n[https://www.lesswrong.com/posts/JLyWP2Y9LAruR2gi9/can-we-efficiently-distinguish-different-mechanisms].\nInspecting its own value function, looking for flaws in it, is not generally an\neffective strategy for actually producing Diamonds (or whatever else is the\nveridical source of reinforcement) in the distribution of scenarios it\nencountered during the broad-but-not-adversarially-tuned distribution of\ntraining inputs.\n\nSo the mechanistic difference between the scenario I'm suggesting and the one\nyou are is that I think there will be lots of strong circuits that, downstream\nof the reinforcement events that produced the\ncorrect-but-not-adversarially-robust value function oriented towards Diamonds,\nwill fire based on features that differentially pick out Diamonds (as well as,\nsay, Liemonds) aga","wordCount":603},"User:pm8vxom7ZZSQEjxB8":{"_id":"pm8vxom7ZZSQEjxB8","__typename":"User","slug":"cfoster0","createdAt":"2018-08-21T22:52:35.800Z","username":"cfoster0","displayName":"cfoster0","previousDisplayName":null,"fullName":"Charles Foster","karma":545,"afKarma":26,"deleted":null,"isAdmin":false,"htmlBio":"","postCount":null,"commentCount":117,"sequenceCount":0,"afPostCount":null,"afCommentCount":1,"spamRiskScore":1,"tagRevisionCount":0},"Comment:zaCojffTGbNaRtyE7":{"_id":"zaCojffTGbNaRtyE7","__typename":"Comment","postId":"2ew4NFZovxCLsvHKS","tagId":null,"tag":null,"tagCommentType":"DISCUSSION","parentCommentId":"PgK98QGs7sodzjf2v","topLevelCommentId":"6qSk7XodzwNeux6vb","descendentCount":1,"title":null,"contents":{"__ref":"Revision:zaCojffTGbNaRtyE7_"},"postedAt":"2023-02-10T06:00:39.946Z","repliesBlockedUntil":null,"userId":"pm8vxom7ZZSQEjxB8","deleted":false,"deletedPublic":false,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:pm8vxom7ZZSQEjxB8"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":8,"extendedScore":{"approvalVoteCount":3,"agreement":2,"agreementVoteCount":1},"score":0.7210474209540968,"voteCount":3,"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":4,"afExtendedScore":{"approvalVoteCount":3,"agreement":2,"agreementVoteCount":1},"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"needsReview":null,"answer":false,"parentAnswerId":"6qSk7XodzwNeux6vb","retracted":false,"postVersion":"1.6.0","reviewedByUserId":null,"shortform":false,"lastSubthreadActivity":"2023-02-10T08:09:41.085Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":1,"votingSystem":"twoAxis","isPinnedOnProfile":false},"Revision:2ew4NFZovxCLsvHKS_":{"_id":"2ew4NFZovxCLsvHKS_","__typename":"Revision","htmlHighlight":"<p>Where \"powerful AI systems\" mean something like \"systems that would be existentially dangerous if sufficiently misaligned\". Current language models are not \"powerful AI systems\".<\/p><p>&nbsp;<br>\nIn \"<a href=\"https://www.lesswrong.com/posts/FWvzwCDRgcjb9sigb/why-agent-foundations-an-overly-abstract-explanation\">Why Agent Foundations? An Overly Abstract Explanation<\/a>\" John Wentworth says:<\/p>\n<blockquote>\n<p>Goodharts Law means that proxies which might at first glance seem approximately-fine will break down when lots of optimization pressure is applied. And when were talking about aligning powerful future AI, were talking about a lot of optimization pressure. Thats the key idea which generalizes to other alignment strategies: crappy proxies wont cut it when we start to apply a lot of optimization pressure.<\/p>\n<\/blockquote>\n<p>The examples he highlighted before that statement (failures of central planning in the Soviet Union) strike me as <a href=\"https://www.lesswrong.com/posts/EbFABnst8LsidYs5Y/goodhart-taxonomy#Adversarial_Goodhart\">examples of \"Adversarial Goodhart\" in Garrabant's Taxonomy<\/a>.<\/p><p><a href=\"https://www.lesswrong.com/posts/zhhYwM7gk8LZsDzxj/dragongod-s-shortform?commentId=DFHL6LF2YBGim4iC4\">I find it non obvious that safety properties for powerful systems need to be adversarially robust<\/a>. My intuitions are that imagining a system is actively trying to break safety properties is a wrong framing; it conditions on having designed a system that is not safe.<\/p><p>If the system is trying/wants to break its safety properties, then it's not safe/you've already made a massive mistake somewhere else. A system that is only safe because it's not powerful enough to break its safety properties is not robust to <a href=\"https://www.lesswrong.com/posts/bBdfbWfWxHN9Chjcq/robustness-to-scale\">scaling up/capability amplification<\/a>.<\/p><p>Other explanations my model generates for this phenomenon involve the phrases \"deceptive alignment\", \"mesa-optimisers\" or \"gradient hacking\", but at this stage <a href=\"https://www.lesswrong.com/posts/NMoLJuDJEms7Ku9XS/guessing-the-teacher-s-password\">I'm just guessing the teacher's passwords<\/a>. Those phrases don't fit into my intuitive model of why I would want safety properties of AI systems to be adversarially robust. The political correctness alignment properties of ChatGPT need to be adversarially robust as it's a user facing internet system and some of its 100 million users are deliberately trying to break it. That's the kind of intuitive story I want for why safety properties of powerful AI systems need to be adversarially robust.<\/p><p>&nbsp;<br>\nI find it plausible that strategic interactions in multipolar scenarios would exert adversarial pressure on the systems, but I'm under the impression that many agent foundations researchers expect unipolar outcomes by default/as the modal case (e.g. due to a fast, localised takeoff), so I don't think multi-agent interactions are the kind of s... <\/p>","wordCount":579,"version":"1.6.0"},"Revision:2ew4NFZovxCLsvHKS_moderationGuidelines":{"_id":"2ew4NFZovxCLsvHKS_moderationGuidelines","__typename":"Revision","html":""},"Revision:PvridmTCj2qsugQCH_description":{"_id":"PvridmTCj2qsugQCH_description","__typename":"Revision","htmlHighlight":"<p><strong>Goodhart's Law <\/strong>states that when a proxy for some value becomes the target of optimization pressure, the proxy will cease to be a good proxy. One form of Goodhart is demonstrated by the Soviet story of a factory graded on how many shoes they produced (a good proxy for productivity)  they soon began producing a higher number of tiny shoes. Useless, but the numbers look good.<\/p><p>Goodhart's Law is of particular relevance to <a href=\"https://www.lessestwrong.com/tag/ai\">AI Alignment<\/a>. Suppose you have something which is generally a good proxy for \"the stuff that humans care about\", it would be dangerous to have a powerful AI optimize for the proxy, in accordance with Goodhart's law, the proxy will breakdown. &nbsp;<\/p><h2>Goodhart Taxonomy<\/h2><p>In <a href=\"https://www.lessestwrong.com/posts/EbFABnst8LsidYs5Y/goodhart-taxonomy\">Goodhart Taxonomy<\/a>, Scott Garrabrant identifies four kinds of Goodharting:<\/p><ul><li>Regressional Goodhart - When selecting for a proxy measure, you select not only for the true goal, but also for the difference between the proxy and the goal.<\/li><li>Causal Goodhart - When there is a non-causal correlation between the proxy and the goal, intervening on the proxy may fail to intervene on the goal.<\/li><li>Extremal Goodhart - Worlds in which the proxy takes an extreme value may be very different from the ordinary worlds in which the correlation between the proxy and the goal was observed.<\/li><li>Adversarial Goodhart - When you optimize for a proxy, you provide an incentive for adversaries to correlate their goal with your proxy, thus destroying the correlation with your goal.<\/li><\/ul><h2>See Also<\/h2><ul><li><a href=\"https://lessestwrong.com/tag/groupthink\">Groupthink<\/a>, <a href=\"https://lessestwrong.com/tag/information-cascades\">Information cascade<\/a>, <a href=\"https://lessestwrong.com/tag/affective-death-spiral\">Affective death spiral<\/a><\/li><li><a href=\"https://wiki.lesswrong.com/wiki/Adaptation_executers\">Adaptation executers<\/a>, <a href=\"https://lessestwrong.com/tag/superstimuli\">Superstimulus<\/a><\/li><li><a href=\"https://lessestwrong.com/tag/signaling\">Signaling<\/a>, <a href=\"https://lessestwrong.com/tag/filtered-evidence\">Filtered evidence<\/a><\/li><li><a href=\"https://lessestwrong.com/tag/cached-thought\">Cached thought<\/a><\/li><li><a href=\"https://lessestwrong.com/tag/modesty-argument\">Modesty argument<\/a>, <a href=\"https://lessestwrong.com/tag/egalitarianism\">Egalitarianism<\/a><\/li><li><a href=\"https://lessestwrong.com/tag/rationalization\">Rationalization<\/a>, <a href=\"https://lessestwrong.com/tag/dark-arts\">Dark arts<\/a><\/li><li><a href=\"https://lessestwrong.com/tag/epistemic-hygiene\">Epistemic hygiene<\/a><\/li><li><a href=\"https://lessestwrong.com/tag/scoring-rule\">Scoring rule<\/a><\/li><\/ul>"},"Tag:PvridmTCj2qsugQCH":{"_id":"PvridmTCj2qsugQCH","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:PvridmTCj2qsugQCH_description"},"userId":"nLbwLhBaQeG6tCNDN","name":"Goodhart's Law","slug":"goodhart-s-law","core":null,"postCount":80,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":null,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-04-24T23:26:23.630Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:haiwnEEx3vhrkfmAP_description":{"_id":"haiwnEEx3vhrkfmAP_description","__typename":"Revision","htmlHighlight":"<p>AI Robustness is an agents ability to maintain its goal and its capabilities when exposed to different data distributions or environments.<\/p>"},"Tag:haiwnEEx3vhrkfmAP":{"_id":"haiwnEEx3vhrkfmAP","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:haiwnEEx3vhrkfmAP_description"},"userId":"qgdGA4ZEyW7zNdK84","name":"AI Robustness","slug":"ai-robustness","core":false,"postCount":5,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2022-07-23T17:35:23.708Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Post:2ew4NFZovxCLsvHKS":{"_id":"2ew4NFZovxCLsvHKS","__typename":"Post","recentComments({\"af\":false,\"commentsLimit\":4,\"maxAgeHours\":18})":[{"__ref":"Comment:3ymYHzcqqn7rspgve"},{"__ref":"Comment:xbEGmBZTqXQapfXqG"},{"__ref":"Comment:Ft5KzABbWd9z4qFiS"},{"__ref":"Comment:zaCojffTGbNaRtyE7"}],"deletedDraft":false,"contents":{"__ref":"Revision:2ew4NFZovxCLsvHKS_"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":2,"moderationGuidelines":{"__ref":"Revision:2ew4NFZovxCLsvHKS_moderationGuidelines"},"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:PvridmTCj2qsugQCH"},{"__ref":"Tag:nvKzwpiranwy29HFJ"},{"__ref":"Tag:haiwnEEx3vhrkfmAP"},{"__ref":"Tag:sYm3HiWcfZvrGu3ui"}],"url":null,"postedAt":"2023-02-09T13:36:00.325Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2023-02-08T18:37:59.201Z","meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"commentCount":23,"voteCount":7,"baseScore":23,"extendedScore":null,"unlisted":false,"score":0.483065687256423,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2023-02-10T15:52:33.429Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":true,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"quAoHT9X7qMDBmA3z","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"r38pkCm7wF4M44MDQ","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"afBaseScore":11,"afExtendedScore":null,"afCommentCount":null,"afLastCommentedAt":"2023-02-08T16:40:26.755Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"reviewCount":null,"reviewVoteCount":null,"positiveReviewVoteCount":null,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"user":{"__ref":"User:quAoHT9X7qMDBmA3z"},"coauthors":[],"slug":"do-the-safety-properties-of-powerful-ai-systems-need-to-be","title":"Do the Safety Properties of Powerful AI Systems Need to be Adversarially Robust? Why? ","draft":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null},"Revision:2CxekqM5fc87mmqXn_":{"_id":"2CxekqM5fc87mmqXn_","__typename":"Revision","html":"<p>I disagree with this post for 2 reasons:<\/p>\n<ol>\n<li>\n<p>Amdahl's law limits how much cyborgism will actually work, and IMO is the reason agents are more effective than simulators.<\/p>\n<\/li>\n<li>\n<p>A more meta point, but contra alt-history, the future is much harder to change and more predictable than we think because the outside view predicts things quite well.<\/p>\n<\/li>\n<\/ol>\n<p>On Amdahl's law, John Wentworth's post on the long tail is very relevant here, as it limits the use of cyborgism here:<\/p>\n<p><a href=\"https://www.lesswrong.com/posts/Nbcs5Fe2cxQuzje4K/value-of-the-long-tail\">https://www.lesswrong.com/posts/Nbcs5Fe2cxQuzje4K/value-of-the-long-tail<\/a><\/p>\n<p>On the meta point here, this is admittedly based on my experience with reading alt-history, but usually I think people overestimate how much the future is influencable.<\/p>\n","plaintextMainText":"I disagree with this post for 2 reasons:\n\n 1. Amdahl's law limits how much cyborgism will actually work, and IMO is the\n    reason agents are more effective than simulators.\n\n 2. A more meta point, but contra alt-history, the future is much harder to\n    change and more predictable than we think because the outside view predicts\n    things quite well.\n\nOn Amdahl's law, John Wentworth's post on the long tail is very relevant here,\nas it limits the use of cyborgism here:\n\nhttps://www.lesswrong.com/posts/Nbcs5Fe2cxQuzje4K/value-of-the-long-tail\n[https://www.lesswrong.com/posts/Nbcs5Fe2cxQuzje4K/value-of-the-long-tail]\n\nOn the meta point here, this is admittedly based on my experience with reading\nalt-history, but usually I think people overestimate how much the future is\ninfluencable.","wordCount":108},"User:nRknKQuPzoG2Wuyyi":{"_id":"nRknKQuPzoG2Wuyyi","__typename":"User","slug":"sharmake-farah","createdAt":"2022-05-23T21:10:28.892Z","username":"sharmake-farah","displayName":"Noosphere89","previousDisplayName":"Sharmake Farah","fullName":null,"karma":516,"afKarma":8,"deleted":null,"isAdmin":false,"htmlBio":"","postCount":18,"commentCount":483,"sequenceCount":null,"afPostCount":null,"afCommentCount":1,"spamRiskScore":1,"tagRevisionCount":14},"Comment:2CxekqM5fc87mmqXn":{"_id":"2CxekqM5fc87mmqXn","__typename":"Comment","postId":"bxt7uCiHam4QXrQAA","tagId":null,"tag":null,"tagCommentType":"DISCUSSION","parentCommentId":null,"topLevelCommentId":null,"descendentCount":0,"title":null,"contents":{"__ref":"Revision:2CxekqM5fc87mmqXn_"},"postedAt":"2023-02-10T15:46:07.478Z","repliesBlockedUntil":null,"userId":"nRknKQuPzoG2Wuyyi","deleted":false,"deletedPublic":false,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:nRknKQuPzoG2Wuyyi"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":1,"extendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"score":18.239233428339386,"voteCount":1,"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"needsReview":null,"answer":false,"parentAnswerId":null,"retracted":false,"postVersion":"0.8.1","reviewedByUserId":null,"shortform":false,"lastSubthreadActivity":"2023-02-10T15:46:07.487Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":null,"votingSystem":"twoAxis","isPinnedOnProfile":false},"Revision:bxt7uCiHam4QXrQAA_":{"_id":"bxt7uCiHam4QXrQAA_","__typename":"Revision","htmlHighlight":"<p><i>Thanks to Garrett Baker, David Udell, Alex Gray, Paul Colognese, Akash Wasil, Jacques Thibodeau, Michael Ivanitskiy, Zach Stein-Perlman, and Anish Upadhayay for feedback on drafts, as well as Scott Viteri for our valuable conversations.<\/i><\/p><figure class=\"image\"><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675885025/mirroredImages/bxt7uCiHam4QXrQAA/smgk4ts7nwdgsv4n0sog.png\"><figcaption>(picture thanks to Julia Persson and Dall-E 2)<\/figcaption><\/figure><p><strong>Executive summary<\/strong>: This post proposes a strategy for safely accelerating alignment research. The plan is to set up human-in-the-loop systems which empower human agency rather than outsource it, and to use those systems to differentially accelerate progress on alignment.&nbsp;<\/p><ol><li><a href=\"https://www.lesswrong.com/posts/bxt7uCiHam4QXrQAA/cyborgism#Introduction\"><u>Introduction<\/u><\/a>: An explanation of the context and motivation for this agenda.<\/li><li><a href=\"https://www.lesswrong.com/posts/bxt7uCiHam4QXrQAA/cyborgism#Automated_Research_Assistants\"><u>Automated Research Assistants<\/u><\/a>: A discussion of why the paradigm of training AI systems to behave as autonomous agents is both counterproductive and dangerous.<\/li><li><a href=\"https://www.lesswrong.com/posts/bxt7uCiHam4QXrQAA/cyborgism#Becoming_a_Cyborg\"><u>Becoming a Cyborg<\/u><\/a>: A proposal for an alternative approach/frame, which focuses on a particular type of human-in-the-loop system I am calling a cyborg.<\/li><li><a href=\"https://www.lesswrong.com/posts/bxt7uCiHam4QXrQAA/cyborgism#Failure_Modes\"><u>Failure Modes<\/u><\/a>: An analysis of how this agenda could either fail to help or actively cause harm by accelerating AI research more broadly.<\/li><li><a href=\"https://www.lesswrong.com/posts/bxt7uCiHam4QXrQAA/cyborgism#Appendix__Testimony_of_a_Cyborg\"><u>Testimony of a Cyborg<\/u><\/a>: A personal account of how Janus uses GPT as a part of their workflow, and how it relates to the cyborgism approach to intelligence augmentation.<\/li><\/ol><h2>Terminology<\/h2><ul><li><strong>GPT<\/strong>: Large language models trained on next-token prediction. Most plans to accelerate research (including this one) revolve around leveraging GPTs specifically. I will mostly be using GPT'' to gesture at the&nbsp;<i>base models&nbsp;<\/i>which have not been augmented using reinforcement learning.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnreftl6hnw2qfe\"><sup><a href=\"#fntl6hnw2qfe\">[1]<\/a><\/sup><\/span><\/li><li><strong>Autonomous Agent<\/strong>: An AI system which can be&nbsp;<a href=\"https://en.wikipedia.org/wiki/Intentional_stance\"><u>well modeled<\/u><\/a> as having goals or preferences, and deliberately selects actions in order to achieve them (with limited human assistance).&nbsp;<\/li><li><strong>Capabilities research<\/strong>: Research which directly improves the capabilities of AI systems and thereby brings us closer to being able to train and deploy more powerful autonomous agents.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefns45fa9lavq\"><sup><a href=\"#fnns45fa9lavq\">[2]<\/a><\/sup><\/span><\/li><li><strong>Simulator<\/strong>: A&nbsp;<a href=\"https://www.lesswrong.com/posts/vJFdjigzmcXMhNTsx/simulators\"><u>class of AI system<\/u><\/a> (of which GPT is a member). Simulators are generative predictive models, where the model makes a prediction (probability distribution) about how the state of a system will evolve, and then the state is updated by sampling from that prediction/distribution. The result is a process which simulates the training distribution, the limit of such a process being a system which faithfully generates trajectories sampled from the distribution<\/li><\/ul>...","wordCount":10567,"version":"0.8.1"},"Revision:bxt7uCiHam4QXrQAA_moderationGuidelines":{"_id":"bxt7uCiHam4QXrQAA_moderationGuidelines","__typename":"Revision","html":""},"Revision:xjNvvmvQ5BH3cfEBr_description":{"_id":"xjNvvmvQ5BH3cfEBr_description","__typename":"Revision","htmlHighlight":"<p>Simulator theory in the context of AI refers to an ontology or frame for understanding the working of large generative models, such as the GPT series from OpenAI. Broadly it views these models as simulating a learned distribution with various degrees of fidelity, which in the case of language models trained on a large corpus of text is the mechanics underlying our world.<\/p><p>It can also refer to an alignment research agenda, that deals with better understanding simulator conditionals, effects of downstream training, alignment-relevant properties such as myopia and agency in the context of language models, and using them as alignment research accelerators.<\/p>"},"Tag:xjNvvmvQ5BH3cfEBr":{"_id":"xjNvvmvQ5BH3cfEBr","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:xjNvvmvQ5BH3cfEBr_description"},"userId":"e9ToWWzhwWp5GSE7P","name":"Simulator Theory","slug":"simulator-theory","core":false,"postCount":32,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2022-12-06T12:53:39.358Z","wikiOnly":false,"deleted":false,"isSubforum":false},"Revision:LXk7bxNkYSjgatdAt_description":{"_id":"LXk7bxNkYSjgatdAt_description","__typename":"Revision","htmlHighlight":"<p>A <strong>tool AI<\/strong> is a type of Artificial Intelligence that is built to be used as a tool by the creators, rather than being an agent with its own action and goal-seeking behavior.<\/p><p>Generally meant to refer to <u><a href=\"https://wiki.lesswrong.com/wiki/AGI\">AGI<\/a><\/u>, tool AI is a proposed method for gaining some of the benefits of the intelligence while avoiding the dangers of having it act autonomously. It was coined by Holden Karnofsky, co-founder of GiveWell, in a critique of the Singularity Institute. Karnofsky proposed that, while he agreed that agent-based AGI was dangerous, it was an unnecessary path of development. His example of tool AI behavior was Google Maps, which uses complex algorithms and data to plot a route, but presents these results to the user instead of driving the user itself.<\/p><p>Eliezer Yudkowsky responded to this by enumerating several ways in which tool AI had similar difficulties in technical specification and safety. He also pointed out that it was not a common proposal among leading AGI thinkers.<\/p><h2><strong>See Also<\/strong><\/h2><ul><li><a href=\"https://www.lesswrong.com/tag/oracle-ai\">Oracle AI<\/a><\/li><\/ul><h2><strong>External Links<\/strong><\/h2><ul><li><a href=\"http://groups.yahoo.com/group/givewell/message/287\">Conversation between Holden Karnofsky and Jaan Tallinn<\/a><\/li><\/ul>"},"Tag:LXk7bxNkYSjgatdAt":{"_id":"LXk7bxNkYSjgatdAt","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:LXk7bxNkYSjgatdAt_description"},"userId":"qgdGA4ZEyW7zNdK84","name":"Tool AI","slug":"tool-ai","core":false,"postCount":27,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-08-22T00:13:20.139Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:c42eTtBCXyJmtpqwZ_description":{"_id":"c42eTtBCXyJmtpqwZ_description","__typename":"Revision","htmlHighlight":"<p>Not obviously the best name for this tag, but maybe good to explore/rename. Wiki-tags are publicly editable!<\/p>"},"Tag:c42eTtBCXyJmtpqwZ":{"_id":"c42eTtBCXyJmtpqwZ","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:c42eTtBCXyJmtpqwZ_description"},"userId":"qgdGA4ZEyW7zNdK84","name":"AI-assisted/AI automated Alignment","slug":"ai-assisted-ai-automated-alignment","core":false,"postCount":31,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2022-08-23T05:10:09.247Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:YWzByWvtXunfrBu5b_description":{"_id":"YWzByWvtXunfrBu5b_description","__typename":"Revision","htmlHighlight":"<p><strong>GPT<\/strong> (Generative Pretrained Transformer) is a family of large transformer-based language models created by <a href=\"https://lesswrong.com/tag/openai\">OpenAI<\/a>. Its ability to generate remarkably human-like responses has relevance to discussions on AGI.<\/p><p>External links:<\/p><p><a href=\"https://arxiv.org/abs/2005.14165\">GPT-3 Paper<\/a><\/p><p><a href=\"https://openai.com/api/\">GPT-3 Website<\/a><\/p>"},"Tag:YWzByWvtXunfrBu5b":{"_id":"YWzByWvtXunfrBu5b","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:YWzByWvtXunfrBu5b_description"},"userId":"nLbwLhBaQeG6tCNDN","name":"GPT","slug":"gpt","core":null,"postCount":212,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-04-10T18:07:00.605Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:oQ9hq3SWXQsCP2aiq_biography":{"_id":"oQ9hq3SWXQsCP2aiq_biography","__typename":"Revision","version":"1.2.0","updateType":"minor","editedAt":"2022-11-26T00:00:03.393Z","userId":"oQ9hq3SWXQsCP2aiq","html":"<p>independent alignment researcher<\/p>","wordCount":3,"htmlHighlight":"<p>independent alignment researcher<\/p>","plaintextDescription":"independent alignment researcher"},"User:oQ9hq3SWXQsCP2aiq":{"_id":"oQ9hq3SWXQsCP2aiq","__typename":"User","biography":{"__ref":"Revision:oQ9hq3SWXQsCP2aiq_biography"},"profileImageId":null,"moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":null,"slug":"nicholaskees","createdAt":"2019-07-21T00:52:51.695Z","username":"nick_kees","displayName":"NicholasKees","previousDisplayName":"nick_kees","fullName":"Nicholas Kees Dupuis","karma":179,"afKarma":65,"deleted":null,"isAdmin":false,"htmlBio":"<p>independent alignment researcher<\/p>","postCount":2,"commentCount":19,"sequenceCount":null,"afPostCount":1,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0},"User:pWHLps2yEJTSNNBLk":{"_id":"pWHLps2yEJTSNNBLk","__typename":"User","slug":"janus-1","createdAt":"2021-09-25T11:56:33.908Z","username":"janus","displayName":"janus","previousDisplayName":null,"fullName":"janus","karma":1899,"afKarma":343,"deleted":null,"isAdmin":false,"htmlBio":"","postCount":7,"commentCount":105,"sequenceCount":1,"afPostCount":5,"afCommentCount":33,"spamRiskScore":1,"tagRevisionCount":1,"biography":{"__ref":"Revision:pWHLps2yEJTSNNBLk_biography"},"profileImageId":null,"moderationStyle":"easy-going","bannedUserIds":null,"moderatorAssistance":true},"Post:bxt7uCiHam4QXrQAA":{"_id":"bxt7uCiHam4QXrQAA","__typename":"Post","recentComments({\"af\":false,\"commentsLimit\":4,\"maxAgeHours\":18})":[{"__ref":"Comment:2CxekqM5fc87mmqXn"}],"deletedDraft":false,"contents":{"__ref":"Revision:bxt7uCiHam4QXrQAA_"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":42,"moderationGuidelines":{"__ref":"Revision:bxt7uCiHam4QXrQAA_moderationGuidelines"},"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:xjNvvmvQ5BH3cfEBr"},{"__ref":"Tag:sYm3HiWcfZvrGu3ui"},{"__ref":"Tag:GDGYkF29pxEQNWjYc"},{"__ref":"Tag:LXk7bxNkYSjgatdAt"},{"__ref":"Tag:c42eTtBCXyJmtpqwZ"},{"__ref":"Tag:YWzByWvtXunfrBu5b"}],"url":null,"postedAt":"2023-02-10T14:47:48.172Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":[{"userId":"pWHLps2yEJTSNNBLk","confirmed":true,"requested":false}],"hasCoauthorPermission":true,"commentCount":1,"voteCount":16,"baseScore":47,"extendedScore":null,"unlisted":false,"score":5.072597868866807,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2023-02-10T15:46:07.682Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"oQ9hq3SWXQsCP2aiq","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":null,"suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"afBaseScore":20,"afExtendedScore":null,"afCommentCount":null,"afLastCommentedAt":"2023-02-08T19:17:53.821Z","afSticky":false,"hideAuthor":false,"moderationStyle":"easy-going","submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"reviewCount":null,"reviewVoteCount":null,"positiveReviewVoteCount":null,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"user":{"__ref":"User:oQ9hq3SWXQsCP2aiq"},"coauthors":[{"__ref":"User:pWHLps2yEJTSNNBLk"}],"slug":"cyborgism","title":"Cyborgism","draft":false,"hideCommentKarma":false,"af":true,"currentUserReviewVote":null},"Revision:t6XW72DpMvswEkXw7_":{"_id":"t6XW72DpMvswEkXw7_","__typename":"Revision","html":"<p>Strong agree with the main point, it confused me for a long time why people were saying we had no evidence of mesa-optimizers existing, and made me think I was getting something very wrong. I disagree with this line though:<\/p><blockquote><p><i>ChatGPT using chain of thought is plausibly already a mesaoptimizer.<\/i><\/p><\/blockquote><p>I think simulacra are better thought of as sub-agents in relation to the original paper's terminology than mesa-optimizers. ChatGPT doesn't seem to be doing anything qualitatively different on this note. The Assistant simulacrum can be seen as doing optimization (depending on your definition of the term), but the fact that jailbreak methods exist to get the underlying model to adopt different simulacra seems to me to show that it's still using the simulator mechanism. Moreover, I expect that if we get GPT-3 level models that are optimizers at the simulator-level, I think things would look <i>very<\/i> different.<\/p>","plaintextMainText":"Strong agree with the main point, it confused me for a long time why people were\nsaying we had no evidence of mesa-optimizers existing, and made me think I was\ngetting something very wrong. I disagree with this line though:\n\nI think simulacra are better thought of as sub-agents in relation to the\noriginal paper's terminology than mesa-optimizers. ChatGPT doesn't seem to be\ndoing anything qualitatively different on this note. The Assistant simulacrum\ncan be seen as doing optimization (depending on your definition of the term),\nbut the fact that jailbreak methods exist to get the underlying model to adopt\ndifferent simulacra seems to me to show that it's still using the simulator\nmechanism. Moreover, I expect that if we get GPT-3 level models that are\noptimizers at the simulator-level, I think things would look very different.","wordCount":148},"Comment:t6XW72DpMvswEkXw7":{"_id":"t6XW72DpMvswEkXw7","__typename":"Comment","postId":"LAxAmooK4uDfWmbep","tagId":null,"tag":null,"tagCommentType":"DISCUSSION","parentCommentId":"gghiYyfzPJKWeTG7o","topLevelCommentId":"gghiYyfzPJKWeTG7o","descendentCount":0,"title":null,"contents":{"__ref":"Revision:t6XW72DpMvswEkXw7_"},"postedAt":"2023-02-10T15:33:39.793Z","repliesBlockedUntil":null,"userId":"e9ToWWzhwWp5GSE7P","deleted":false,"deletedPublic":false,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:e9ToWWzhwWp5GSE7P"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":1,"extendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"score":15.403202103857955,"voteCount":1,"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"needsReview":null,"answer":false,"parentAnswerId":null,"retracted":false,"postVersion":"0.19.7","reviewedByUserId":null,"shortform":false,"lastSubthreadActivity":"2023-02-10T15:33:39.796Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":null,"votingSystem":"twoAxis","isPinnedOnProfile":false},"Revision:Ai69SsK4LJekcN5vF_":{"_id":"Ai69SsK4LJekcN5vF_","__typename":"Revision","html":"<p>One more, related to your first point: I wouldn't expect all mesaoptimizers to have the same signature, since they could take very different forms. What does the distribution of mesaoptimizer signatures look like? How likely is it that a novel (undetectable) mesaoptimizer arises in training?<\/p>","plaintextMainText":"One more, related to your first point: I wouldn't expect all mesaoptimizers to\nhave the same signature, since they could take very different forms. What does\nthe distribution of mesaoptimizer signatures look like? How likely is it that a\nnovel (undetectable) mesaoptimizer arises in training?","wordCount":45},"User:ye3Gk7544RaxnNaf7":{"_id":"ye3Gk7544RaxnNaf7","__typename":"User","slug":"joel-burget","createdAt":"2018-09-02T15:23:03.257Z","username":"joel-burget","displayName":"Joel Burget","previousDisplayName":null,"fullName":null,"karma":107,"afKarma":4,"deleted":null,"isAdmin":false,"htmlBio":"","postCount":5,"commentCount":22,"sequenceCount":0,"afPostCount":null,"afCommentCount":1,"spamRiskScore":1,"tagRevisionCount":1},"Comment:Ai69SsK4LJekcN5vF":{"_id":"Ai69SsK4LJekcN5vF","__typename":"Comment","postId":"LAxAmooK4uDfWmbep","tagId":null,"tag":null,"tagCommentType":"DISCUSSION","parentCommentId":"XSRLZjwnzZBXYqX9T","topLevelCommentId":"rW872wfxTi6tSaAMB","descendentCount":0,"title":null,"contents":{"__ref":"Revision:Ai69SsK4LJekcN5vF_"},"postedAt":"2023-02-10T13:56:25.155Z","repliesBlockedUntil":null,"userId":"ye3Gk7544RaxnNaf7","deleted":false,"deletedPublic":false,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:ye3Gk7544RaxnNaf7"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":1,"extendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"score":5.593557720032349,"voteCount":1,"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"needsReview":null,"answer":false,"parentAnswerId":null,"retracted":false,"postVersion":"0.19.7","reviewedByUserId":null,"shortform":false,"lastSubthreadActivity":"2023-02-10T13:56:25.292Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":null,"votingSystem":"twoAxis","isPinnedOnProfile":false},"Revision:W9H9nsvGQoxLqobuN_":{"_id":"W9H9nsvGQoxLqobuN_","__typename":"Revision","html":"<p>The critical issue is whether consequentialist mesa optimizers will arise. If consequentialist mesaoptimizers don't arise, like in the link below, then much of the safety concern is gone.<\/p>\n<p>Link below:<\/p>\n<p><a href=\"https://www.lesswrong.com/posts/firtXAWGdvzXYAh9B/paper-transformers-learn-in-context-by-gradient-descent#pbEciBKsk86xmcgqb\">https://www.lesswrong.com/posts/firtXAWGdvzXYAh9B/paper-transformers-learn-in-context-by-gradient-descent#pbEciBKsk86xmcgqb<\/a><\/p>\n","plaintextMainText":"The critical issue is whether consequentialist mesa optimizers will arise. If\nconsequentialist mesaoptimizers don't arise, like in the link below, then much\nof the safety concern is gone.\n\nLink below:\n\nhttps://www.lesswrong.com/posts/firtXAWGdvzXYAh9B/paper-transformers-learn-in-context-by-gradient-descent#pbEciBKsk86xmcgqb\n[https://www.lesswrong.com/posts/firtXAWGdvzXYAh9B/paper-transformers-learn-in-context-by-gradient-descent#pbEciBKsk86xmcgqb]","wordCount":31},"Comment:W9H9nsvGQoxLqobuN":{"_id":"W9H9nsvGQoxLqobuN","__typename":"Comment","postId":"LAxAmooK4uDfWmbep","tagId":null,"tag":null,"tagCommentType":"DISCUSSION","parentCommentId":"gghiYyfzPJKWeTG7o","topLevelCommentId":"gghiYyfzPJKWeTG7o","descendentCount":0,"title":null,"contents":{"__ref":"Revision:W9H9nsvGQoxLqobuN_"},"postedAt":"2023-02-10T13:15:49.839Z","repliesBlockedUntil":null,"userId":"nRknKQuPzoG2Wuyyi","deleted":false,"deletedPublic":false,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:nRknKQuPzoG2Wuyyi"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":1,"extendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"score":3.932603965152085,"voteCount":1,"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"needsReview":null,"answer":false,"parentAnswerId":null,"retracted":false,"postVersion":"0.19.7","reviewedByUserId":null,"shortform":false,"lastSubthreadActivity":"2023-02-10T13:15:49.843Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":null,"votingSystem":"twoAxis","isPinnedOnProfile":false},"Revision:Ebk4BXsNjefRSY5K4_":{"_id":"Ebk4BXsNjefRSY5K4_","__typename":"Revision","html":"<p>Thanks for this nice post !<\/p>\n<p>When you said that the objective was to &nbsp;find the type of strategies the model currently learning before it becomes performant, and stop it if this isnt the one we want&nbsp;\nBut how would you define what attractors are good ones ? How to identifiate the properties of an attractor if no dangerous model as been trained that has this attractor ?\nAnd what if the num er of attractor is huge and we cant test them all beforehand ? It doesnt seem obvious that the number of attractor wouldnt grow as the network does.<\/p>\n","plaintextMainText":"Thanks for this nice post !\n\nWhen you said that the objective was to find the type of strategies the model\ncurrently learning before it becomes performant, and stop it if this isnt the\none we want But how would you define what attractors are good ones ? How to\nidentifiate the properties of an attractor if no dangerous model as been trained\nthat has this attractor ? And what if the num er of attractor is huge and we\ncant test them all beforehand ? It doesnt seem obvious that the number of\nattractor wouldnt grow as the network does.","wordCount":103},"User:G5knkdcjXkEgK7sjF":{"_id":"G5knkdcjXkEgK7sjF","__typename":"User","slug":"wcargo","createdAt":"2022-01-09T17:48:47.848Z","username":"Wcargo","displayName":"Wcargo","previousDisplayName":null,"fullName":null,"karma":2,"afKarma":null,"deleted":null,"isAdmin":false,"htmlBio":"","postCount":null,"commentCount":2,"sequenceCount":null,"afPostCount":null,"afCommentCount":0,"spamRiskScore":0.9,"tagRevisionCount":null},"Comment:Ebk4BXsNjefRSY5K4":{"_id":"Ebk4BXsNjefRSY5K4","__typename":"Comment","postId":"LAxAmooK4uDfWmbep","tagId":null,"tag":null,"tagCommentType":"DISCUSSION","parentCommentId":null,"topLevelCommentId":null,"descendentCount":0,"title":null,"contents":{"__ref":"Revision:Ebk4BXsNjefRSY5K4_"},"postedAt":"2023-02-10T12:27:24.651Z","repliesBlockedUntil":null,"userId":"G5knkdcjXkEgK7sjF","deleted":false,"deletedPublic":false,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:G5knkdcjXkEgK7sjF"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":3,"extendedScore":{"approvalVoteCount":2,"agreement":0,"agreementVoteCount":0},"score":2.882966864014824,"voteCount":2,"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"needsReview":null,"answer":false,"parentAnswerId":null,"retracted":false,"postVersion":"0.19.7","reviewedByUserId":null,"shortform":false,"lastSubthreadActivity":"2023-02-10T12:27:24.655Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":null,"votingSystem":"twoAxis","isPinnedOnProfile":false},"Revision:LAxAmooK4uDfWmbep_":{"_id":"LAxAmooK4uDfWmbep_","__typename":"Revision","htmlHighlight":"<blockquote><p>Show me your original face before you were born.<br><br><i> Variation of the Zen koan<\/i><\/p><\/blockquote><figure class=\"image\"><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675924827/mirroredImages/LAxAmooK4uDfWmbep/tfzoi1estexh3tua0v8b.png\" srcset=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675924828/mirroredImages/LAxAmooK4uDfWmbep/ao8pkh5alrl8v6bevhab.png 270w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675924827/mirroredImages/LAxAmooK4uDfWmbep/rtnd0z4gs8ymmohd0fak.png 540w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675924827/mirroredImages/LAxAmooK4uDfWmbep/f13xu4bwvxh6fm0xnb0e.png 810w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675924827/mirroredImages/LAxAmooK4uDfWmbep/k0c7k3s9zoe6usvjlqpa.png 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675924827/mirroredImages/LAxAmooK4uDfWmbep/cs8bjparjl57djsi6dj9.png 1350w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675924829/mirroredImages/LAxAmooK4uDfWmbep/k64wdoepovmywd07ezhd.png 1620w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675924828/mirroredImages/LAxAmooK4uDfWmbep/x8cp9cqfaynetgyqxawu.png 1890w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675924828/mirroredImages/LAxAmooK4uDfWmbep/bppc0aeh4ysihqqtp5po.png 2160w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675924829/mirroredImages/LAxAmooK4uDfWmbep/r2uaqbwgw18lfnvuvbce.png 2430w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675924829/mirroredImages/LAxAmooK4uDfWmbep/sfebavswjahm718fhoar.png 2627w\"><figcaption><i>'The Mask' by Rozzi Roomian, with DALL-E 2 outpainting<\/i><\/figcaption><\/figure><p>I was able to use the <a href=\"https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation\">weird centroid-proximate tokens<\/a> that Jessica Mary and Matthew Watkins discovered to associate several of the Instruct models on the OpenAI API with the base models they were initialized from. Prompting GPT-3 models with these tokens causes aberrant and correlated behaviors, and I found that the correlation is preserved between base models and Instruct versions, thereby exposing a \"fingerprint\" inherited from pretraining.<\/p><p>I was inspired to try this by JDP's proposal to fingerprint generalization strategies using correlations in model outputs on out-of-distribution inputs. This post describes his idea and the outcome of my experiment, which I think is positive evidence that this \"black box cryptanalysis\"-inspired approach to fingerprinting models is promising.<\/p><h1>Unspeakable/unspoken tokens<\/h1><p>Jessica and Matthew found that that, of the tokens closest to the centroid in GPT-J's embedding space, many were odd words like ' SolidGoldMagikarp' and ' externalToEVA'. They decided to ask GPT-3 about these tokens, and found that not only did GPT-3 have trouble repeating the tokens back, each one caused structured anomalous behaviors (see <a href=\"https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation\">their post<\/a> for an in-depth exposition).<\/p><p><a href=\"https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation#A_possible__partial_explanation\">A partial explanation<\/a> for why this happens, which was my first instinct as well as Stuart Armstrong's, is that these are words that appeared in the GPT-2 training set frequently enough to be assigned tokens by the GPT-2 tokenizer, which GPT-J and GPT-3 also use, but which <i>didn't<\/i> appear in the more curated GPT-J and GPT-3 training sets. So the embeddings for these tokens may never have been updated by actual usages of the words during the training of these newer models. This might explain why the models aren't able to repeat them - they never saw them spoken. Perhaps the reason they're close to the centroid in embedding space is because their embeddings haven't been updated very much from the initialization values, or were updated only indirectly, and so remain very \"generic\".<\/p><p>Why do they cause correlated anomalous behaviors? I'm confused about this like everyone, but one handwavy guess is that since their embeddings look \"generic\" or \"typical\", perhaps they <i>look meaningful <\/i>to the model even though they're actually as out-of-distribution as anything can be. M... <\/p>","wordCount":2553,"version":"0.19.7"},"Revision:LAxAmooK4uDfWmbep_moderationGuidelines":{"_id":"LAxAmooK4uDfWmbep_moderationGuidelines","__typename":"Revision","html":""},"Revision:NZ67PZ8CkeS6xn27h_description":{"_id":"NZ67PZ8CkeS6xn27h_description","__typename":"Revision","htmlHighlight":"<p><strong>Mesa-Optimization<\/strong> is the situation that occurs when a learned model (such as a neural network) is itself an optimizer. In this situation, a <i>base optimizer<\/i> creates a second optimizer, called a <i>mesa-optimizer<\/i>. The primary reference work for this concept is Hubinger et al.'s \"<a href=\"https://www.alignmentforum.org/posts/FkgsxrGf3QxhfLWHG/risks-from-learned-optimization-introduction\">Risks from Learned Optimization in Advanced Machine Learning Systems<\/a>\".<\/p><p>Example: Natural selection is an optimization process that optimizes for reproductive fitness. Natural selection produced humans, who are themselves optimizers. Humans are therefore mesa-optimizers of natural selection.<\/p><p>In the context of AI alignment, the concern is that a base optimizer (e.g., a gradient descent process) may produce a learned model that is itself an optimizer, and that has unexpected and undesirable properties. Even if the gradient descent process is in some sense \"trying\" to do exactly what human developers want, the resultant mesa-optimizer will not typically be trying to do the exact same thing.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref1wvq4n2qe47\"><sup><a href=\"#fn1wvq4n2qe47\">[1]<\/a><\/sup><\/span><\/p><p>&nbsp;<\/p><h2>History<\/h2><p>Previously work under this concept was called <i>Inner Optimizer <\/i>or <i>Optimization Daemons.<\/i><\/p><p><a href=\"https://www.lesswrong.com/users/wei_dai\">Wei Dai<\/a> brings up a similar idea in an SL4 thread.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefqwecn6uicu\"><sup><a href=\"#fnqwecn6uicu\">[2]<\/a><\/sup><\/span><\/p><p>The optimization daemons article on <a href=\"https://arbital.com/\">Arbital<\/a> was published probably in 2016.<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref1wvq4n2qe47\"><sup><a href=\"#fn1wvq4n2qe47\">[1]<\/a><\/sup><\/span><\/p><p><a href=\"https://www.lesswrong.com/users/jessica-liu-taylor\">Jessica Taylor<\/a> wrote two posts about daemons while at <a href=\"https://www.lesswrong.com/tag/machine-intelligence-research-institute-miri\">MIRI<\/a>:<\/p><ul><li><a href=\"https://agentfoundations.org/item?id=1281\">\"Are daemons a problem for ideal agents?\"<\/a> (2017-02-11)<\/li><li><a href=\"https://agentfoundations.org/item?id=1290\">\"Maximally efficient agents will probably have an anti-daemon immune system\"<\/a> (2017-02-23)<\/li><\/ul><h2>&nbsp;<\/h2><h2>See also<\/h2><ul><li><a href=\"https://www.lesswrong.com/tag/inner-alignment\">Inner Alignment<\/a><\/li><li><a href=\"https://lessestwrong.com/tag/complexity-of-value\">Complexity of value<\/a><\/li><li><a href=\"https://lessestwrong.com/lw/l3/thou_art_godshatter/\">Thou Art Godshatter<\/a><\/li><\/ul><h2>External links<\/h2><p><a href=\"https://www.youtube.com/watch?v=bJLcIBixGj8\">Video by Robert Miles<\/a><\/p><p>Some posts that reference optimization daemons:<\/p><ul><li><a href=\"http://effective-altruism.com/ea/1k4/draft_cause_prioritization_for_downsidefocused/\">\"Cause prioritization for downside-focused value systems\"<\/a>: \"Alternatively, perhaps goal preservation becomes more difficult the more capable AI systems become, in which case the future might be controlled by unstable goal functions taking turns over the steering wheel\"<\/li><li><a href=\"https://ai-alignment.com/techniques-for-optimizing-worst-case-performance-39eafec74b99\">\"Techniques for optimizing worst-case performance\"<\/a>: \"The difficulty of optimizing worst-case performance is one of the most likely reasons that I think prosaic AI alignment might turn out to be impossible (if combined with an unlucky empirical situation).\" (the phrase \"unlucky empirical situation\" links to the optimization daemons page on <a href=\"https://arbital.com/\">Arbital<\/a>)<\/li><\/ul><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fn1wvq4n2qe47\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnref1wvq4n2qe47\">^<\/a><\/strong><\/sup><\/span><div class=\"footnote-content\"><p><a href=\"https://arbital.com/p/daemons/\"><u>\"Optimization daemons\"<\/u><\/a>. Arbital.<\/p><\/div><\/li><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnqwecn6uicu\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefqwecn6uicu\">^<\/a><\/strong><\/sup><\/span><div class=\"footnote-content\"><p>Wei Dai. <a href=\"http://sl4.org/archive/0312/7421.html\"><u>'\"friendly\" humans?'<\/u><\/a> December 31, 2003.<\/p><\/div><\/li><\/ol>"},"Tag:NZ67PZ8CkeS6xn27h":{"_id":"NZ67PZ8CkeS6xn27h","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:NZ67PZ8CkeS6xn27h_description"},"userId":"hbQoLoK5tpmFAJGr4","name":"Mesa-Optimization","slug":"mesa-optimization","core":null,"postCount":90,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":null,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-05-15T18:42:36.147Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:Dw5Z6wtTgk4Fikz9f_description":{"_id":"Dw5Z6wtTgk4Fikz9f_description","__typename":"Revision","htmlHighlight":"<p><strong>Inner Alignment <\/strong>is the problem of ensuring <a href=\"https://www.lesswrong.com/tag/mesa-optimization\">mesa-optimizers<\/a> (i.e. when a trained ML system is itself an optimizer) are aligned with the objective function of the training process. As an example, evolution is an optimization force that itself 'designed' optimizers (humans) to achieve its goals. However, humans do not primarily maximise reproductive success, they instead use birth control and then go out and have fun. This is a failure of inner alignment.&nbsp;<\/p><p>The term was first given a definition in the Hubinger et al paper <i>Risk from Learned Optimization<\/i>:<\/p><blockquote><p>We refer to this problem of aligning mesa-optimizers with the base objective as the inner alignment problem. This is distinct from the outer alignment problem, which is the traditional problem of ensuring that the base objective captures the intended goal of the programmers.<\/p><\/blockquote><p><strong>Related Pages:<\/strong> <a href=\"https://www.lesswrong.com/tag/mesa-optimization\">Mesa-Optimization<\/a><\/p><h2>External Links:<\/h2><p><a href=\"https://www.youtube.com/watch?v=bJLcIBixGj8\">Video by Robert Miles<\/a><\/p>"},"Tag:Dw5Z6wtTgk4Fikz9f":{"_id":"Dw5Z6wtTgk4Fikz9f","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:Dw5Z6wtTgk4Fikz9f_description"},"userId":"EQNTWXLKMeWMp2FQS","name":"Inner Alignment","slug":"inner-alignment","core":false,"postCount":158,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-17T06:11:39.285Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:pWHLps2yEJTSNNBLk_biography":{"_id":"pWHLps2yEJTSNNBLk_biography","__typename":"Revision","version":"1.2.0","updateType":"minor","editedAt":"2022-09-10T23:32:05.620Z","userId":"pWHLps2yEJTSNNBLk","html":"","wordCount":1,"htmlHighlight":"","plaintextDescription":null},"User:QBGzMxkzBJpLxBzTj":{"_id":"QBGzMxkzBJpLxBzTj","__typename":"User","slug":"jdp","createdAt":"2021-04-01T03:39:01.920Z","username":"jdp","displayName":"jdp","previousDisplayName":null,"fullName":"John David Pressman","karma":272,"afKarma":null,"deleted":null,"isAdmin":false,"htmlBio":"","postCount":2,"commentCount":4,"sequenceCount":null,"afPostCount":null,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0},"Post:LAxAmooK4uDfWmbep":{"_id":"LAxAmooK4uDfWmbep","__typename":"Post","recentComments({\"af\":false,\"commentsLimit\":4,\"maxAgeHours\":18})":[{"__ref":"Comment:t6XW72DpMvswEkXw7"},{"__ref":"Comment:Ai69SsK4LJekcN5vF"},{"__ref":"Comment:W9H9nsvGQoxLqobuN"},{"__ref":"Comment:Ebk4BXsNjefRSY5K4"}],"deletedDraft":false,"contents":{"__ref":"Revision:LAxAmooK4uDfWmbep_"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":10,"moderationGuidelines":{"__ref":"Revision:LAxAmooK4uDfWmbep_moderationGuidelines"},"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:YWzByWvtXunfrBu5b"},{"__ref":"Tag:sYm3HiWcfZvrGu3ui"},{"__ref":"Tag:NZ67PZ8CkeS6xn27h"},{"__ref":"Tag:Dw5Z6wtTgk4Fikz9f"}],"url":"https://generative.ink/posts/anomalous-tokens-reveal-the-original-identities-of-instruct-models/","postedAt":"2023-02-09T01:30:56.609Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2023-02-09T01:40:19.035Z","meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":[{"userId":"QBGzMxkzBJpLxBzTj","confirmed":true,"requested":false}],"hasCoauthorPermission":true,"commentCount":12,"voteCount":53,"baseScore":109,"extendedScore":null,"unlisted":false,"score":1.1782954484173904,"lastVisitedAt":"2023-02-10T12:32:01.209Z","isFuture":false,"isRead":true,"lastCommentedAt":"2023-02-10T15:33:40.005Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"pWHLps2yEJTSNNBLk","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"nLbwLhBaQeG6tCNDN","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"afBaseScore":39,"afExtendedScore":null,"afCommentCount":7,"afLastCommentedAt":"2023-02-10T02:38:47.941Z","afSticky":false,"hideAuthor":false,"moderationStyle":"easy-going","submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"reviewCount":null,"reviewVoteCount":null,"positiveReviewVoteCount":null,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"user":{"__ref":"User:pWHLps2yEJTSNNBLk"},"coauthors":[{"__ref":"User:QBGzMxkzBJpLxBzTj"}],"slug":"anomalous-tokens-reveal-the-original-identities-of-instruct","title":"Anomalous tokens reveal the original identities of Instruct models","draft":false,"hideCommentKarma":false,"af":true,"currentUserReviewVote":null},"Revision:RTD3KpvG3nsG4ctDN_":{"_id":"RTD3KpvG3nsG4ctDN_","__typename":"Revision","html":"<p>The base models of GPT-3 already have the ability to \"follow instructions\", it's just veiled behind the more general interface. If you prompt it with something as simple as <a href=\"https://imgur.com/a/rmvfPSA\">this<\/a> (GPT generation is highlighted), you can see how it contains this capability <i>somewhere<\/i>.<\/p><p>You may have noticed that it starts to repeat itself after a few lines, and come up with new questions on its own besides. That's part of what the fine-tuning fixes, making its generations more concise and stop at the point where the next token would be leading to another question. InstructGPT also has the value of not needing the wrapper of \"Q: [] A: []\", but that's not really a qualitative difference.<\/p><p>In other words, instruction following is <i>not<\/i> a new capability and the fine-tuning doesn't really make any qualitative changes to the model. In fact, I think that you can get results [close to] this good if you prompt it <i>really<\/i> well (like, in the realm of <a href=\"https://ai.googleblog.com/2022/02/guiding-frozen-language-models-with.html\">soft prompts<\/a>).<\/p>","plaintextMainText":"The base models of GPT-3 already have the ability to \"follow instructions\", it's\njust veiled behind the more general interface. If you prompt it with something\nas simple as this [https://imgur.com/a/rmvfPSA] (GPT generation is highlighted),\nyou can see how it contains this capability somewhere.\n\nYou may have noticed that it starts to repeat itself after a few lines, and come\nup with new questions on its own besides. That's part of what the fine-tuning\nfixes, making its generations more concise and stop at the point where the next\ntoken would be leading to another question. InstructGPT also has the value of\nnot needing the wrapper of \"Q: [] A: []\", but that's not really a qualitative\ndifference.\n\nIn other words, instruction following is not a new capability and the\nfine-tuning doesn't really make any qualitative changes to the model. In fact, I\nthink that you can get results [close to] this good if you prompt it really well\n(like, in the realm of soft prompts\n[https://ai.googleblog.com/2022/02/guiding-frozen-language-models-with.html]).","wordCount":164},"Comment:RTD3KpvG3nsG4ctDN":{"_id":"RTD3KpvG3nsG4ctDN","__typename":"Comment","postId":"eywpzHRgXTCCAi8yt","tagId":null,"tag":null,"tagCommentType":"DISCUSSION","parentCommentId":null,"topLevelCommentId":null,"descendentCount":0,"title":null,"contents":{"__ref":"Revision:RTD3KpvG3nsG4ctDN_"},"postedAt":"2023-02-10T15:27:05.091Z","repliesBlockedUntil":null,"userId":"e9ToWWzhwWp5GSE7P","deleted":false,"deletedPublic":false,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:e9ToWWzhwWp5GSE7P"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":2,"extendedScore":{"approvalVoteCount":2,"agreement":0,"agreementVoteCount":0},"score":14.465176007012928,"voteCount":2,"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"needsReview":null,"answer":true,"parentAnswerId":null,"retracted":false,"postVersion":"1.0.0","reviewedByUserId":null,"shortform":false,"lastSubthreadActivity":"2023-02-10T15:27:05.106Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":null,"votingSystem":"twoAxis","isPinnedOnProfile":false},"Revision:eywpzHRgXTCCAi8yt_":{"_id":"eywpzHRgXTCCAi8yt_","__typename":"Revision","htmlHighlight":"<p>I <a href=\"https://www.lesswrong.com/posts/BPRHZFH2xx7nz5TYT/open-and-welcome-thread-january-2023?commentId=LufkFyHkAarrf3yLN\">posted<\/a> in the open thread and was told that it would be worth promoting to top level.<\/p>\n<p>cubefox <a href=\"https://www.lesswrong.com/posts/BPRHZFH2xx7nz5TYT/open-and-welcome-thread-january-2023?commentId=nmuzRkjxkpxJF2MWY\">responded<\/a> with a <a href=\"https://openai.com/blog/instruction-following/\">link<\/a> to an great explanation of <em>how<\/em> the fine-tuning is done, which made me realize that my original question was unclear, so I'm going to try to clarify.<\/p>\n<p>The fundamental behavior of GPT-3 is token prediction, which can straightforwardly be leveraged into text completion; in contrast, the fundamental behavior of InstructGPT is instruction following. Instruction following is a new capability that uses the knowledge from the token prediction task to produce output as well as to understand input; how does that capability develop?<\/p>\n<p>Some plausible experiments related to the question:<\/p>\n<ul>\n<li>Follow a similar methodology to fine-tune a predictive model for instruction following, checkpointing along the way; for 100 (or even more) novel instruction prompts, see how the different checkpoints respond (in particular, how often they do completion vs instruction following).<\/li>\n<li>Given a prompt <code>P<\/code>, which produces completion <code>C<\/code> when fed into the fine-tuned model, try to find a prompt <code>P'<\/code> that produces <code>C<\/code> when fed into the original model.<\/li>\n<li>Fine-tune twice with the same data and reward model, but in a different order; presumably the models will have different weights, but can we find prompts that give widely diverging results? If we have two checkpoint histories, at which point does the behavior diverge?<\/li>\n<\/ul>","wordCount":228,"version":"1.0.0"},"Revision:66rcHyj9vi4TpqHF5_biography":{"_id":"66rcHyj9vi4TpqHF5_biography","__typename":"Revision","version":"1.2.0","updateType":"minor","editedAt":"2023-01-09T21:09:43.007Z","userId":"66rcHyj9vi4TpqHF5","html":"","wordCount":0,"htmlHighlight":"","plaintextDescription":null},"User:66rcHyj9vi4TpqHF5":{"_id":"66rcHyj9vi4TpqHF5","__typename":"User","biography":{"__ref":"Revision:66rcHyj9vi4TpqHF5_biography"},"profileImageId":null,"moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":null,"slug":"alex-rozenshteyn","createdAt":"2017-11-23T02:05:30.153Z","username":"alex-rozenshteyn","displayName":"rpglover64","previousDisplayName":"Alex Rozenshteyn","fullName":null,"karma":122,"afKarma":0,"deleted":null,"isAdmin":false,"htmlBio":"","postCount":3,"commentCount":42,"sequenceCount":0,"afPostCount":null,"afCommentCount":null,"spamRiskScore":1,"tagRevisionCount":0},"Post:eywpzHRgXTCCAi8yt":{"_id":"eywpzHRgXTCCAi8yt","__typename":"Post","recentComments({\"af\":false,\"commentsLimit\":4,\"maxAgeHours\":18})":[{"__ref":"Comment:RTD3KpvG3nsG4ctDN"}],"deletedDraft":false,"contents":{"__ref":"Revision:eywpzHRgXTCCAi8yt_"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":1,"moderationGuidelines":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:sYm3HiWcfZvrGu3ui"},{"__ref":"Tag:YWzByWvtXunfrBu5b"}],"url":null,"postedAt":"2023-02-10T07:57:04.733Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"commentCount":1,"voteCount":5,"baseScore":17,"extendedScore":null,"unlisted":false,"score":1.1474235841185743,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2023-02-10T15:27:05.302Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":true,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"66rcHyj9vi4TpqHF5","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":null,"suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"afBaseScore":4,"afExtendedScore":null,"afCommentCount":null,"afLastCommentedAt":"2023-02-10T07:57:04.735Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"reviewCount":null,"reviewVoteCount":null,"positiveReviewVoteCount":null,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"user":{"__ref":"User:66rcHyj9vi4TpqHF5"},"coauthors":[],"slug":"what-s-actually-going-on-in-the-mind-of-the-model-when-we","title":"What's actually going on in the \"mind\" of the model when we fine-tune GPT-3 to InstructGPT?","draft":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null},"Revision:3xx9fpaJk6NfRhn7D_":{"_id":"3xx9fpaJk6NfRhn7D_","__typename":"Revision","htmlHighlight":"<p><span>\n\nIn contra dance there are two roles, which were traditionally called\n\"Ladies\" and \"Gents\".  A lot of people are currently trying to move\nthe community over to calling the roles \"Robins\" and \"Larks\", to make\nit clear that anyone can dance either role.  BIDA, the dance I help\norganize, switched in <\/span>\n\n<a href=\"https://blog.bidadance.org/2017/06/switching-to-larks-and-ravens.html\">2017<\/a>,\nand since restarting dances in Spring 2022 \n\n<a href=\"https://www.jefftk.com/p/boston-contra-fully-gender-free\">all the Boston dances<\/a>\nare gender-free.  A recent discussion on the sharedweight \n\n<a href=\"https://www.sharedweight.net/lists/contra-callers/\">callers\nlist<\/a>, however, brought up some past times people tried to change\ncontra dance role terms, and I wanted to look into this more.\n\n\n\n<\/p><p>\n\nIn the early 90s, there was a push to move from Gents/Ladies\nto Men/Women.  For example, here's Myrtle Wilhite's 1993\nessay, \"I am not a lady\":\n\n<\/p><p>\n\n<\/p>\n\n<blockquote>\n<p>\nYou may notice that I don't write or call dances with ladies in\nthem. This is distinctly classist language in the fabric of contra\nterminology which not only implies upper vs. lower class distinctions\n('woman' does not), but encourages submission for the women (\"now, act\nlike a lady!!!\"). I preserve the clarity of the call with \"women\" for\nladies and \"men\" for gents (same number of syllables), and in my\ncalling years I have never had any misunderstandings about it. (As you\nmight guess, I don't call \"...and trap that pretty little girl\" in\nsquare calls either.)\n<\/p><p>\nTo the rejoinder that \"the figure is called a ladies chain\", I reply\nthat the name of a figure is \"chain\", and that the gender\ndiscrimination only determines who is to cross the set. After all,\nthere are \"men's chains\".\n<\/p><p>\nTo those who reply that this is \"traditional wording that shalt not be\naltered\" (was that the eleventh commandment?), I remind them that this\nis THE FOLK PROCESS after all, and I'm allowed to try different\nthings, thank you. If the wording didn't work, it wouldn't work, but\nit does. Of those who spontaneously noticed, I had only favorable\ncomments from men and women alike. (I wonder after writing that how\nmany ruffled feathers there will be--good excuse to make a feather\npillow...)\n<\/p><p>\nSo, I'd like to suggest that you refer to the woman's role\nconsistently by the term woman or women, and the man's role\nconsistently by the term man or men. And if you don't think that other\nchoreographers are likely to agree with this editing, I would really\nlike you to at least preserve the terminology in my dances/dance\ndescriptions. If you choose not to do this in your own calling or\ndance ch<\/p><\/blockquote>...","wordCount":852,"version":"1.1.0"},"Revision:3xx9fpaJk6NfRhn7D_moderationGuidelines":{"_id":"3xx9fpaJk6NfRhn7D_moderationGuidelines","__typename":"Revision","html":""},"Revision:TtEoCrFeowCGb6rFK_biography":{"_id":"TtEoCrFeowCGb6rFK_biography","__typename":"Revision","version":"1.2.0","updateType":"minor","editedAt":"2022-12-28T15:53:45.439Z","userId":"TtEoCrFeowCGb6rFK","html":"<p>Software engineer at the Nucleic Acid Observatory in Boston. Speaking for myself unless I say otherwise.<\/p>","wordCount":16,"htmlHighlight":"<p>Software engineer at the Nucleic Acid Observatory in Boston. Speaking for myself unless I say otherwise.<\/p>","plaintextDescription":"Software engineer at the Nucleic Acid Observatory in Boston. Speaking for myself unless I say otherwise."},"User:TtEoCrFeowCGb6rFK":{"_id":"TtEoCrFeowCGb6rFK","__typename":"User","biography":{"__ref":"Revision:TtEoCrFeowCGb6rFK_biography"},"profileImageId":null,"moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":null,"slug":"jkaufman","createdAt":"2010-11-04T21:42:19.863Z","username":"jkaufman","displayName":"jefftk","previousDisplayName":null,"fullName":"Jeff Kaufman","karma":13944,"afKarma":3,"deleted":false,"isAdmin":false,"htmlBio":"<p>Software engineer at the Nucleic Acid Observatory in Boston. Speaking for myself unless I say otherwise.<\/p>","postCount":621,"commentCount":1663,"sequenceCount":null,"afPostCount":0,"afCommentCount":1,"spamRiskScore":1,"tagRevisionCount":1},"Post:3xx9fpaJk6NfRhn7D":{"_id":"3xx9fpaJk6NfRhn7D","__typename":"Post","recentComments({\"af\":false,\"commentsLimit\":4,\"maxAgeHours\":18})":[],"deletedDraft":false,"contents":{"__ref":"Revision:3xx9fpaJk6NfRhn7D_"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":3,"moderationGuidelines":{"__ref":"Revision:3xx9fpaJk6NfRhn7D_moderationGuidelines"},"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[],"url":null,"postedAt":"2023-02-10T15:00:01.226Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"commentCount":null,"voteCount":1,"baseScore":9,"extendedScore":null,"unlisted":false,"score":2.2196472364523805,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2023-02-10T15:00:01.226Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"TtEoCrFeowCGb6rFK","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":null,"suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":0,"afExtendedScore":null,"afCommentCount":null,"afLastCommentedAt":"2023-02-10T15:00:01.229Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"reviewCount":null,"reviewVoteCount":null,"positiveReviewVoteCount":null,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"user":{"__ref":"User:TtEoCrFeowCGb6rFK"},"coauthors":[],"slug":"contra-changing-role-terms","title":"Contra: Changing Role Terms","draft":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null},"Revision:dYjaeCpirbjw7R7yu_":{"_id":"dYjaeCpirbjw7R7yu_","__typename":"Revision","html":"<p>Interesting that you mention this. I just discussed it with someone else who made the same point. Honestly, I didn't think it through while writing the novel, so you could regard it as a logical flaw. However, in hindsight and inspired by the comments of the other person, I came up with a theory about how this was possible which I will include in a revised version at some later point.<\/p>","plaintextMainText":"Interesting that you mention this. I just discussed it with someone else who\nmade the same point. Honestly, I didn't think it through while writing the\nnovel, so you could regard it as a logical flaw. However, in hindsight and\ninspired by the comments of the other person, I came up with a theory about how\nthis was possible which I will include in a revised version at some later point.","wordCount":71},"User:hdQn7FqtLu2PHCYQF":{"_id":"hdQn7FqtLu2PHCYQF","__typename":"User","slug":"karl-von-wendt","createdAt":"2022-02-25T14:58:39.203Z","username":"Karl von Wendt","displayName":"Karl von Wendt","previousDisplayName":null,"fullName":null,"karma":210,"afKarma":12,"deleted":null,"isAdmin":false,"htmlBio":"<p>German writer of science-fiction novels and children's books (pen name Karl Olsberg). I blog and create videos about AI risks in German at <a href=\"http://www.ki-risiken.de\">www.ki-risiken.de<\/a> and <a href=\"http://youtube.com/karlolsbergautor\">youtube.com/karlolsbergautor<\/a>.<\/p>\n","postCount":4,"commentCount":45,"sequenceCount":null,"afPostCount":null,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":null,"biography":{"__ref":"Revision:hdQn7FqtLu2PHCYQF_biography"},"profileImageId":null,"moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":null},"Comment:dYjaeCpirbjw7R7yu":{"_id":"dYjaeCpirbjw7R7yu","__typename":"Comment","postId":"rSiybWzeiG8agYtNr","tagId":null,"tag":null,"tagCommentType":"DISCUSSION","parentCommentId":"tjKsqyci9RZZ6agiK","topLevelCommentId":"tjKsqyci9RZZ6agiK","descendentCount":0,"title":null,"contents":{"__ref":"Revision:dYjaeCpirbjw7R7yu_"},"postedAt":"2023-02-10T14:56:28.162Z","repliesBlockedUntil":null,"userId":"hdQn7FqtLu2PHCYQF","deleted":false,"deletedPublic":false,"deletedReason":null,"hideAuthor":false,"authorIsUnreviewed":false,"user":{"__ref":"User:hdQn7FqtLu2PHCYQF"},"currentUserVote":null,"currentUserExtendedVote":null,"baseScore":1,"extendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"score":9.99373014721801,"voteCount":1,"af":false,"afDate":null,"moveToAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"needsReview":null,"answer":false,"parentAnswerId":null,"retracted":false,"postVersion":"1.1.0","reviewedByUserId":null,"shortform":false,"lastSubthreadActivity":"2023-02-10T14:56:28.165Z","moderatorHat":false,"hideModeratorHat":null,"nominatedForReview":null,"reviewingForReview":null,"promoted":null,"promotedByUser":null,"directChildrenCount":null,"votingSystem":"twoAxis","isPinnedOnProfile":false},"Revision:rSiybWzeiG8agYtNr_":{"_id":"rSiybWzeiG8agYtNr_","__typename":"Revision","htmlHighlight":"<p>Ive written a novel about AI alignment in German and translated it into English. You can <a href=\"https://docs.google.com/document/d/10wTLO0LSnTGM8JkYzLGBEgF8tdq-82TU/edit?usp=sharing&amp;ouid=107790339755901298954&amp;rtpof=true&amp;sd=true\">read and comment on the English version here<\/a> or <a href=\"https://drive.google.com/file/d/1f2tP--RTafQX1a5_pVGyjFVagLyRbFc_/view?usp=share_link\">download the ebook<\/a> or <a href=\"https://drive.google.com/file/d/1lOPB7WzDNfSgz70zEKMIElBw3fB_RoRp/view?usp=sharing\">a PDF in A4<\/a> or <a href=\"https://drive.google.com/file/d/1ZaOj_m396VACHGw8_sFzHSnq07D7OXzk/view?usp=sharing\">US letter format<\/a>. This is a preliminary version not (yet) intended for the general public, so please dont distribute the links outside the AI safety/EA communities. Id appreciate your feedback!<\/p><h2>Teaser:&nbsp;<\/h2><p>When psychologist Daniel unexpectedly gets a job offer from the Berlin subsidiary of Mental Systems, one of the leading technology companies in the world, hes excited. But he soon finds out that behind the friendly facade, theres enormous pressure because Mental Systems is in a global race for the development of the first artificial general intelligence. With their amazing AI Virtua, they seem to be in the lead. But some are concerned about the rapid progress because it seems unclear whether the trust the management puts in Virtua is really justified. When a devastating hacker attack seems to have destroyed years of research and the lead of the AI safety team is gone missing, Daniel sets out on a quest to find out what really happened, and why. But will he be able to prevent a disastrous turn of events that could destroy the future of humanity?<\/p><h2>Some background:<\/h2><p>Im a professional novelist with more than 50 books published in German under the <a href=\"https://karl-olsberg.jimdo.com/english/\">pen name Karl Olsberg<\/a>. My first novel Das System about an out-of-control AI, published in 2007, became a national bestseller. At the time, I had no idea how an AI could really get out of control, so the novel was highly speculative science fiction. Since then, I have seen reality coming uncomfortably close to the scenarios in my books. Since my participation in the AI safety camp last year, my timeline expectation for AGI has shrunken significantly. VIRTUA is probably my most realistic AI novel yet. I still hope it will remain science fiction.<\/p><p>At the next AI safety camp, Ill lead a project with the goal of <a href=\"https://docs.google.com/document/d/1U--XV5Cuu5lug1kIJLJGYYEaqvYrsUZV7d1Q7cDR_ss/edit?usp=sharing\">developing realistic and detailed failure stories<\/a>. If youre interested in collaborating, you can <a href=\"https://aisafety.camp/\">apply here<\/a> until January 19<sup>th<\/sup>.<\/p><p><strong>Edit: <\/strong>At about the same time I posted this, blaked has published an impressive post describing <a href=\"https://www.lesswrong.com/posts/9kQFure4hdDmRBNdH/how-it-feels-to-have-your-mind-hacked-by-an-ai\">his own experience with an LLM that \"hacked his mind\"<\/a> in a similar way to what happens to Jerry in the book.&nbsp;<\/p>","wordCount":394,"version":"1.1.0"},"Revision:rSiybWzeiG8agYtNr_moderationGuidelines":{"_id":"rSiybWzeiG8agYtNr_moderationGuidelines","__typename":"Revision","html":""},"Revision:Rz5jb3cYHTSRmqNnN_description":{"_id":"Rz5jb3cYHTSRmqNnN_description","__typename":"Revision","htmlHighlight":"<p>An <strong>existential risk<\/strong> (or <strong>x-risk<\/strong>) is a risk that poses astronomically large negative consequences for humanity, such as human extinction or permanent global totalitarianism.<\/p><p><a href=\"https://lessestwrong.com/tag/nick-bostrom\">Nick Bostrom<\/a> introduced the term \"existential risk\" in his 2002 paper \"<a href=\"https://www.nickbostrom.com/existential/risks.pdf\">Existential Risks: Analyzing Human Extinction Scenarios and Related Hazards<\/a>.\"<a href=\"https://lessestwrong.com/tag/existential-risk?revision=0.0.39#fn1\"><sup>1<\/sup><\/a> In the paper, Bostrom defined an existential risk as:<\/p><blockquote><p>One where an adverse outcome would either annihilate Earth-originating intelligent life or permanently and drastically curtail its potential.<\/p><\/blockquote><p>The Oxford <a href=\"https://www.lesswrong.com/tag/future-of-humanity-institute-fhi\">Future of Humanity Institute<\/a> (FHI) was founded by Bostrom in 2005 in part to study existential risks. Other institutions with a generalist focus on existential risk include the <a href=\"https://www.cser.ac.uk/\">Centre for the Study of Existential Risk<\/a>.<\/p><p>FHI's <a href=\"https://www.existential-risk.org/faq.html\">existential-risk.org FAQ<\/a> notes regarding the definition of \"existential risk\":<\/p><blockquote><p>An existential risk is one that threatens the entire future of humanity. [...]<\/p><p>Humanity, in this context, does not mean the biological species <i>Homo sapiens<\/i>. If we humans were to evolve into another species, or merge or replace ourselves with intelligent machines, this would not necessarily mean that an existential catastrophe had occurred  although it might if the quality of life enjoyed by those new life forms turns out to be far inferior to that enjoyed by humans.<\/p><\/blockquote><p>&nbsp;<\/p><h2>Classification of Existential Risks<\/h2><p>Bostrom<a href=\"https://lessestwrong.com/tag/existential-risk?revision=0.0.39#fn2\"><sup>2<\/sup><\/a> proposes a series of classifications for existential risks:<\/p><ul><li><strong>Bangs<\/strong> - Earthly intelligent life is extinguished relatively suddenly by any cause; the prototypical end of humanity. Examples of bangs include deliberate or accidental misuse of nanotechnology, nuclear holocaust, <a href=\"https://lessestwrong.com/tag/simulation-argument\">the end of our simulation<\/a>, or an <a href=\"https://wiki.lesswrong.com/wiki/unfriendly_AI\">unfriendly AI<\/a>.<\/li><li><strong>Crunches<\/strong> - The potential humanity had to enhance itself indefinitely is forever eliminated, although humanity continues. Possible crunches include an exhaustion of resources, social or governmental pressure ending technological development, and even future technological development proving an unsurpassable challenge before the creation of a <a href=\"https://lessestwrong.com/tag/superintelligence\">superintelligence<\/a>.<\/li><li><strong>Shrieks<\/strong> - Humanity enhances itself, but explores only a narrow portion of its desirable possibilities. As the <a href=\"https://lessestwrong.com/tag/complexity-of-value\">criteria for desirability haven't been defined yet<\/a>, this category is mainly undefined. However, a flawed <a href=\"https://wiki.lesswrong.com/wiki/friendly_AI\">friendly AI<\/a> incorrectly interpreting our values, a superhuman <a href=\"https://wiki.lesswrong.com/wiki/WBE\">upload<\/a> deciding its own values and imposing them on the rest of humanity, and an intolerant<\/li><\/ul>..."},"Tag:Rz5jb3cYHTSRmqNnN":{"_id":"Rz5jb3cYHTSRmqNnN","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:Rz5jb3cYHTSRmqNnN_description"},"userId":"r38pkCm7wF4M44MDQ","name":"Existential Risk","slug":"existential-risk","core":false,"postCount":203,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-07-01T19:17:56.948Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:hdQn7FqtLu2PHCYQF_biography":{"_id":"hdQn7FqtLu2PHCYQF_biography","__typename":"Revision","version":null,"updateType":null,"editedAt":"2023-02-10T16:22:42.279Z","userId":null,"html":"<p>German writer of science-fiction novels and children's books (pen name Karl Olsberg). I blog and create videos about AI risks in German at <a href=\"http://www.ki-risiken.de\">www.ki-risiken.de<\/a> and <a href=\"http://youtube.com/karlolsbergautor\">youtube.com/karlolsbergautor<\/a>.<\/p>\n","wordCount":null,"htmlHighlight":"<p>German writer of science-fiction novels and children's books (pen name Karl Olsberg). I blog and create videos about AI risks in German at <a href=\"http://www.ki-risiken.de\">www.ki-risiken.de<\/a> and <a href=\"http://youtube.com/karlolsbergautor\">youtube.com/karlolsbergautor<\/a>.<\/p>","plaintextDescription":"German writer of science-fiction novels and children's books (pen name Karl Olsberg). I blog and create videos about AI risks in German at www.ki-risiken.de and youtube.com/karlolsbergautor."},"Post:rSiybWzeiG8agYtNr":{"_id":"rSiybWzeiG8agYtNr","__typename":"Post","recentComments({\"af\":false,\"commentsLimit\":4,\"maxAgeHours\":18})":[{"__ref":"Comment:dYjaeCpirbjw7R7yu"}],"deletedDraft":false,"contents":{"__ref":"Revision:rSiybWzeiG8agYtNr_"},"fmCrosspost":{"isCrosspost":true,"hostedHere":true,"foreignPostId":"XLDfRTa6JbfCLXNTd"},"readTimeMinutes":2,"moderationGuidelines":{"__ref":"Revision:rSiybWzeiG8agYtNr_moderationGuidelines"},"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:sYm3HiWcfZvrGu3ui"},{"__ref":"Tag:etDohXtBrXd8WqCtR"},{"__ref":"Tag:Rz5jb3cYHTSRmqNnN"}],"url":null,"postedAt":"2023-01-12T09:37:21.528Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2023-01-12T22:40:23.448Z","meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"commentCount":10,"voteCount":23,"baseScore":31,"extendedScore":null,"unlisted":false,"score":0.016863780689041888,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2023-02-10T14:56:28.377Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"hdQn7FqtLu2PHCYQF","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"r38pkCm7wF4M44MDQ","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"afBaseScore":7,"afExtendedScore":null,"afCommentCount":null,"afLastCommentedAt":"2023-01-12T09:37:21.531Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"reviewCount":null,"reviewVoteCount":null,"positiveReviewVoteCount":null,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"user":{"__ref":"User:hdQn7FqtLu2PHCYQF"},"coauthors":[],"slug":"virtua-a-novel-about-ai-alignment","title":"VIRTUA: a novel about AI alignment","draft":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null},"Revision:BPRHZFH2xx7nz5TYT_":{"_id":"BPRHZFH2xx7nz5TYT_","__typename":"Revision","htmlHighlight":"<p>If its worth saying, but not worth its own post, here's a place to put it.<\/p><p>If you are new to LessWrong, here's the place to introduce yourself. Personal stories, anecdotes, or just general comments on how you found us and what you hope to get from the site and community are invited. This is also the place to discuss feature requests and other ideas you have for the site, if you don't want to write a full top-level post.<\/p><p>If you're new to the community, you can start reading the <a href=\"https://lesswrong.com/highlights\">Highlights from the Sequences<\/a>, a collection of posts about the core ideas of LessWrong.<\/p><p>If you want to explore the community more, I recommend <a href=\"https://www.lesswrong.com/library\">reading the Library<\/a>, <a href=\"https://www.lesswrong.com/?view=curated\">checking recent Curated posts<\/a>, <a href=\"https://www.lesswrong.com/community\">seeing if there are any meetups in your area<\/a>, and checking out the <a href=\"https://www.lesswrong.com/faq#Getting_Started\">Getting Started<\/a> section of the <a href=\"https://www.lesswrong.com/faq\">LessWrong FAQ<\/a>. If you want to orient to the content on the site, you can also check out the <a href=\"https://www.lesswrong.com/tags/all\">Concepts section<\/a>.<\/p><p>The Open Thread tag is <a href=\"https://www.lesswrong.com/tag/open-threads?sortedBy=new\">here<\/a>. The Open Thread sequence is <a href=\"https://www.lesswrong.com/s/yai5mppkuCHPQmzpN\">here<\/a>.<\/p>","wordCount":173,"version":"1.1.0"},"Revision:BPRHZFH2xx7nz5TYT_moderationGuidelines":{"_id":"BPRHZFH2xx7nz5TYT_moderationGuidelines","__typename":"Revision","html":""},"Revision:BPRHZFH2xx7nz5TYT_customHighlight":{"_id":"BPRHZFH2xx7nz5TYT_customHighlight","__typename":"Revision","html":""},"Revision:ABG8vt87eW4FFA6gD_description":{"_id":"ABG8vt87eW4FFA6gD_description","__typename":"Revision","htmlHighlight":"<p><strong>Open Threads<\/strong> are informal discussion areas, where users are welcome to post comments that didn't quite feel big enough to warrant a top-level post, nor fit in other posts.<\/p><p>Sometimes an Open Thread focuses on a specific topic. The most common Open Threads are the monthly Open and Welcome Threads, which serve as a general focal point of discussion, as well as a place for new users to introduce themselves.<\/p><p><i>Note: if a post is in the <\/i><a href=\"http://localhost:3000/tag/ai-questions-open-thread\"><i>AI Questions Open Thread<\/i><\/a><i> series, it should get that tag instead of this one.<\/i><\/p>"},"Tag:ABG8vt87eW4FFA6gD":{"_id":"ABG8vt87eW4FFA6gD","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:ABG8vt87eW4FFA6gD_description"},"userId":null,"name":"Open Threads","slug":"open-threads","core":false,"postCount":462,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":null,"needsReview":null,"descriptionTruncationCount":null,"createdAt":null,"wikiOnly":false,"deleted":false,"isSubforum":null},"Post:BPRHZFH2xx7nz5TYT":{"_id":"BPRHZFH2xx7nz5TYT","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:BPRHZFH2xx7nz5TYT_"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":1,"moderationGuidelines":{"__ref":"Revision:BPRHZFH2xx7nz5TYT_moderationGuidelines"},"customHighlight":{"__ref":"Revision:BPRHZFH2xx7nz5TYT_customHighlight"},"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:ABG8vt87eW4FFA6gD"}],"url":null,"postedAt":"2023-01-07T11:16:18.646Z","createdAt":null,"sticky":true,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"commentCount":33,"voteCount":5,"baseScore":13,"extendedScore":null,"unlisted":false,"score":0.00576990841705427,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2023-02-10T14:20:23.652Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"quAoHT9X7qMDBmA3z","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"r38pkCm7wF4M44MDQ","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"afBaseScore":2,"afExtendedScore":null,"afCommentCount":null,"afLastCommentedAt":"2023-01-07T11:16:18.648Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"reviewCount":null,"reviewVoteCount":null,"positiveReviewVoteCount":null,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"user":{"__ref":"User:quAoHT9X7qMDBmA3z"},"coauthors":[],"slug":"open-and-welcome-thread-january-2023","title":"Open & Welcome Thread - January 2023","draft":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null},"Revision:hfkjegoMZ8j8KGyiR_":{"_id":"hfkjegoMZ8j8KGyiR_","__typename":"Revision","htmlHighlight":"<p><i>We often prefer reading over listening to audio content, and have been testing transcribing podcasts using our new tool at Conjecture, <\/i><a href=\"https://app.verbalize.dev/\"><i>Verbalize<\/i><\/a><i>, with some light editing and formatting. We're posting highlights and transcripts of podcasts in case others share our preferences, and because there is a lot of important alignment-relevant information in podcasts that never made it to LessWrong.<\/i><br><br><i>If anyone is creating alignment-relevant audio content and wants to transcribe it, get in touch with us and we can give you free credits!<\/i><\/p><p><i>The podcast episode transcribed in this post is available <\/i><a href=\"https://www.youtube.com/watch?v=2RjuJzmafAA\"><i>here<\/i><\/a><i>.<\/i><\/p><h3>Topics covered include:<\/h3><ul><li>Defining artificial general intelligence<\/li><li>What makes humans more powerful than chimps?<\/li><li>Would AIs have to be social to be intelligent?<\/li><li>Importing humanity's memes into AIs<\/li><li>How do we measure progress in AI?<\/li><li>Gut feelings about AI progress<\/li><li>Connor's predictions about AGI<\/li><li>Is predicting AGI soon betting against the market?<\/li><li>How accurate are prediction markets about AGI?<\/li><\/ul><h3>Books cited in the episode include:<\/h3><ul><li><a href=\"https://www.penguinrandomhouse.com/series/INO/incerto\">The Incerto Series <\/a>by Nassim Nicholas Taleb<\/li><li><a href=\"https://en.wikipedia.org/wiki/The_Selfish_Gene\">The Selfish Gene, <\/a>Richard Dawkins<\/li><li><a href=\"https://en.wikipedia.org/wiki/Frans_de_Waal#Books\">Various books on primates and animal intelligence<\/a> by Frans De Wall<\/li><li><a href=\"https://equilibriabook.com/\">Inadequate Equilibria<\/a> by Eliezer Yudkowsky<\/li><\/ul><h1>Highlights<\/h1><p>On intelligence in humans and chimps:<\/p><blockquote><p>&nbsp;We are more social because we're more intelligent and we're more intelligent because we are more social. These things are not independent variables. So at first glance, if you look at a human brain versus a chimp brain, it's basically the same thing. You see like all the same kind of structures, same kind of neurons, kind of, sure, a bunch of parameters are different. You see some more spindle cells than not. You see some more whatever. Of course, it's bigger. Human brain is just significantly, it just has more parameters, it's just GPT-3 versus GPT-4...<\/p><p>But really, the difference is, is that humans have memes. And I mean, this in the, you know, in a Richard Dawkins sense of like, evolved, informational, like you know, programmatic virtual concepts that can be passed around between groups. If I had to pick one niche, what is the niche that humans are evolved for?&nbsp;<\/p><p>I think the niche we're evolved for is memetic hosts.<\/p><\/blockquote><p>On benchmarks and scaling laws:<\/p><blockquote><p>Benchmarks are actually coordination technologies. They're actually social technologies. Benchmarks, what benchmarks are fundamentally for is coordination mechanisms. The kind of mechanisms you n<\/p><\/blockquote>...","wordCount":12986,"version":"1.0.0"},"Revision:hfkjegoMZ8j8KGyiR_moderationGuidelines":{"_id":"hfkjegoMZ8j8KGyiR_moderationGuidelines","__typename":"Revision","html":""},"Revision:vxsbTxQGYTeNDAZXb_description":{"_id":"vxsbTxQGYTeNDAZXb_description","__typename":"Revision","htmlHighlight":"<p>Conjecture is an alignment startup founded by Connor Leahy, Sid Black and Gabriel Alfour, which aims to scale alignment research.<\/p>\n<p>The initial directions of their research agenda include:<\/p>\n<ul>\n<li>New frames for reasoning about large language models<\/li>\n<li>Scalable mechanistic interpretability<\/li>\n<li>History and philosophy of alignment<\/li>\n<\/ul>"},"Tag:vxsbTxQGYTeNDAZXb":{"_id":"vxsbTxQGYTeNDAZXb","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:vxsbTxQGYTeNDAZXb_description"},"userId":"qgdGA4ZEyW7zNdK84","name":"Conjecture (org)","slug":"conjecture-org","core":false,"postCount":40,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2022-04-18T15:57:33.360Z","wikiOnly":false,"deleted":false,"isSubforum":null},"User:fxnsvh4nSwJ3x3SRT":{"_id":"fxnsvh4nSwJ3x3SRT","__typename":"User","biography":null,"profileImageId":null,"moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":null,"slug":"remember","createdAt":"2022-05-10T15:38:38.529Z","username":"remember","displayName":"remember","previousDisplayName":null,"fullName":null,"karma":317,"afKarma":24,"deleted":null,"isAdmin":false,"htmlBio":"","postCount":6,"commentCount":1,"sequenceCount":null,"afPostCount":null,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":null},"User:NFAj9C8Rn3JEweFHN":{"_id":"NFAj9C8Rn3JEweFHN","__typename":"User","slug":"andream","createdAt":"2022-06-28T18:01:01.664Z","username":"AndreaM","displayName":"Andrea_Miotti","previousDisplayName":"AndreaM","fullName":null,"karma":134,"afKarma":null,"deleted":null,"isAdmin":false,"htmlBio":"","postCount":null,"commentCount":1,"sequenceCount":null,"afPostCount":null,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":1},"Post:hfkjegoMZ8j8KGyiR":{"_id":"hfkjegoMZ8j8KGyiR","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:hfkjegoMZ8j8KGyiR_"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":52,"moderationGuidelines":{"__ref":"Revision:hfkjegoMZ8j8KGyiR_moderationGuidelines"},"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:vxsbTxQGYTeNDAZXb"},{"__ref":"Tag:sYm3HiWcfZvrGu3ui"},{"__ref":"Tag:Ng8Gice9KNkncxqcj"},{"__ref":"Tag:3uE2pXvbcnS9nnZRE"}],"url":null,"postedAt":"2023-02-10T13:55:59.387Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":[{"userId":"NFAj9C8Rn3JEweFHN","confirmed":true,"requested":false}],"hasCoauthorPermission":true,"commentCount":null,"voteCount":6,"baseScore":22,"extendedScore":null,"unlisted":false,"score":3.0575704962497854,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2023-02-10T13:55:59.387Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"fxnsvh4nSwJ3x3SRT","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":null,"suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"afBaseScore":11,"afExtendedScore":null,"afCommentCount":null,"afLastCommentedAt":"2023-02-06T16:32:05.185Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"reviewCount":null,"reviewVoteCount":null,"positiveReviewVoteCount":null,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"user":{"__ref":"User:fxnsvh4nSwJ3x3SRT"},"coauthors":[{"__ref":"User:NFAj9C8Rn3JEweFHN"}],"slug":"fli-podcast-connor-leahy-on-ai-progress-chimps-memes-and","title":"FLI Podcast: Connor Leahy on AI Progress, Chimps, Memes, and Markets (Part 1/3)","draft":false,"hideCommentKarma":false,"af":true,"currentUserReviewVote":null},"Revision:woCPxs8GxE7H35zzK_":{"_id":"woCPxs8GxE7H35zzK_","__typename":"Revision","htmlHighlight":"<p>I think I've uncovered an error in Eliezer Yudkowsky's book <a href=\"https://equilibriabook.com/\">Inadequate Equilibria<\/a> that undermines a key point in the book. Here are some of my observations.&nbsp;<\/p><p>First, let me provide some context. In the <a href=\"https://equilibriabook.com/inadequacy-and-modesty/\">first chapter<\/a>, Yudkowsky states that prior to Shinzo Abe's tenure as Prime Minister of Japan, the Bank of Japan had implemented a bad monetary policy that cost Japan trillions of dollars in real economic growth.<\/p><p>His point was that he was able to spot this mistake, and confidently know better than the experts employed at the Bank of Japan, despite not being an expert in economic policy himself. In a dialogue, he wrote,<\/p><blockquote><p>CONVENTIONAL CYNICAL ECONOMIST: So, Eliezer, you think you know better than the Bank of Japan and many other central banks around the world, do you?<\/p><p>ELIEZER: &nbsp;Yep. Or rather, by reading econblogs, I believe myself to have identified which econbloggers know better, like Scott Sumner.<\/p><p>C.C.E.: Even though literally trillions of dollars of real value are at stake?<\/p><p>ELIEZER: &nbsp;Yep.<\/p><\/blockquote><p>To demonstrate that he was correct on this issue, Yudkowsky said the following,<\/p><blockquote><p>When we critique a government, we dont usually get to see what would actually happen if the government took our advice. But in this one case, less than a month after my exchange with John, the Bank of Japanunder the new leadership of Haruhiko Kuroda, and under unprecedented pressure from recently elected Prime Minister Shinzo Abe, who included monetary policy in his campaign platformembarked on an attempt to print huge amounts of money, with a stated goal of doubling the Japanese money supply.<a href=\"https://equilibriabook.com/inadequacy-and-modesty/#footnote-5-definition\"><sup>5<\/sup><\/a><\/p><\/blockquote><blockquote><p>Immediately after, Japan experienced real GDP growth of 2.3%, where the previous trend was for falling RGDP. Their economy was operating that far under capacity due to lack of money.<a href=\"https://equilibriabook.com/inadequacy-and-modesty/#footnote-6-definition\"><sup>6<\/sup><\/a><\/p><\/blockquote><p>However, that last part is not correct, as far as I can tell.<\/p><p>According to official <a href=\"https://fred.stlouisfed.org/series/JPNRGDPEXP\">government data<\/a>, Japan's RGDP had not been falling prior to 2013, other than the fall caused by the Great Recession. RGDP did grow by ~2.0% in 2013, but I cannot discern any significant change in the trend after Haruhiko Kuroda began serving as governor at the Bank of Japan.<\/p><figure class=\"image\"><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675820015/mirroredImages/woCPxs8GxE7H35zzK/rvnpw8fnqzt0yxdwocbr.png\" srcset=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675820015/mirroredImages/woCPxs8GxE7H35zzK/jww3hnhgafpc7m81y7zl.png 120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675820015/mirroredImages/woCPxs8GxE7H35zzK/yoxrirw36ku5rimbb3ys.png 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675820016/mirroredImages/woCPxs8GxE7H35zzK/soc2xsll6zvpkscmki2e.png 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675820015/mirroredImages/woCPxs8GxE7H35zzK/xl7vywbhvngcnuigl4f5.png 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675820015/mirroredImages/woCPxs8GxE7H35zzK/vkz8haovlkuegipfymuq.png 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675820015/mirroredImages/woCPxs8GxE7H35zzK/skhiww118vsoehvxwu23.png 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675820015/mirroredImages/woCPxs8GxE7H35zzK/e1cyqotzma5xkj68mzbn.png 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675820015/mirroredImages/woCPxs8GxE7H35zzK/hcrd3yp0pjqqbgogl4ay.png 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675820015/mirroredImages/woCPxs8GxE7H35zzK/bmws3bipojolwsla2i8e.png 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675820015/mirroredImages/woCPxs8GxE7H35zzK/lqhgghxajjso8hd1akk5.png 1169w\"><\/figure><figure class=\"image\"><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675820015/mirroredImages/woCPxs8GxE7H35zzK/mcwyjui3souen3wnllyq.png\" srcset=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675820015/mirroredImages/woCPxs8GxE7H35zzK/g66cagiraithpbmfdbjw.png 120w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675820015/mirroredImages/woCPxs8GxE7H35zzK/gv6dbg1zbozoqmrzglek.png 240w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675820015/mirroredImages/woCPxs8GxE7H35zzK/mb0w6b6r9da6mtc6dmq9.png 360w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675820015/mirroredImages/woCPxs8GxE7H35zzK/dozlfbbgljjgkbqxeckg.png 480w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675820015/mirroredImages/woCPxs8GxE7H35zzK/ajupurdmbwzvizh1nojr.png 600w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675820015/mirroredImages/woCPxs8GxE7H35zzK/i71g18sreeqcjnkrjrvz.png 720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675820015/mirroredImages/woCPxs8GxE7H35zzK/ynnlpg0jehukhqeqqd3j.png 840w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675820015/mirroredImages/woCPxs8GxE7H35zzK/f8wlvcnxjwysgvwr5m9w.png 960w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675820015/mirroredImages/woCPxs8GxE7H35zzK/nybp8frfa6kygfgwo000.png 1080w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675820015/mirroredImages/woCPxs8GxE7H35zzK/ikc3d9z9xeloa17y1uev.png 1169w\"><\/figure><p>In his footnote, Yudkowsky cites <a href=\"https://archive.is/ufnXt\">this article<\/a> from 2017 to provide a \"more recent update\" about Japan's successful monetary policy. However, I don't think the article demonstrates that Yudkowsky was correct in any major way about the point he made.<\/p><p>The article never pre... <\/p>","wordCount":713,"version":"1.15.1"},"Revision:woCPxs8GxE7H35zzK_moderationGuidelines":{"_id":"woCPxs8GxE7H35zzK_moderationGuidelines","__typename":"Revision","html":"<p>I encourage critiques, counterarguments, and corrections. I merely ask that you be polite and respectful.<\/p>\n"},"Revision:PDJ6KqJBRzvKPfuS3_description":{"_id":"PDJ6KqJBRzvKPfuS3_description","__typename":"Revision","htmlHighlight":"<p><strong>Economics<\/strong> is the social science that studies how humans and other agents interact in a universe with scarce resources. It deals with topics such as trade, specialization of labor, accumulation of capital, technology, and resource consumption. Agents in economics are generally assumed to have utility functions, which they try to maximize under various constraints.<\/p><p>Economics is usually separated into microeconomics and macroeconomics. Microeconomics concerns the behavior of agents as they interact in a market. More narrowly, it studies the price mechanism, a decentralized system of allocating goods and services based on an evolving system of prices and trade, which all actors in a market economy contribute towards. The price mechanism is closely related to the concept of the <a href=\"https://en.wikipedia.org/wiki/Invisible_hand\">invisible hand<\/a>, first introduced by <a href=\"https://en.wikipedia.org/wiki/Adam_Smith\">Adam Smith<\/a>. <a href=\"https://www.lesswrong.com/tag/game-theory\">Game theory<\/a> is the mathematical study of rational agency, which formalizes many standard results in microeconomics.<\/p><p>Macroeconomics concerns the aggregate behavior of entire economies. For example, it studies economic growth, inflation, international trade and unemployment. An ongoing debate concerns to what extent the <a href=\"https://www.lesswrong.com/tag/economic-consequences-of-agi\">impacts of artificial intelligence<\/a> should be viewed through the lens of economics.<\/p>"},"Tag:PDJ6KqJBRzvKPfuS3":{"_id":"PDJ6KqJBRzvKPfuS3","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:PDJ6KqJBRzvKPfuS3_description"},"userId":"r38pkCm7wF4M44MDQ","name":"Economics","slug":"economics","core":null,"postCount":274,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":null,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-14T22:24:48.135Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:qf3kDBak4BQDDw3f2_description":{"_id":"qf3kDBak4BQDDw3f2_description","__typename":"Revision","htmlHighlight":"<p><strong>Modest Epistemology<\/strong> is the claim that average opinions are more accurate than individual opinions, and individuals should take advantage of this by moving toward average opinions, even in cases where they have strong arguments for their own views and against more typical views. (Another name for this concept is \"the wisdom of crowds\" -- that name is much more popular outside of LessWrong.) In terms of <a href=\"https://www.lesswrong.com/tag/inside-outside-view\">inside view vs outside view<\/a>, we can describe modest epistemology as the belief that inside views are quite fallible and outside views much more robust; therefore, we should weigh outside-view considerations much more heavily.<\/p><p>In LessWrong parlance, \"modesty\" and \"humility\" should not be confused. While Eliezer lists \"humility\" as a virtue, he provides many arguments <i>against<\/i> modesty (most extensively, in the book <a href=\"https://www.lesswrong.com/s/oLGCcbnvabyibnG9d\"><i>Inadequate Equilibria<\/i><\/a>; but also in many earlier sources.) <a href=\"https://www.lesswrong.com/tag/humility-1\"><strong>Humility<\/strong><\/a> is the general idea that you should expect to be fallible. Modest Epistemology is specifically the view that, due to your own fallibility, you should <i>rely heavily on <\/i><a href=\"https://www.lesswrong.com/tag/inside-outside-view\"><i>outside-view<\/i><\/a><i>.<\/i> Modest epistemology says that you should trust average opinions more than your own opinion, even when you have strong arguments for your own views and against more typical views.<\/p><p>Historically, Robin Hanson has argued in favor of epistemic modesty and outside-view, while Eliezer has argued against epistemic modesty and for a strong inside views. For example, this disagreement played a role in <a href=\"https://www.lesswrong.com/tag/the-hanson-yudkowsky-ai-foom-debate\">The Foom Debate<\/a>. Eliezer and Hanson both agree that <a href=\"https://www.lesswrong.com/tag/aumann-s-agreement-theorem\">Aumann's Agreement Theorem<\/a> implies that rational agents should converge to agreement; however, they have very different opinions about whether/how this breaks down in the absence of perfect rationality. Eliezer sees little reason to move one's opinion toward that of an irrational person's. Hanson thinks irrational agents still benefit from moving their opinions toward each other. One of Hanson's arguments involves <a href=\"https://www.lesswrong.com/tag/hansonian-pre-rationality\">pre-priors<\/a>.<\/p><p><strong>External Posts:<\/strong><\/p><p><a href=\"http://www.overcomingbias.com/2008/09/immodest-caplan.html\">Immodest Caplan<\/a> by Robin Hanson<\/p><p><strong>Related Sequences:<\/strong> <a href=\"https://www.lesswrong.com/s/oLGCcbnvabyibnG9d\">Inadequate Equilibria<\/a><\/p><p><strong>Related Pages:<\/strong> <a href=\"https://www.lesswrong.com/tag/modesty\">modesty<\/a>, <a href=\"https://www.lesswrong.com/tag/humility-1\">Humility<\/a>, <a href=\"https://www.lesswrong.com/tag/inside-outside-view\">Inside/Outside View<\/a>, <a href=\"https://www.lesswrong.com/tag/egalitarianism\">Egalitarianism<\/a>, <a href=\"https://www.lesswrong.com/tag/modesty-argument\">Modesty argument<\/a>, <a href=\"https://www.lesswrong.com/tag/disagreement\">Disagreement<\/a><\/p>"},"Tag:qf3kDBak4BQDDw3f2":{"_id":"qf3kDBak4BQDDw3f2","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:qf3kDBak4BQDDw3f2_description"},"userId":"Q7NW4XaWQmfPfdcFj","name":"Modest Epistemology","slug":"modest-epistemology","core":false,"postCount":21,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2021-04-07T17:49:30.078Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:TWDkQT6f9mgyNXQ4p_biography":{"_id":"TWDkQT6f9mgyNXQ4p_biography","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2023-02-08T03:33:14.974Z","userId":"TWDkQT6f9mgyNXQ4p","html":"<p>Someone who is interested in learning and doing good.<\/p><p>My Twitter: <a href=\"https://twitter.com/MatthewJBar\">https://twitter.com/MatthewJBar<\/a><\/p><p>My Substack: <a href=\"https://matthewbarnett.substack.com/\">https://matthewbarnett.substack.com/<\/a><\/p>","wordCount":15,"htmlHighlight":"<p>Someone who is interested in learning and doing good.<\/p><p>My Twitter: <a href=\"https://twitter.com/MatthewJBar\">https://twitter.com/MatthewJBar<\/a><\/p><p>My Substack: <a href=\"https://matthewbarnett.substack.com/\">https://matthewbarnett.substack.com/<\/a><\/p>","plaintextDescription":"Someone who is interested in learning and doing good.\n\nMy Twitter: https://twitter.com/MatthewJBar\n\nMy Substack: https://matthewbarnett.substack.com/"},"User:TWDkQT6f9mgyNXQ4p":{"_id":"TWDkQT6f9mgyNXQ4p","__typename":"User","biography":{"__ref":"Revision:TWDkQT6f9mgyNXQ4p_biography"},"profileImageId":null,"moderationStyle":"norm-enforcing","bannedUserIds":null,"moderatorAssistance":true,"slug":"matthew-barnett","createdAt":"2018-01-23T08:41:14.281Z","username":"matthew-barnett","displayName":"Matthew Barnett","previousDisplayName":null,"fullName":"Matthew Barnett","karma":6360,"afKarma":601,"deleted":null,"isAdmin":false,"htmlBio":"<p>Someone who is interested in learning and doing good.<\/p><p>My Twitter: <a href=\"https://twitter.com/MatthewJBar\">https://twitter.com/MatthewJBar<\/a><\/p><p>My Substack: <a href=\"https://matthewbarnett.substack.com/\">https://matthewbarnett.substack.com/<\/a><\/p>","postCount":47,"commentCount":712,"sequenceCount":1,"afPostCount":11,"afCommentCount":132,"spamRiskScore":1,"tagRevisionCount":2},"Post:woCPxs8GxE7H35zzK":{"_id":"woCPxs8GxE7H35zzK","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:woCPxs8GxE7H35zzK_"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":3,"moderationGuidelines":{"__ref":"Revision:woCPxs8GxE7H35zzK_moderationGuidelines"},"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:3uE2pXvbcnS9nnZRE"},{"__ref":"Tag:PDJ6KqJBRzvKPfuS3"},{"__ref":"Tag:qf3kDBak4BQDDw3f2"}],"url":null,"postedAt":"2023-02-08T01:33:33.715Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2023-02-08T02:35:28.113Z","meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"commentCount":46,"voteCount":134,"baseScore":271,"extendedScore":null,"unlisted":false,"score":2.3187228237305155,"lastVisitedAt":"2023-02-10T12:23:35.017Z","isFuture":false,"isRead":true,"lastCommentedAt":"2023-02-10T13:25:16.594Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"TWDkQT6f9mgyNXQ4p","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"r38pkCm7wF4M44MDQ","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"afBaseScore":81,"afExtendedScore":null,"afCommentCount":null,"afLastCommentedAt":"2023-02-08T01:33:33.718Z","afSticky":false,"hideAuthor":false,"moderationStyle":"norm-enforcing","submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"reviewCount":null,"reviewVoteCount":null,"positiveReviewVoteCount":null,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"user":{"__ref":"User:TWDkQT6f9mgyNXQ4p"},"coauthors":[],"slug":"noting-an-error-in-inadequate-equilibria","title":"Noting an error in Inadequate Equilibria","draft":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null},"Revision:gjxKuoMyRWh6Mxvke_":{"_id":"gjxKuoMyRWh6Mxvke_","__typename":"Revision","htmlHighlight":"<p>I got rid of impostor syndrome after having it for nearly ten years, and I predict the results are replicable.&nbsp;<\/p><p>In this post Ill explain how to do it yourself and describe the upcoming class Im running where Ill see if I can replicate it with a small group.&nbsp;<\/p><p>The very summarized version of the method is<\/p><ol><li><strong>Do loving-kindness meditation practice directed towards yourself<\/strong> for an hour a day for a week straight.&nbsp;<\/li><li><strong>Do confidence practice<\/strong> (like loving-kindness, but for confidence. Explained below) for an hour a day for two weeks straight.<\/li><li><strong>(Optional) Do occasional maintenance practice to top up your confidence <\/strong>or bounce back from setbacks.&nbsp;<\/li><\/ol><p><a href=\"https://forms.gle/ofrL8tec2bk5Rxgy9\"><u>Apply to attend the class here<\/u><\/a>.<\/p><p>&nbsp;<\/p><h2>What I tried before<\/h2><p>I was a confident kid, then I did an internship at 80,000 Hours back in 2013. Living in Oxford gave me impostor syndrome almost instantly. Turns out that basing your confidence on being a big fish in a small pond only works if you stay in a small pond.&nbsp;<\/p><p>Between 2013 and 2022, I had more or less chronic low confidence and high anxiety around work. I tried everything to get rid of it: mindfulness, cognitive behavioral therapy, internal family systems, memory reconsolidation, exposure therapy, acceptance and commitment therapy, talk therapy, and just plain old reason. Nothing made a dent.&nbsp;<\/p><h2>&nbsp;<\/h2><h2>What it feels like to go from impostor syndrome to self-love<\/h2><p>When I had impostor syndrome, every time I made a mistake or performed less than perfectly, Id beat myself up mercilessly. Even when I succeeded by virtually anybodys standards, I would always have a reason for why it didnt really count, and couldnt everybody see all the ways Id messed up?<\/p><p>I was terrified of receiving feedback because then I would find out that secretly everybody hated me and thought I was useless, and they were just putting up with me because they had to. I felt I was always one step away from being kicked out of the community and being eaten by bears.&nbsp;<\/p><p>I've since experienced a 90% reduction in my work anxiety. After failures, I no longer feel debilitating self-recrimination; instead, I am inspired to think about what went wrong and improve.&nbsp;<\/p><p>In the past, when I looked at pictures of myself, the first thing that came to mind was how ugly I was. My initial reaction is now, \"Aw. I love that girl.\"&nbsp;<\/p><p>I can now look clearly at the things that Ive done and see the bad&nbsp;<i>and<\/i>... <\/p>","wordCount":5777,"version":"0.4.7"},"Revision:gjxKuoMyRWh6Mxvke_moderationGuidelines":{"_id":"gjxKuoMyRWh6Mxvke_moderationGuidelines","__typename":"Revision","html":""},"Revision:3ee9k6NJfcGzL6kMS_description":{"_id":"3ee9k6NJfcGzL6kMS_description","__typename":"Revision","htmlHighlight":"<p>Contrary to the stereotype, <a href=\"https://www.lesswrong.com/tag/rationality\">rationality<\/a> doesn't mean denying <strong>emotion<\/strong>. When emotion is appropriate to the reality of the situation, it should be embraced; only when emotion isn't appropriate should it be suppressed.<\/p><h2>External links<\/h2><ul><li><a href=\"http://www.youtube.com/watch?v=tLgNZ9aTEwc\">The Straw Vulcan<\/a>, a talk introducing rationality, by <a href=\"http://lesswrong.com/user/Julia_Galef/\">Julia Galef<\/a> (<a href=\"https://www.lesswrong.com/lw/90n/summary_of_the_straw_vulcan/\">summary<\/a>)<\/li><li><a href=\"http://www.overcomingbias.com/2006/12/vulcan_logic.html\">Vulcan Logic<\/a> by <a href=\"https://en.wikipedia.org/wiki/Hal_Finney_(cypherpunk)\">Hal Finney<\/a><\/li><\/ul><h2>See also<\/h2><ul><li><a href=\"https://www.lesswrong.com/tag/alief\">Alief<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/truth-semantics-and-meaning\">Truth<\/a>, <a href=\"https://www.lesswrong.com/tag/rationality\">Rationality<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/litany-of-tarski\">Litany of Tarski<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/hollywood-rationality\">Hollywood rationality<\/a><\/li><\/ul>"},"Tag:3ee9k6NJfcGzL6kMS":{"_id":"3ee9k6NJfcGzL6kMS","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:3ee9k6NJfcGzL6kMS_description"},"userId":"qgdGA4ZEyW7zNdK84","name":"Emotions","slug":"emotions","core":false,"postCount":135,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-07-07T21:10:58.722Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:Jzm2mYuuDBCNWq8hi_description":{"_id":"Jzm2mYuuDBCNWq8hi_description","__typename":"Revision","htmlHighlight":"<p>Posts about <strong>Happiness<\/strong>. One of the tricky things about Happiness is that sometimes directly pursuing it doesn't work or is even counterproductive. Happiness isn't (and can't be) <a href=\"https://www.lesswrong.com/posts/synsRtBKDeAFuo7e3/not-for-the-sake-of-happiness-alone\">the only important thing<\/a>, but it is nonetheless important. Thus LessWrong dealt a lot with questions about happiness and how to pursue it.<\/p><blockquote><p>Happiness is a choice. If youre so smart, how come you arent happy? How come you havent figured that out? Thats my challenge to all the people who think theyre so smart and so capable. - Naval Ravikant<\/p><\/blockquote><p>See also: <a href=\"https://www.lesswrong.com/tag/gratitude\">Gratitude<\/a>, <a href=\"https://www.lesswrong.com/tag/well-being\">Well-being<\/a><\/p>"},"Tag:Jzm2mYuuDBCNWq8hi":{"_id":"Jzm2mYuuDBCNWq8hi","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:Jzm2mYuuDBCNWq8hi_description"},"userId":"sKAL2jzfkYkDbQmx9","name":"Happiness","slug":"happiness-1","core":false,"postCount":46,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-08-03T06:53:24.953Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Tag:dLfyktLWd7BqtsZBf":{"_id":"dLfyktLWd7BqtsZBf","__typename":"Tag","parentTag":null,"subTags":[],"description":null,"userId":"L4j57Ah7zd637c6c8","name":"Memory Reconsolidation","slug":"memory-reconsolidation","core":false,"postCount":18,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-08-20T22:27:37.590Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:6v2FHy8dtyCYg9Kz4_description":{"_id":"6v2FHy8dtyCYg9Kz4_description","__typename":"Revision","htmlHighlight":"<p><strong>Therapy<\/strong> is treatment intended to reduce or remove a disorder. Depression, burn wounds, and many other afflictions can be treated with therapy and time. Psychotherapy aims to treat mental disorders, while physical therapy deals with injuries, physical illnesses, and other bodily damage.<\/p><p><strong>Related Pages: <\/strong><a href=\"https://www.lesswrong.com/tag/psychology\">Psychology<\/a>, <a href=\"https://www.lesswrong.com/tag/psychiatry\">Psychiatry<\/a>, <a href=\"https://www.lesswrong.com/tag/self-improvement\">Self Improvement<\/a>, <a href=\"https://www.lesswrong.com/tag/meditation\">Meditation<\/a>, <a href=\"https://www.lesswrong.com/tag/subagents\">subagents<\/a>, <a href=\"https://www.lesswrong.com/tag/center-for-applied-rationality-cfar\">Center for Applied Rationality (CFAR)<\/a><\/p>"},"Tag:6v2FHy8dtyCYg9Kz4":{"_id":"6v2FHy8dtyCYg9Kz4","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:6v2FHy8dtyCYg9Kz4_description"},"userId":"2gSkegMMWi3DPdmhQ","name":"Therapy","slug":"therapy","core":false,"postCount":29,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-10-10T20:14:01.270Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:PxuDgwGPiRxd3Www7_biography":{"_id":"PxuDgwGPiRxd3Www7_biography","__typename":"Revision","version":"1.3.0","updateType":"minor","editedAt":"2022-09-29T13:21:15.844Z","userId":"PxuDgwGPiRxd3Www7","html":"<p>Think it would be high-impact or fun to meet? Book a 20-minute slot here <a href=\"http://t.ly/vwOU\">t.ly/vwOU<\/a><\/p>","wordCount":15,"htmlHighlight":"<p>Think it would be high-impact or fun to meet? Book a 20-minute slot here <a href=\"http://t.ly/vwOU\">t.ly/vwOU<\/a><\/p>","plaintextDescription":"Think it would be high-impact or fun to meet? Book a 20-minute slot here t.ly/vwOU"},"User:PxuDgwGPiRxd3Www7":{"_id":"PxuDgwGPiRxd3Www7","__typename":"User","biography":{"__ref":"Revision:PxuDgwGPiRxd3Www7_biography"},"profileImageId":null,"moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":null,"slug":"ea247","createdAt":"2012-09-21T14:21:02.831Z","username":"ea247","displayName":"KatWoods","previousDisplayName":null,"fullName":null,"karma":886,"afKarma":2,"deleted":false,"isAdmin":false,"htmlBio":"<p>Think it would be high-impact or fun to meet? Book a 20-minute slot here <a href=\"http://t.ly/vwOU\">t.ly/vwOU<\/a><\/p>","postCount":14,"commentCount":35,"sequenceCount":null,"afPostCount":null,"afCommentCount":null,"spamRiskScore":1,"tagRevisionCount":1},"Post:gjxKuoMyRWh6Mxvke":{"_id":"gjxKuoMyRWh6Mxvke","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:gjxKuoMyRWh6Mxvke_"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":23,"moderationGuidelines":{"__ref":"Revision:gjxKuoMyRWh6Mxvke_moderationGuidelines"},"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:3ee9k6NJfcGzL6kMS"},{"__ref":"Tag:WqLn4pAWi5hn6McHQ"},{"__ref":"Tag:Jzm2mYuuDBCNWq8hi"},{"__ref":"Tag:fkABsGCJZ6y9qConW"},{"__ref":"Tag:dLfyktLWd7BqtsZBf"},{"__ref":"Tag:6v2FHy8dtyCYg9Kz4"}],"url":null,"postedAt":"2023-02-09T21:04:52.843Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2023-02-09T22:40:00.593Z","meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"commentCount":null,"voteCount":12,"baseScore":8,"extendedScore":null,"unlisted":false,"score":1.7213211908103903,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2023-02-09T21:04:52.843Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"PxuDgwGPiRxd3Www7","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"qgdGA4ZEyW7zNdK84","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"afBaseScore":1,"afExtendedScore":null,"afCommentCount":null,"afLastCommentedAt":"2023-01-01T20:25:03.870Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"reviewCount":null,"reviewVoteCount":null,"positiveReviewVoteCount":null,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"user":{"__ref":"User:PxuDgwGPiRxd3Www7"},"coauthors":[],"slug":"impostor-syndrome-how-to-cure-it-with-spreadsheets-and","title":"Impostor syndrome: how to cure it with spreadsheets and meditation ","draft":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null},"Revision:Qrg5tRBZvdABEJfDP_":{"_id":"Qrg5tRBZvdABEJfDP_","__typename":"Revision","htmlHighlight":"<p><span>\n\nIf I'm interviewing someone for a position my job is to assess their\nsuitability as a potential employee, but if they're my cousin I might\nbe tempted to give them an overly favorable review.  Most\norganizations have Conflict of Interest (CoI) policies that describe\nhow to handle this sort of situation: it's common that someone might\nhave external relationships which lead to duties, interests, or\ndesires that conflict with what's best for their organization.\n\n<\/span>\n\n<\/p><p>\n\nIt's reasonably common for non-profits to publish their CoI policies (<a href=\"https://www.hewlett.org/wp-content/uploads/2020/05/Conflict-of-Interest-Policy.pdf\">Hewlett<\/a>,\n<a href=\"https://media.carnegie.org/filer_public/8c/20/8c2083c5-e5ad-49cd-8a89-3466d14974d5/2022coisigned.pdf\">Carnegie<\/a>, <a href=\"https://docs.gatesfoundation.org/Documents/conflict_of_interest_policy.pdf\">Gates<\/a>).  Within effective altruism I do see some of this:\n\n<\/p><p>\n\n<\/p>\n\n<ul>\n\n<li><p>Animal Charity Evaluators has a <a href=\"https://animalcharityevaluators.org/transparency/policies/\">great\npage<\/a> on their policies, which includes their full CoI policies.\n\n<\/p><\/li>\n<li><p>Open Philanthropy shares their <a href=\"https://www.openphilanthropy.org/relationship-disclosure-policy/\">Relationship\nDisclosure Policy<\/a>, though I (and <a href=\"https://forum.effectivealtruism.org/posts/EooyY6XeebdtSaXz5/does-open-philanthropy-have-a-public-document-regarding\">others<\/a>)\ndon't see their full policy.\n\n<\/p><\/li>\n<li><p>GiveWell has a public <a href=\"https://files.givewell.org/files/ClearFund/Conflict_of_Interest_Policy_for_Board_Members_Offices_and_Key_Persons.pdf\">Conflict\nof Interest Policy for Board Members, Officers, and Key Persons<\/a>,\nthough probably also has an internal one for regular employees that\nseems not to be public?  They maintain a <a href=\"https://www.givewell.org/about/official-records/relationship-disclosures\">Relationship\nDisclosures<\/a> page, which I think is great.\n\n<\/p><\/li>\n<\/ul>\n\n\n\n<p>\n\nHistorically <a href=\"https://forum.effectivealtruism.org/posts/ESQS57Jn7kLsi5dc2/eas-write-about-where-they-give\">people<\/a>\nand <a href=\"https://www.givewell.org/how-we-work/transparency\">organizations<\/a>\nwithin the EA movement have prioritized transparency, and while\nthere's been <a href=\"https://www.openphilanthropy.org/research/update-on-how-were-thinking-about-openness-and-information-sharing/\">some\nshift away<\/a> from the most enthusiastic versions of this as we've <a href=\"https://blog.givewell.org/2014/09/11/challenges-of-transparency/\">better\nunderstood the costs<\/a>, there are still a lot of benefits.  If\nyou're already going to the effort of drafting a policy like this,\nmaking it public seems pretty useful:\n\n<\/p><p>\n\n<\/p>\n\n<ul>\n\n<li><p>EAs who are concerned about CoIs within the community and are\nthinking about what norms they might try to influence can see what's\nalready formally in place.\n\n<\/p><\/li>\n<li><p>Other organizations can reference it in trying to figure out\nwhat sort of policy they want.\n\n<\/p><\/li>\n<li><p>People who are worried a situation can see what policy was\n(supposed to have been) followed.\n\n<\/p><\/li>\n<\/ul>\n\n\n\n<p>\n\nOn the other hand, many EA organizations don't seem to have public\npolicies.  This includes ones that work in community building or\ngrant-making where they seem pretty important.  Here are a few I\nchecked:\n\n<\/p><p>\n\n<\/p>\n\n<ul>\n\n<li><p>The Centre for Effective Altruism <a href=\"https://www.centreforeffectivealtruism.org/our-mistakes\">mentions<\/a>\nthat they have a  \"written conflict of interest policy\", but it\ndoesn't seem to be public.\n\n<\/p><\/li>\n<li><p>The Effective Ventures Foundation doesn't list anything on\ntheir site, but says in their <a href=\"https://assets.ctfassets.net/es8pp29e1wp8/719m3SIVrQSzDcUxrzo7dS/af10eed02339549672126b0e87f2776d/Final_-_2021_Form_990_signed_-_CEA.pdf\">2021\nIRS filings<\/a> that \"when a conflict of interest arises a plan for\nregularly checking in with the involved parties is done monthly<\/p><\/li><\/ul>...","wordCount":628,"version":"1.4.0"},"Revision:Qrg5tRBZvdABEJfDP_moderationGuidelines":{"_id":"Qrg5tRBZvdABEJfDP_moderationGuidelines","__typename":"Revision","html":""},"Post:Qrg5tRBZvdABEJfDP":{"_id":"Qrg5tRBZvdABEJfDP","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:Qrg5tRBZvdABEJfDP_"},"fmCrosspost":{"isCrosspost":true,"hostedHere":true,"foreignPostId":"a9vfDqofuZwbzpKvw"},"readTimeMinutes":3,"moderationGuidelines":{"__ref":"Revision:Qrg5tRBZvdABEJfDP_moderationGuidelines"},"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:izp6eeJJEg9v5zcur"},{"__ref":"Tag:xexCWMyds6QLWognu"}],"url":null,"postedAt":"2023-02-09T19:30:01.282Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":null,"meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"commentCount":4,"voteCount":10,"baseScore":32,"extendedScore":null,"unlisted":false,"score":1.5579174338832962,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2023-02-10T02:28:58.929Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"TtEoCrFeowCGb6rFK","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"r38pkCm7wF4M44MDQ","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":7,"afExtendedScore":null,"afCommentCount":null,"afLastCommentedAt":"2023-02-09T19:30:01.285Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"reviewCount":null,"reviewVoteCount":null,"positiveReviewVoteCount":null,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"user":{"__ref":"User:TtEoCrFeowCGb6rFK"},"coauthors":[],"slug":"make-conflict-of-interest-policies-public","title":"Make Conflict of Interest Policies Public","draft":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null},"Revision:CYN7swrefEss4e3Qe_":{"_id":"CYN7swrefEss4e3Qe_","__typename":"Revision","htmlHighlight":"<p>Lets start with one of those insights that are as obvious as they are easy to forget: if you want to master something, you should study the highest achievements of your field. If you want to learn writing, read great writers, etc.<\/p><p>But this is not what parents usually do when they think about how to educate their kids. The default for a parent is rather to imitate their peers and outsource the big decisions to bureaucracies. But what would we learn if we studied the highest achievements?&nbsp;<\/p><p>Thinking about this question, I wrote down a list of twenty namesvon Neumann, Tolstoy, Curie, Pascal, etcselected on the highly scientific criteria a random Swedish person can recall their name and think,&nbsp;<i>Sounds like a genius to me<\/i>. That list is to me a good first approximation of what an exceptional result in the field of child-rearing looks like. I ordered a few piles of biographies, read, and took notes. Trying to be a little less biased in my sample, I asked myself if I could recall anyone exceptional that did not fit the patterns I saw in the biographies, which I could, and so I ordered a few more biographies.<\/p><p>This kept going for an unhealthy amount of time.<\/p><p>I sampled writers (Virginia Woolf, Lev Tolstoy), mathematicians (John von Neumann, Blaise Pascal, Alan Turing), philosophers (Bertrand Russell, Ren Descartes), and composers (Mozart, Bach), trying to get a diverse sample.&nbsp;<\/p><p>In this essay, I am going to detail a few of the patterns that have struck me after having skimmed 42 biographies. I will sort the claims so that I start with more universal patterns and end with patterns that are less common.<\/p><h2><strong>Exceptional people grow up in exceptional milieus<\/strong><\/h2><p><i>This seems to be true for &gt;95 percent of the people I looked at.<\/i><\/p><p>These naked apes, the humans, are intensely social animals. They obsessively internalize values, ideas, skills, and desires from the people who surround them. It is therefore not surprising that those who grow up to be exceptional tend to have spent their formative years surrounded by adults who were exceptional.<\/p><p>Virginia Woolf never attended school. Her father, Leslie Stephen, who, along with their tutors, educated Virginia and her sister, was an editor, critic, and biographer complicatedly hated by his daughter and of such standing that he could invite<a href=\"https://en.wikipedia.org/wiki/Henry_James\">&nbsp;<u>Henry James<\/u><\/a>,<a href=\"https://en.wikipedia.org/wiki/Thomas_Hardy\"><u> Thomas Hardy<\/u><\/a>, and<a href=\"https://en.wikipedia.org/wiki/Alfred_Lord_Tennyson\"><u> Alfred Lord Tennyson<\/u><\/a> to dine and converse with his child... <\/p>","wordCount":4598,"version":"1.0.0"},"Revision:CYN7swrefEss4e3Qe_moderationGuidelines":{"_id":"CYN7swrefEss4e3Qe_moderationGuidelines","__typename":"Revision","html":""},"Revision:CYN7swrefEss4e3Qe_customHighlight":{"_id":"CYN7swrefEss4e3Qe_customHighlight","__typename":"Revision","html":""},"Revision:Q55STnFh6gbSezRuR_description":{"_id":"Q55STnFh6gbSezRuR_description","__typename":"Revision","htmlHighlight":"<p><strong>Parenting<\/strong>, i.e. how to raise children well.<\/p><p><strong>Related pages: <\/strong><a href=\"https://www.lesswrong.com/tag/education\">Education<\/a>, <a href=\"https://www.lesswrong.com/tag/developmental-psychology\">Developmental Psychology<\/a>, <a href=\"https://www.lesswrong.com/tag/santa-claus\">Santa Claus<\/a>, <a href=\"https://www.lesswrong.com/tag/family-planning\">family planning<\/a><\/p><p><strong>External links: <\/strong><a href=\"https://en.wikipedia.org/wiki/Baby_sign_language\">Baby sign language<\/a><\/p>"},"Tag:Q55STnFh6gbSezRuR":{"_id":"Q55STnFh6gbSezRuR","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:Q55STnFh6gbSezRuR_description"},"userId":"qxJ28GN72aiJu96iF","name":"Parenting","slug":"parenting","core":false,"postCount":129,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-05T00:05:56.237Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Tag:fH8jPjHF2R27sRTTG":{"_id":"fH8jPjHF2R27sRTTG","__typename":"Tag","parentTag":null,"subTags":[],"description":null,"userId":"qxJ28GN72aiJu96iF","name":"Education","slug":"education","core":false,"postCount":170,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-12T11:04:34.644Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Post:CYN7swrefEss4e3Qe":{"_id":"CYN7swrefEss4e3Qe","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:CYN7swrefEss4e3Qe_"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":18,"moderationGuidelines":{"__ref":"Revision:CYN7swrefEss4e3Qe_moderationGuidelines"},"customHighlight":{"__ref":"Revision:CYN7swrefEss4e3Qe_customHighlight"},"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:Q55STnFh6gbSezRuR"},{"__ref":"Tag:fH8jPjHF2R27sRTTG"},{"__ref":"Tag:xexCWMyds6QLWognu"},{"__ref":"Tag:3uE2pXvbcnS9nnZRE"}],"url":"https://escapingflatland.substack.com/p/childhoods","postedAt":"2023-02-06T17:27:09.596Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2023-02-06T18:36:20.786Z","meta":false,"shareWithUsers":["3oopbgcjYfvN8B2fp"],"sharingSettings":{"anyoneWithLinkCan":"none","explicitlySharedUsersCan":"comment"},"coauthorStatuses":null,"hasCoauthorPermission":true,"commentCount":23,"voteCount":86,"baseScore":163,"extendedScore":null,"unlisted":false,"score":1.028633188107963,"lastVisitedAt":"2023-02-09T19:49:18.957Z","isFuture":false,"isRead":true,"lastCommentedAt":"2023-02-09T14:10:11.027Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"mpsskhizpeqNqZgkZ","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"qgdGA4ZEyW7zNdK84","suggestForCuratedUserIds":["r38pkCm7wF4M44MDQ"],"suggestForCuratedUsernames":"Raemon","reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"afBaseScore":29,"afExtendedScore":null,"afCommentCount":null,"afLastCommentedAt":"2023-01-31T08:28:07.910Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"reviewCount":null,"reviewVoteCount":null,"positiveReviewVoteCount":null,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"user":{"__ref":"User:mpsskhizpeqNqZgkZ"},"coauthors":[],"slug":"childhoods-of-exceptional-people","title":"Childhoods of exceptional people","draft":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null},"Revision:gp9pmgSX3BXnhv8pJ_":{"_id":"gp9pmgSX3BXnhv8pJ_","__typename":"Revision","htmlHighlight":"<p><i><strong>Warning: this is not in typical LessWrong \"style\", but nevertheless I think it is of interest to people here.<\/strong><\/i><\/p><p>Most people approach productivity from the bottom up. They notice something about a process that feels inefficient, so they set out to fix that specific problem. They use a website blocker and a habit tracker, but none of these tools address the root problem. Personally, I even went as far as making my own tools, but they yielded only marginally more productive time. I craved more, and I was willing to go as far as it takes. I wanted to solve productivity top downwith a system that would enforce non stop productivity with zero effort on my part.<\/p><p>I had tried less intense watch you work solutions before. Sharing a screen with someone through <a href=\"https://focusmate.com/\"><u>FocusMate<\/u><\/a> coworking was great, but I had problems scheduling and keeping consistent sessions because of my chaotic calendar. <a href=\"https://www.studytogether.com/\"><u>StudyTogether<\/u><\/a>s leaderboard was a great way to push myself to spend hours in the server, but I found myself eating dinner or napping instead of being productive with nobody the wiser.&nbsp;<\/p><p>I decided it was time to try the nuclear option: having people physically sit behind me to keep me on task. And if I was going to do that I was going to do it right: theyd be there 16 hours a day and only leave for me to sleep. (I have an endlessly growing list of projects I want to make, books I want to read, and skills I want to learn, so productivity means a lot to me!)<\/p><p>It fit my chaotic schedule well, because if I had a call or appointment I would step out, and then go right back to work when I would get back. There was also no way to game the system because they could see everything I was doing.<\/p><h1>Hiring<\/h1><p>I made the following Craigslist post and eagerly refreshed my inbox:<\/p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fceec713e-371f-4dd7-b697-9fa67b02ee89_1290x694.png\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fceec713e-371f-4dd7-b697-9fa67b02ee89_1290x694.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fceec713e-371f-4dd7-b697-9fa67b02ee89_1290x694.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fceec713e-371f-4dd7-b697-9fa67b02ee89_1290x694.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fceec713e-371f-4dd7-b697-9fa67b02ee89_1290x694.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fceec713e-371f-4dd7-b697-9fa67b02ee89_1290x694.png 1456w\"><\/a><\/p><p>At first, I interviewed applicants about their data entry and cooking skills, but realized it was far more important to get a feel for how comfortable we were working around each other. I moved all but one of the interview candidates who actually showed up (which was only !) to the trial stage and, in the end, chose three people, with two others as backups.&nbsp;<\/p><p>This is what the shift schedule looked like (not their real names):<\/p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6491d92d-7131-4d80-979b-3b9102485b11_1258x135.png\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6491d92d-7131-4d80-979b-3b9102485b11_1258x135.png\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6491d92d-7131-4d80-979b-3b9102485b11_1258x135.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6491d92d-7131-4d80-979b-3b9102485b11_1258x135.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6491d92d-7131-4d80-979b-3b9102485b11_1258x135.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6491d92d-7131-4d80-979b-3b9102485b11_1258x135.png 1456w\"><\/a><\/p><p>(I didnt mean to only hire women; it just turned out that way. One guy actually canceled at the last minute. For reference, ~70% of my applicants were women.)<\/p><h1>The Setup<\/h1><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faaa8d75c-1312-423c-b0b8-f51296d46984_1600x1600.jpeg\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faaa8d75c-1312-423c-b0b8-f51296d46984_1600x1600.jpeg\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faaa8d75c-1312-423c-b0b8-f51296d46984_1600x1600.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faaa8d75c-1312-423c-b0b8-f51296d46984_1600x1600.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faaa8d75c-1312-423c-b0b8-f51296d46984_1600x1600.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faaa8d75c-1312-423c-b0b8-f51296d46984_1600x1600.jpeg 1456w\"><\/a><\/p><p>&nbsp;<\/p><p><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F239c8eab-ed64-465e-8752-c29f369e239e_768x1024.jpeg\"><img src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F239c8eab-ed64-465e-8752-c29f369e239e_768x1024.jpeg\" alt=\"\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F239c8eab-ed64-465e-8752-c29f369e239e_768x1024.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F239c8eab-ed64-465e-8752-c29f369e239e_768x1024.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F239c8eab-ed64-465e-8752-c29f369e239e_768x1024.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F239c8eab-ed64-465e-8752-c29f369e239e_768x1024.jpeg 1456w\"><\/a><\/p><h1>The Experience<\/h1><p>Sunday night, before the ... <\/p>","wordCount":2987,"version":"1.0.0"},"Revision:TWfbN7GbhfNTnwunF_biography":{"_id":"TWfbN7GbhfNTnwunF_biography","__typename":"Revision","version":"1.1.0","updateType":"minor","editedAt":"2022-09-11T17:56:52.310Z","userId":"TWfbN7GbhfNTnwunF","html":"","wordCount":1,"htmlHighlight":"","plaintextDescription":null},"User:TWfbN7GbhfNTnwunF":{"_id":"TWfbN7GbhfNTnwunF","__typename":"User","biography":{"__ref":"Revision:TWfbN7GbhfNTnwunF_biography"},"profileImageId":null,"moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":null,"slug":"simon-berens","createdAt":"2020-04-02T16:18:59.291Z","username":"sberens","displayName":"Simon Berens","previousDisplayName":"sberens","fullName":null,"karma":281,"afKarma":0,"deleted":null,"isAdmin":false,"htmlBio":"","postCount":5,"commentCount":13,"sequenceCount":null,"afPostCount":null,"afCommentCount":0,"spamRiskScore":1,"tagRevisionCount":0},"Post:gp9pmgSX3BXnhv8pJ":{"_id":"gp9pmgSX3BXnhv8pJ","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:gp9pmgSX3BXnhv8pJ_"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":12,"moderationGuidelines":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:WqLn4pAWi5hn6McHQ"},{"__ref":"Tag:fkABsGCJZ6y9qConW"},{"__ref":"Tag:udPbn9RthmgTtHMiG"}],"url":"https://simonberens.me/blog/i-hired-5-people","postedAt":"2023-02-05T01:19:39.182Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2023-02-05T08:15:46.994Z","meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":true,"commentCount":54,"voteCount":87,"baseScore":174,"extendedScore":null,"unlisted":false,"score":0.8685314984493779,"lastVisitedAt":"2023-02-05T08:30:09.464Z","isFuture":false,"isRead":true,"lastCommentedAt":"2023-02-09T15:20:05.511Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"TWfbN7GbhfNTnwunF","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"r38pkCm7wF4M44MDQ","suggestForCuratedUserIds":["EQNTWXLKMeWMp2FQS"],"suggestForCuratedUsernames":"Ben Pace","reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"afBaseScore":43,"afExtendedScore":null,"afCommentCount":0,"afLastCommentedAt":"2023-02-05T01:19:39.182Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"reviewCount":null,"reviewVoteCount":null,"positiveReviewVoteCount":null,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"user":{"__ref":"User:TWfbN7GbhfNTnwunF"},"coauthors":[],"slug":"i-hired-5-people-to-sit-behind-me-and-make-me-productive-for","title":"I hired 5 people to sit behind me and make me productive for a month","draft":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null},"Revision:YKfNZAmiLdepDngwi_":{"_id":"YKfNZAmiLdepDngwi_","__typename":"Revision","htmlHighlight":"<p><strong>Epistemic status<\/strong>: whimsical<\/p><h1>Bees: a new unit of measurement for ML model size<\/h1><p>Talking about modern ML models inevitably leads to a bunch of <a href=\"https://xkcd.com/2091/\">hard-to-intuit<\/a> large numbers, especially when it comes to parameter count.<\/p><p>To address this, we propose that we adopt a new, human-friendly unit to measure the number of learnable parameters in an architecture:<\/p><p><strong>1 beepower = 1 BP = 1 billion parameters<\/strong><\/p><p>Bees have about one billion<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefudplyua1b59\"><sup><a href=\"#fnudplyua1b59\">[1]<\/a><\/sup><\/span>&nbsp;synapses<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnref8lxivrtntr3\"><sup><a href=\"#fn8lxivrtntr3\">[2]<\/a><\/sup><\/span>&nbsp;in their forebrain<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefkc0qq2ftq1f\"><sup><a href=\"#fnkc0qq2ftq1f\">[3]<\/a><\/sup><\/span>, so this gives a nice basis for comparisons<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefig8csrczcqm\"><sup><a href=\"#fnig8csrczcqm\">[4]<\/a><\/sup><\/span>&nbsp;between animal brains and artificial neural nets.<\/p><p>Like horsepower and candlepower,<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefc2xrbihy709\"><sup><a href=\"#fnc2xrbihy709\">[5]<\/a><\/sup><\/span>&nbsp;the unit of beepower expresses the scale of a new and unfamiliar technology in terms that we are already familiar with. And it makes discussion of model specs flow better.<\/p><p>\"This model has twenty bees\", you might say. Or \"wow, look at all that beepower; did you train long enough to make good use of it?\"<\/p><p>Here's a helpful infographic to calibrate you on this new unit of measurement:<\/p><figure class=\"image\"><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675872061/mirroredImages/YKfNZAmiLdepDngwi/buy2ktvnex22qyj48t9y.png\" srcset=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675872063/mirroredImages/YKfNZAmiLdepDngwi/utwebbrfv4wsd23yrmg1.png 430w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675872061/mirroredImages/YKfNZAmiLdepDngwi/d2c8mqjicxb9cbvkdmmh.png 860w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675872061/mirroredImages/YKfNZAmiLdepDngwi/dbh5noy9myye3n98lxik.png 1290w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675872065/mirroredImages/YKfNZAmiLdepDngwi/gddaajathtsbjxfmawpo.png 1720w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675872064/mirroredImages/YKfNZAmiLdepDngwi/leg8iwkgzeqmug4d2asp.png 2150w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675872061/mirroredImages/YKfNZAmiLdepDngwi/gf6ujewtclhhkegomntw.png 2580w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675872064/mirroredImages/YKfNZAmiLdepDngwi/pn4dx3mew8cfkpvcfhyl.png 3010w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675872066/mirroredImages/YKfNZAmiLdepDngwi/qylpcfmmkutwmprzwqcv.png 3440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675872065/mirroredImages/YKfNZAmiLdepDngwi/k20cx8ebxzkrtrgzixjv.png 3870w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675872062/mirroredImages/YKfNZAmiLdepDngwi/v5gnmevgs6kbqocboxky.png 4201w\"><figcaption>The parameter count of various recent language models, denoted in beepower.<\/figcaption><\/figure><h1>Other animals<\/h1><p>We can even benchmark<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefs35r6gi87o\"><sup><a href=\"#fns35r6gi87o\">[6]<\/a><\/sup><\/span>&nbsp;against more or less brainy animals.<\/p><p>The smallest OpenAI API model, Ada, is probably<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefnd640n85ff\"><sup><a href=\"#fnnd640n85ff\">[7]<\/a><\/sup><\/span>&nbsp;350 million parameters, or about a third of a bee, which is comparable to a cricket:<\/p><figure class=\"image\"><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675848024/mirroredImages/YKfNZAmiLdepDngwi/v2vlbbgbhbsfjufkf8lm.jpg\" alt=\"Blog - Why Are There Crickets That Keep Getting Into My Chicago Home?\"><figcaption>While Jiminy Cricket can compose better English than Ada, this cricket cannot.<\/figcaption><\/figure><p>The next size up, Babbage, is around 1.3 BP, or cockroach-sized.<\/p><p>Curie has almost seven bees, which is... sort of in an awkward gap between insects and mammals.<\/p><p>Davinci is a 175-bee model, which gets us up to hedgehog (or quail) scale:<\/p><figure class=\"image\"><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675848024/mirroredImages/YKfNZAmiLdepDngwi/r3zopyxnknybkjsqhcl8.jpg\" alt=\"16 Fun Facts About Hedgehogs | Mental Floss\"><figcaption>As a large language model trained by OpenAI, I don't have the ability to \"be the cutest little guy oh my gosh\"<\/figcaption><\/figure><p>Gopher (280 BP) is partridge (or ferret) sized. More research into actual gophers is needed to know how many gophers worth of parameters Gopher has.&nbsp;<\/p><figure class=\"image\"><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675848024/mirroredImages/YKfNZAmiLdepDngwi/clx7a7nwt6yhci18dmbt.jpg\" alt=\"Grey partridge - Wikipedia\"><figcaption>Really, they should've named Gopher \"Partridge\" or \"Ferret\"!<\/figcaption><\/figure><p>Amusingly, PaLM, at 540 bees, has about as many parameters as a chinchilla has synapses:<span class=\"footnote-reference\" role=\"doc-noteref\" id=\"fnrefdv5f56rhzp\"><sup><a href=\"#fndv5f56rhzp\">[8]<\/a><\/sup><\/span><\/p><figure class=\"image\"><img src=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675848024/mirroredImages/YKfNZAmiLdepDngwi/v0ltk16grvnhmdafemxc.jpg\" srcset=\"https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675848024/mirroredImages/YKfNZAmiLdepDngwi/hflenchem64zk8inobak.jpg 110w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675848024/mirroredImages/YKfNZAmiLdepDngwi/pq1k80hhhlmsr7xx1vsj.jpg 220w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675848024/mirroredImages/YKfNZAmiLdepDngwi/mmzoib2gvekpw9ejrrcm.jpg 330w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675848024/mirroredImages/YKfNZAmiLdepDngwi/lzwt4jmqrovshwjka693.jpg 440w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675848024/mirroredImages/YKfNZAmiLdepDngwi/czec6ej878tgew5vm2lp.jpg 550w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675848024/mirroredImages/YKfNZAmiLdepDngwi/u54pe2v06rzmylztjvpq.jpg 660w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675848024/mirroredImages/YKfNZAmiLdepDngwi/wzg78vk8te8qqf8crbkl.jpg 770w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675848024/mirroredImages/YKfNZAmiLdepDngwi/zguhrcafvpdtapw1z8p5.jpg 880w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675848024/mirroredImages/YKfNZAmiLdepDngwi/ffziin7hyi6uvvaepdu9.jpg 990w, https://res.cloudinary.com/lesswrong-2-0/image/upload/v1675848024/mirroredImages/YKfNZAmiLdepDngwi/x9abhwjgd3nazoept5co.jpg 1024w\"><figcaption>We think PaLM has about one chinchilla worth of parameters. This isn't confusing at all.<\/figcaption><\/figure><p>Tragically, we could not figure out how many palms worth of parameters Chinchilla (70 bees) has. We leave this as an exercise for the reader.<\/p><p>&nbsp;<\/p><ol class=\"footnotes\" role=\"doc-endnotes\"><li class=\"footnote-item\" role=\"doc-endnote\" id=\"fnudplyua1b59\"><span class=\"footnote-back-link\"><sup><strong><a href=\"#fnrefudplyua1b59\">^<\/a><\/strong><\/sup><\/span><div class=\"footnote-content\"><p>There are <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC311238/\">about 170,000 neurons<\/a> in the corpora pendiculata of a honeybee, or roughly 140,000 after adjusting for the tendency of optical fractionators to overcou<\/p><\/div><\/li><\/ol>...","wordCount":402,"version":"0.8.3"},"Revision:YKfNZAmiLdepDngwi_moderationGuidelines":{"_id":"YKfNZAmiLdepDngwi_moderationGuidelines","__typename":"Revision","html":""},"Revision:hNFdS3rRiYgqqD8aM_description":{"_id":"hNFdS3rRiYgqqD8aM_description","__typename":"Revision","htmlHighlight":"<html><head><\/head><body><p><strong>Humor<\/strong>. This tag is a joke.<\/p><\/body><\/html>"},"Tag:hNFdS3rRiYgqqD8aM":{"_id":"hNFdS3rRiYgqqD8aM","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:hNFdS3rRiYgqqD8aM_description"},"userId":"nLbwLhBaQeG6tCNDN","name":"Humor","slug":"humor","core":null,"postCount":141,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":null,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-04-22T22:52:13.969Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:fpEBgFE7fgpxTm9BF_description":{"_id":"fpEBgFE7fgpxTm9BF_description","__typename":"Revision","htmlHighlight":"<p><strong>Machine Learning<\/strong> refers to the general field of study that deals with automated statistical learning and pattern detection by non-biological systems. It can be seen as a sub-domain of artificial intelligence that specifically deals with modeling and prediction through the knowledge extracted from training data. As a multi-disciplinary area, it has borrowed concepts and ideas from other areas like pure mathematics and cognitive science.<\/p><h2>Understanding different machine learning algorithms<\/h2><p>The most widely used distinction is between unsupervised (e.g. k-means clustering, principal component analysis) vs supervised (e.g. Support Vector Machines, logistic regression) methods. The first approach identifies interesting patterns (e.g. clusters and latent dimensions) in unlabeled training data, whereas the second takes labeled training data and tries to predict the label for unlabeled data points from the same distribution.<\/p><p>Another important distinction relates to the bias/variance tradeoff -- some machine learning methods are are capable of recognizing more complex patterns, but the tradeoff is that these methods can overfit and generalize poorly if there's noise in the training data -- especially if there's not much training data available.<\/p><p>There are also subfields of machine learning devoted to operating on specific kinds of data. For example, Hidden Markov Models and recurrent neural networks operate on time series data. Convolutional neural networks are commonly applied to image data.<\/p><h2>Applications<\/h2><p>The use of machine learning has been widespread since its formal definition in the 50s. The ability to make predictions based on data has been extensively used in areas such as analysis of financial markets, natural language processing and even brain-computer interfaces. Amazons product suggestion system makes use of training data in the form of past customer purchases in order to predict what customers might want to buy in the future.<\/p><p>In addition to its practical usefulness, machine learning has also offered insight into human cognitive organization. It seems likely machine learning will play an important role in the development of <a href=\"https://www.lesswrong.com/tag/artificial-general-intelligence\">artificial general intelligence<\/a>.<\/p><h2>Further Reading &amp; References<\/h2><ul><li><a href=\"https://web.stanford.edu/~hastie/ElemStatLearn/\">The Elements of Statistical Learning<\/a><\/li><\/ul><h2>See Also<\/h2><ul><li><a href=\"https://www.lesswrong.com/tag/forecasting-and-prediction\">Prediction<\/a><\/li><\/ul>"},"Tag:fpEBgFE7fgpxTm9BF":{"_id":"fpEBgFE7fgpxTm9BF","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:fpEBgFE7fgpxTm9BF_description"},"userId":"qgdGA4ZEyW7zNdK84","name":"Machine Learning  (ML)","slug":"machine-learning-ml","core":null,"postCount":288,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":null,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-08T04:33:04.074Z","wikiOnly":false,"deleted":false,"isSubforum":null},"User:vkJnzkZKmPszTLfKc":{"_id":"vkJnzkZKmPszTLfKc","__typename":"User","biography":null,"profileImageId":null,"moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":null,"slug":"adam-scherlis","createdAt":"2021-07-27T01:15:25.295Z","username":"adam-scherlis","displayName":"Adam Scherlis","previousDisplayName":null,"fullName":null,"karma":752,"afKarma":99,"deleted":null,"isAdmin":false,"htmlBio":"","postCount":17,"commentCount":73,"sequenceCount":null,"afPostCount":5,"afCommentCount":2,"spamRiskScore":1,"tagRevisionCount":null},"User:DgtwuwsTGQo4MQfJa":{"_id":"DgtwuwsTGQo4MQfJa","__typename":"User","slug":"lawrencec","createdAt":"2014-04-24T00:48:04.170Z","username":"LawChan","displayName":"LawrenceC","previousDisplayName":"LawChan","fullName":"Lawrence Chan","karma":2148,"afKarma":546,"deleted":false,"isAdmin":false,"htmlBio":"<p>I do AI Alignment research. Currently at ARC Evals, though I still dabble in interpretability in my spare time.<\/p><p>I'm also currently on leave from my PhD at UC Berkeley's CHAI.&nbsp;<\/p>","postCount":14,"commentCount":299,"sequenceCount":2,"afPostCount":13,"afCommentCount":73,"spamRiskScore":1,"tagRevisionCount":0},"Post:YKfNZAmiLdepDngwi":{"_id":"YKfNZAmiLdepDngwi","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:YKfNZAmiLdepDngwi_"},"fmCrosspost":{"isCrosspost":false},"readTimeMinutes":2,"moderationGuidelines":{"__ref":"Revision:YKfNZAmiLdepDngwi_moderationGuidelines"},"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:sYm3HiWcfZvrGu3ui"},{"__ref":"Tag:hNFdS3rRiYgqqD8aM"},{"__ref":"Tag:fpEBgFE7fgpxTm9BF"}],"url":null,"postedAt":"2023-02-08T18:58:01.364Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2023-02-08T20:25:38.909Z","meta":false,"shareWithUsers":["DgtwuwsTGQo4MQfJa"],"sharingSettings":{"anyoneWithLinkCan":"none","explicitlySharedUsersCan":"edit"},"coauthorStatuses":[{"userId":"DgtwuwsTGQo4MQfJa","confirmed":true,"requested":true}],"hasCoauthorPermission":true,"commentCount":10,"voteCount":62,"baseScore":97,"extendedScore":null,"unlisted":false,"score":0.8512721175505796,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2023-02-10T08:16:53.413Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"vkJnzkZKmPszTLfKc","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"qgdGA4ZEyW7zNdK84","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":[],"reviewForAlignmentUserId":null,"afBaseScore":36,"afExtendedScore":null,"afCommentCount":null,"afLastCommentedAt":"2023-02-08T08:24:12.406Z","afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"reviewCount":null,"reviewVoteCount":null,"positiveReviewVoteCount":null,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"user":{"__ref":"User:vkJnzkZKmPszTLfKc"},"coauthors":[{"__ref":"User:DgtwuwsTGQo4MQfJa"}],"slug":"gpt-175bee","title":"GPT-175bee","draft":false,"hideCommentKarma":false,"af":false,"currentUserReviewVote":null},"Revision:CoZhXrhpQxpy9xw9y_":{"_id":"CoZhXrhpQxpy9xw9y_","__typename":"Revision","htmlHighlight":"<p>(<i>Partially in response to&nbsp;<\/i><a href=\"https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities\"><i><u>AGI Ruin: A list of Lethalities<\/u><\/i><\/a>.&nbsp;<i>Written in the same rambling style. Not exhaustive.<\/i>)<\/p><h3>Agreements<\/h3><ol><li>Powerful AI systems have a good chance of deliberately and irreversibly disempowering humanity. This is a much easier failure mode than killing everyone with destructive physical technologies.<\/li><li>Catastrophically risky AI systems could plausibly exist soon, and there likely wont be a strong consensus about this fact until such systems pose a meaningful existential risk per year. There is not necessarily any fire alarm.<\/li><li>Even if there were consensus about a risk from powerful AI systems, there is a good chance that the world would respond in a totally unproductive way. Its wishful thinking to look at possible stories of doom and say we wouldnt let that happen; humanity is fully capable of messing up even very basic challenges, especially if they are novel.<\/li><li>I think that many of the projects intended to help with AI alignment don't make progress on key difficulties and wont significantly reduce the risk of catastrophic outcomes. This is related to people gravitating to whatever research is most tractable and not being too picky about what problems it helps with, and related to a low level of concern with the long-term future in particular. Overall, there are relatively few researchers who are effectively focused on the technical problems most relevant to existential risk from alignment failures.<\/li><li>There are strong social and political pressures to spend much more of our time talking about how AI shapes existing conflicts and shifts power. This pressure is already playing out and it doesnt seem too likely to get better. I think Eliezers term <a href=\"https://twitter.com/ESYudkowsky/status/927643062091710469\"><u>the last derail<\/u><\/a> is hyperbolic but on point.<\/li><li>Even when thinking about accident risk, peoples minds seem to go to what they think of as more realistic and less sci fi risks that are much less likely to be existential (and sometimes I think less plausible). Its very possible this dynamic wont change until after actually existing AI systems pose an existential risk.<\/li><li>There is a good chance that an AI catastrophe looks like an abrupt coup where AI systems permanently disempower humans with little opportunity for resistance. People seem to consistently round this risk down to more boring stories that fit better with their narratives about the world. It is quite possible that an AI coup will be sp<\/li><\/ol>...","wordCount":6139,"version":"1.10.0"},"Revision:CoZhXrhpQxpy9xw9y_moderationGuidelines":{"_id":"CoZhXrhpQxpy9xw9y_moderationGuidelines","__typename":"Revision","html":""},"Revision:CoZhXrhpQxpy9xw9y_customHighlight":{"_id":"CoZhXrhpQxpy9xw9y_customHighlight","__typename":"Revision","html":""},"User:gb44edJjXhte8DA3A":{"_id":"gb44edJjXhte8DA3A","__typename":"User","biography":null,"profileImageId":null,"moderationStyle":"easy-going","bannedUserIds":null,"moderatorAssistance":true,"slug":"paulfchristiano","createdAt":"2010-07-28T17:04:08.586Z","username":"paulfchristiano","displayName":"paulfchristiano","previousDisplayName":null,"fullName":"Paul Christiano","karma":22478,"afKarma":5124,"deleted":false,"isAdmin":false,"htmlBio":"","postCount":150,"commentCount":2122,"sequenceCount":1,"afPostCount":76,"afCommentCount":792,"spamRiskScore":1,"tagRevisionCount":0},"Post:CoZhXrhpQxpy9xw9y":{"_id":"CoZhXrhpQxpy9xw9y","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:CoZhXrhpQxpy9xw9y_"},"fmCrosspost":null,"readTimeMinutes":25,"moderationGuidelines":{"__ref":"Revision:CoZhXrhpQxpy9xw9y_moderationGuidelines"},"customHighlight":{"__ref":"Revision:CoZhXrhpQxpy9xw9y_customHighlight"},"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:sYm3HiWcfZvrGu3ui"},{"__ref":"Tag:ZFrgTgzwEfStg26JL"},{"__ref":"Tag:3uE2pXvbcnS9nnZRE"}],"url":null,"postedAt":"2022-06-19T19:15:55.698Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2022-06-19T19:37:09.548Z","meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":false,"commentCount":205,"voteCount":337,"baseScore":781,"extendedScore":null,"unlisted":false,"score":0.03871445286948464,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2022-11-08T00:21:58.481Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":"2022-06-21T18:21:27.884Z","commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"gb44edJjXhte8DA3A","location":null,"googleLocation":null,"onlineEvent":false,"globalEvent":false,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":[],"groupId":null,"reviewedByUserId":"qgdGA4ZEyW7zNdK84","suggestForCuratedUserIds":["EQNTWXLKMeWMp2FQS","qxJ28GN72aiJu96iF","r38pkCm7wF4M44MDQ"],"suggestForCuratedUsernames":"Ben Pace, Kaj_Sotala, Raemon","reviewForCuratedUserId":"qgdGA4ZEyW7zNdK84","authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":206,"afExtendedScore":null,"afCommentCount":55,"afLastCommentedAt":"2022-06-27T09:41:27.985Z","afSticky":false,"hideAuthor":false,"moderationStyle":"easy-going","submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":false,"reviewCount":null,"reviewVoteCount":null,"positiveReviewVoteCount":null,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":null,"reviewCount2019":null,"user":{"__ref":"User:gb44edJjXhte8DA3A"},"coauthors":[],"slug":"where-i-agree-and-disagree-with-eliezer","title":"Where I agree and disagree with Eliezer","draft":false,"hideCommentKarma":false,"af":true,"currentUserReviewVote":null},"Revision:LgavAYtzFQZKg95WC_":{"_id":"LgavAYtzFQZKg95WC_","__typename":"Revision","htmlHighlight":"<p><strong>Related to: <\/strong><a href=\"/lw/41/individual_rationality_is_a_matter_of_life_and/\">Individual Rationality is a Matter of Life and Death<\/a>, <a href=\"/lw/6t/the_benefits_of_rationality/\">The Benefits of Rationality<\/a>, <a href=\"/lw/7i/rationality_is_systematized_winning/\">Rationality is Systematized Winning<\/a><br /><strong>But I finally snapped after reading: <\/strong><a href=\"/lw/9c/mandatory_secret_identities/\">Mandatory Secret Identities<\/a><br /><br />Okay, the title was for shock value. Rationality is pretty great. Just not <em>quite <\/em>as great as everyone here seems to think it is.<br /><br />For this post, I will be using \"extreme rationality\" or \"x-rationality\" in the sense of \"techniques and theories from Overcoming Bias, Less Wrong, or similar deliberate formal rationality study programs, above and beyond the standard level of rationality possessed by an intelligent science-literate person without formal rationalist training.\" It seems pretty uncontroversial that there are massive benefits from going from a completely irrational moron to the average intelligent person's level. I'm coining this new term so there's no temptation to confuse x-rationality with normal, lower-level rationality.<br /><br />And for this post, I use \"benefits\" or \"practical benefits\" to mean anything not relating to philosophy, truth, winning debates, or a sense of personal satisfaction from understanding things better. Money, status, popularity, and scientific discovery all count.<br /><br />So, what are these \"benefits\" of \"x-rationality\"?<br /><br />A while back, Vladimir Nesov asked exactly that, and <a href=\"/lw/2x/in_what_ways_have_you_become_stronger/\">made a thread for people to list all of the positive effects<\/a> x-rationality had on their lives. Only a handful responded, and most responses weren't very practical. Anna Salamon, one of the few people to give a really impressive list of benefits, wrote:<\/p>\n<blockquote>\n<p>I'm surprised there are so few apparent gains listed. Are most people who benefited just being silent? We should expect a certain number of headache-cures, etc., just by placebo effects or coincidences of timing.<\/p>\n<\/blockquote>\n<p>There have since been a few more people claiming practical benefits from x-rationality, but we should generally expect more people to claim benefits than to actually experience them. Anna mentions the placebo effect, and to that I would add cognitive dissonance - people spent all this time learning x-rationality, so it MUST have helped them! - and the same sort of confirmation bias that makes Christians swear that their prayers really work.<br /><br />I find my personal experience in accord with the evidence from Vladimir's thread. I've gotten countless clarity-of-mind benefits from Overcoming Bias' x-rationality, but practical benefits? As... <\/p>","wordCount":2372,"version":"1.0.0"},"Revision:9YFoDPFwMoWthzgkY_description":{"_id":"9YFoDPFwMoWthzgkY_description","__typename":"Revision","htmlHighlight":"<p><strong>Pitfalls of Rationality<\/strong> are frequent <a href=\"https://www.lesswrong.com/tag/failure-mode\">error modes<\/a>, obstacles or problems that arise when people try to practice rationality, or engage with rationality-related materials. Related concepts include the \"valley of bad rationality\".<br><br>There are two threads touched in posts under this tag:<\/p><ol><li>Things that go wrong when people try to be more rational and they unintentionally end up making things worse.<\/li><li>Arguably, why haven't rationalists visible succeeded at their bold and ambitious goals yet?<\/li><\/ol><p>Regarding the first point, from <a href=\"https://www.lesswrong.com/posts/oZNXmHcdhb4m7vwsv/incremental-progress-and-the-valley\">Incremental Progress and the Valley<\/a>:<\/p><blockquote><p>Ah.&nbsp; Well, here's the the thing:&nbsp; An <i>incremental<\/i> step in the direction of rationality, if the result is still irrational in other ways, does not have to yield <i>incrementally <\/i>more winning.<\/p><p>The optimality theorems that we have for probability theory and decision theory, are for <i>perfect<\/i> probability theory and decision theory.&nbsp; There is no companion theorem which says that, starting from some flawed initial form, every <i>incremental<\/i> modification of the algorithm that takes the structure closer to the ideal, must yield an <i>incremental<\/i> improvement in performance.&nbsp; This has not yet been proven, because it is not, in fact, true.<\/p><\/blockquote><p>See also: <a href=\"https://www.lesswrong.com/tag/criticisms-of-the-rationalist-movement\">Criticisms of the Rationalist Movement<\/a>, <a href=\"https://www.lesswrong.com/tag/value-of-rationality\">Value of Rationality<\/a><\/p>"},"Tag:9YFoDPFwMoWthzgkY":{"_id":"9YFoDPFwMoWthzgkY","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:9YFoDPFwMoWthzgkY_description"},"userId":"x5S2Kuj6TfQTGuo63","name":"Pitfalls of Rationality","slug":"pitfalls-of-rationality","core":false,"postCount":70,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":null,"descriptionTruncationCount":null,"createdAt":"2020-06-11T19:31:37.154Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:3QnDqGSdRMA5mdMM6_description":{"_id":"3QnDqGSdRMA5mdMM6_description","__typename":"Revision","htmlHighlight":"<p><strong>Related pages:<\/strong> <a href=\"https://www.lesswrong.com/tag/costs-of-rationality\">Costs of Rationality<\/a>, <a href=\"https://www.lesswrong.com/tag/valley-of-bad-rationality\">Valley of Bad Rationality<\/a>, <a href=\"https://www.lesswrong.com/tag/pitfalls-of-rationality\">Pitfalls of Rationality<\/a>, <a href=\"https://www.lesswrong.com/tag/criticisms-of-the-rationalist-movement\">Criticisms of The Rationalist Movement<\/a><\/p>"},"Tag:3QnDqGSdRMA5mdMM6":{"_id":"3QnDqGSdRMA5mdMM6","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:3QnDqGSdRMA5mdMM6_description"},"userId":"r38pkCm7wF4M44MDQ","name":"Value of Rationality","slug":"value-of-rationality","core":false,"postCount":18,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-08-22T07:55:16.723Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:5f5c37ee1b5cdee568cfb345_description":{"_id":"5f5c37ee1b5cdee568cfb345_description","__typename":"Revision","htmlHighlight":"<p><strong>Criticisms of the <\/strong><a href=\"https://www.lesswrong.com/tag/rationalist-movement\">rationalist movement<\/a> and <a href=\"https://www.lesswrong.com/about\">LessWrong<\/a> have existed for most of its duration on various grounds.<\/p><h2>Cult of Rationality<\/h2><p>Less Wrong has been referred to as a <a href=\"https://www.lesswrong.com/tag/phyg\"><s>cult<\/s> phyg<\/a> on numerous occasions,<a href=\"#fn1\"><sup>1<\/sup><\/a><a href=\"#fn2\"><sup>2<\/sup><\/a><a href=\"#fn3\"><sup>3<\/sup><\/a> with <a href=\"https://www.lesswrong.com/tag/eliezer-yudkowsky\">Eliezer Yudkowsky<\/a> as its leader. Eliezer's confidence in his AI safety work outside of mainstream academia and self-professed intelligence renders him highly unpopular with his critics.<a href=\"#fn4\"><sup>4<\/sup><\/a><\/p><h2>Neoreaction<\/h2><p>The Neoreaction movement,<a href=\"#fn5\"><sup>5<\/sup><\/a> is a notoriously adjacent idea to the community. Whist it has being explicitly refuted by figures such as Eliezer<a href=\"#fn6\"><sup>6<\/sup><\/a><a href=\"#fn7\"><sup>7<\/sup><\/a> and Scott,<a href=\"#fn8\"><sup>8<\/sup><\/a> it is often actively-associated by critics.<a href=\"#fn9\"><sup>9<\/sup><\/a><a href=\"#fn10\"><sup>10<\/sup><\/a><\/p><h2>Rationalism<\/h2><p>The movement has been criticized as overemphasizing <a href=\"https://www.lesswrong.com/tag/induction\">inductive reasoning<\/a> over <a href=\"https://www.lesswrong.com/tag/empiricism\">empiricism<\/a>,<a href=\"#fn11\"><sup>11<\/sup><\/a> a criticism that has been refuted by <a href=\"https://www.lesswrong.com/tag/scott-alexander\">Scott Alexander<\/a>.<a href=\"#fn12\"><sup>12<\/sup><\/a><\/p><h2>Roko's basilisk<\/h2><p>The <a href=\"https://wiki.lesswrong.com/wiki/Roko's_basilisk\">Roko's basilisk<\/a> thought experiment was notorious in that it required specific preconditions available nearly exclusively within the Less Wrong community that rendered the reader vulnerable to this 'memetic hazard'. As such it has drawn derision from critics who feel perception risk from unfriendly AI is overstated within the community.<a href=\"#fn13\"><sup>13<\/sup><\/a><a href=\"#fn14\"><sup>14<\/sup><\/a><\/p><h2>Transhumanism<\/h2><p>Less Wrong's community was partially founded by soliciting users from the transhumanist <a href=\"https://hpluspedia.org/wiki/SL4#cite_note-1\">SL4<\/a> mailing list and <a href=\"https://www.lesswrong.com/tag/eliezer-yudkowsky\">Eliezer Yudkowsky<\/a> is himself a prominent transhumanist.<\/p><p>As such, the fringe nature of transhumanist ideas such as <a href=\"https://www.lesswrong.com/tag/cryonics\">cryonics<\/a>, AGI takeover<a href=\"#fn15\"><sup>15<\/sup><\/a> has met with continued scorn from the skeptics based at <a href=\"https://wiki.lesswrong.com/wiki/RationalWiki\">RationalWiki<\/a>.<a href=\"#fn16\"><sup>16<\/sup><\/a><\/p><h2>See also<\/h2><ul><li><a href=\"https://www.lesswrong.com/tag/rationalist-movement\">Rationalist movement<\/a><\/li><li><a href=\"https://wiki.lesswrong.com/wiki/RationalWiki\">RationalWiki<\/a><\/li><li><a href=\"https://wiki.lesswrong.com/wiki/Sneer_Club\">Sneer Club<\/a><\/li><\/ul><h2>References<\/h2><ol><li><a href=\"http://lesswrong.com/lw/4d/youre_calling_who_a_cult_leader/\">http://lesswrong.com/lw/4d/youre_calling_who_a_cult_leader/<\/a><a href=\"#fnref1\"><\/a><\/li><li><a href=\"http://lesswrong.com/lw/bql/our_phyg_is_not_exclusive_enough/\">http://lesswrong.com/lw/bql/our_phyg_is_not_exclusive_enough/<\/a><a href=\"#fnref2\"><\/a><\/li><li><a href=\"https://www.reddit.com/r/OutOfTheLoop/comments/3ttw2e/what_is_lesswrong_and_why_do_people_say_it_is_a/\">https://www.reddit.com/r/OutOfTheLoop/comments/3ttw2e/what_is_lesswrong_and_why_do_people_say_it_is_a/<\/a><a href=\"#fnref3\"><\/a><\/li><li><a href=\"http://rationalwiki.org/wiki/Eliezer_Yudkowsky\">http://rationalwiki.org/wiki/Eliezer_Yudkowsky<\/a><a href=\"#fnref4\"><\/a><\/li><li><a href=\"https://web.archive.org/web/20130424060436/http://habitableworlds.wordpress.com/2013/04/21/visualizing-neoreaction/\">https://web.archive.org/web/20130424060436/http://habitableworlds.wordpress.com/2013/04/21/visualizing-neoreaction/<\/a><a href=\"#fnref5\"><\/a><\/li><li><a href=\"http://yudkowsky.tumblr.com/post/142497361345/this-isnt-going-to-work-but-for-the-record-and\">http://yudkowsky.tumblr.com/post/142497361345/this-isnt-going-to-work-but-for-the-record-and<\/a><a href=\"#fnref6\"><\/a><\/li><li><a href=\"http://lesswrong.com/lw/fh4/why_is_mencius_moldbug_so_popular_on_less_wrong/\">http://lesswrong.com/lw/fh4/why_is_mencius_moldbug_so_popular_on_less_wrong/<\/a><a href=\"#fnref7\"><\/a><\/li><li><a href=\"http://slatestarcodex.com/2013/10/20/the-anti-reactionary-faq/\">http://slatestarcodex.com/2013/10/20/the-anti-reactionary-faq/<\/a><a href=\"#fnref8\"><\/a><\/li><li><a href=\"http://rationalwiki.org/wiki/Neoreactionary_movement\">http://rationalwiki.org/wiki/Neoreactionary_movement<\/a><a href=\"#fnref9\"><\/a><\/li><li><a href=\"https://hpluspedia.org/wiki/The_Silicon_Ideology\">https://hpluspedia.org/wiki/The_Silicon_Ideology<\/a><a href=\"#fnref10\"><\/a><\/li><li><a href=\"https://the-orbit.net/almostdiamonds/2014/11/24/why-i-am-not-a-rationalist/\">https://the-orbit.net/almostdiamonds/2014/11/24/why-i-am-not-a-rationalist/<\/a><a href=\"#fnref11\"><\/a><\/li><li><a href=\"http://slatestarcodex.com/2014/11/27/why-i-am-not-rene-descartes/\">http://slatestarcodex.com/2014/11/27/why-i-am-not-rene-descartes/<\/a><a href=\"#fnref12\"><\/a><\/li><li><a href=\"http://rationalwiki.org/wiki/Roko's_basilisk\">http://rationalwiki.or<\/a><\/li><\/ol>..."},"Tag:5f5c37ee1b5cdee568cfb345":{"_id":"5f5c37ee1b5cdee568cfb345","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:5f5c37ee1b5cdee568cfb345_description"},"userId":"RNTWCoLXwK5DKhFDA","name":"Criticisms of The Rationalist Movement","slug":"criticisms-of-the-rationalist-movement","core":null,"postCount":16,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":null,"needsReview":false,"descriptionTruncationCount":null,"createdAt":"2020-09-11T19:58:52.875Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Tag:bXSkC7FFgApRnSajw":{"_id":"bXSkC7FFgApRnSajw","__typename":"Tag","parentTag":null,"subTags":[],"description":null,"userId":"Q7NW4XaWQmfPfdcFj","name":"General Semantics","slug":"general-semantics","core":false,"postCount":10,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2021-08-09T19:57:04.412Z","wikiOnly":false,"deleted":false,"isSubforum":null},"User:XgYW5s8njaYrtyP7q":{"_id":"XgYW5s8njaYrtyP7q","__typename":"User","biography":null,"profileImageId":null,"moderationStyle":null,"bannedUserIds":null,"moderatorAssistance":null,"slug":"scottalexander","createdAt":"2009-02-28T15:53:46.032Z","username":"Yvain","displayName":"Scott Alexander","previousDisplayName":null,"fullName":null,"karma":40156,"afKarma":68,"deleted":false,"isAdmin":false,"htmlBio":"","postCount":214,"commentCount":1567,"sequenceCount":13,"afPostCount":1,"afCommentCount":1,"spamRiskScore":1,"tagRevisionCount":19},"Post:LgavAYtzFQZKg95WC":{"_id":"LgavAYtzFQZKg95WC","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:LgavAYtzFQZKg95WC_"},"fmCrosspost":null,"readTimeMinutes":9,"moderationGuidelines":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:9YFoDPFwMoWthzgkY"},{"__ref":"Tag:Ng8Gice9KNkncxqcj"},{"__ref":"Tag:3QnDqGSdRMA5mdMM6"},{"__ref":"Tag:5f5c37ee1b5cdee568cfb345"},{"__ref":"Tag:bXSkC7FFgApRnSajw"}],"url":null,"postedAt":"2009-04-09T02:44:20.056Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2018-01-30T00:32:03.501Z","meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":null,"commentCount":281,"voteCount":225,"baseScore":232,"extendedScore":null,"unlisted":false,"score":0.000334,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2022-03-07T17:29:40.408Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":null,"curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"XgYW5s8njaYrtyP7q","location":null,"googleLocation":null,"onlineEvent":null,"globalEvent":null,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":15,"afExtendedScore":null,"afCommentCount":null,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":null,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":0,"reviewCount2019":null,"user":{"__ref":"User:XgYW5s8njaYrtyP7q"},"coauthors":[],"slug":"extreme-rationality-it-s-not-that-great","title":"Extreme Rationality: It's Not That Great","draft":false,"hideCommentKarma":null,"af":false,"currentUserReviewVote":null},"Revision:dLbkrPu5STNCBLRjr_":{"_id":"dLbkrPu5STNCBLRjr_","__typename":"Revision","htmlHighlight":"<p>At the Singularity Summit 2007, one of the speakers called for democratic, multinational development of artificial intelligence. So I stepped up to the microphone and asked:<\/p><blockquote><p>Suppose that a group of democratic republics form a consortium to develop AI, and theres a lot of politicking during the processsome interest groups have unusually large influence, others get shaftedin other words, the result looks just like the products of modern democracies. Alternatively, suppose a group of rebel nerds develops an AI in their basement, and instructs the AI to poll everyone in the worlddropping cellphones to anyone who doesnt have themand do whatever the majority says. Which of these do you think is more democratic, and would you feel safe with either?<\/p><\/blockquote><p>I wanted to find out whether he believed in the pragmatic adequacy of the democratic political process, or if he believed in the moral rightness of voting. But the speaker replied:<\/p><blockquote><p>The first scenario sounds like an editorial in <i>Reason<\/i> magazine, and the second sounds like a Hollywood movie plot.<\/p><\/blockquote><p>Confused, I asked:<\/p><blockquote><p>Then what kind of democratic process <i>did<\/i> you have in mind?<\/p><\/blockquote><p>The speaker replied:<\/p><blockquote><p>Something like the Human Genome Projectthat was an internationally sponsored research project.<\/p><\/blockquote><p>I asked:<\/p><blockquote><p>How would different interest groups resolve their conflicts in a structure like the Human Genome Project?<\/p><\/blockquote><p>And the speaker said:<\/p><blockquote><p>I dont know.<\/p><\/blockquote><p>This exchange puts me in mind of a <a href=\"http://content.time.com/time/magazine/article/0,9171,954853,00.html\">quote<\/a> from some dictator or other, who was asked if he had any intentions to move his pet state toward democracy:<\/p><blockquote><p>We believe we are already within a democratic system. Some factors are still missing, like the expression of the peoples will.<\/p><\/blockquote><p>The substance of a democracy is the specific mechanism that resolves policy conflicts. If all groups had the same preferred policies, there would be no need for democracywe would automatically cooperate. The resolution process can be a direct majority vote, or an elected legislature, or even a voter-sensitive behavior of an artificial intelligence, but it has to be <i>something<\/i>. What does it <i>mean<\/i> to call for a democratic solution if you dont have a conflict-resolution mechanism in mind?<\/p><p>I think it means that you have said the word democracy, so the audience is supposed to cheer. Its not so much a propositional statement or belief, as the equivalent of the Applause light that tells a studio audience when to clap.<\/p><p>This case... <\/p>","wordCount":735,"version":"2.1.0"},"Revision:SJFsFfFhE6m2ThAYJ_description":{"_id":"SJFsFfFhE6m2ThAYJ_description","__typename":"Revision","htmlHighlight":"<p>One principle of rationality is that &quot;<a href=\"https://www.lesswrong.com/s/7gRSERQZbqTuLX5re/p/a7n8GdKiAZRX86T5A\">beliefs should pay rent in <strong>anticipated experiences<\/strong><\/a>.&quot; If you believe in something, what do you expect to be different as a result? What does the belief say should happen, and what does it say should <em>not<\/em> happen? If you have a verbal disagreement with someone, how does your disagreement cash out in differing expectations?<\/p><p>If two people try to get specific about the anticipated experiences driving their disagreement, one method for doing so is the <a href=\"https://www.lesswrong.com/posts/exa5kmvopeRyfJgCy/double-crux-a-strategy-for-resolving-disagreement\">double crux<\/a> technique. The notion that beliefs are models of what we expect to experience is also one of the basic premises of <a href=\"https://www.lesswrong.com/tag/predictive-processing\">predictive processing<\/a> theories of how the brain works. Beliefs that do not pay rent may be related to <a href=\"https://www.lesswrong.com/posts/4xKeNKFXFB458f5N8/ethnic-tension-and-meaningless-arguments\">meaningless arguments<\/a> driven by <a href=\"https://www.lesswrong.com/tag/coalitional-instincts\">coalitional instincts<\/a>. <\/p><blockquote> <em>If a tree falls in a forest and no one hears it, does it make a sound? One says, &#x201C;Yes it does, for it makes vibrations in the air.&#x201D; Another says, &#x201C;No it does not, for there is no auditory processing in any brain.&#x201D;<\/em>  [...]<\/blockquote><blockquote>Suppose that, after a tree falls, the two arguers walk into the forest together. Will one expect to see the tree fallen to the right, and the other expect to see the tree fallen to the left? Suppose that before the tree falls, the two leave a sound recorder next to the tree. Would one, playing back the recorder, expect to hear something different from the other? Suppose they attach an electroencephalograph to any brain in the world; would one expect to see a different trace than the other?<\/blockquote><blockquote>Though the two argue, one saying &#x201C;No,&#x201D; and the other saying &#x201C;Yes,&#x201D; they do not anticipate any different experiences. The two think they have different models of the world, but they have no difference with respect to what they expect will <em>happen to<\/em> them; their maps of the world do not diverge in any sensory detail.<\/blockquote><blockquote>-- Eliezer Yudkowsky, <a href=\"https://www.lesswrong.com/s/7gRSERQZbqTuLX5re/p/a7n8GdKiAZRX86T5A\">Making Beliefs Pay Rent (In Anticipated Experiences)<\/a><\/blockquote>"},"Tag:SJFsFfFhE6m2ThAYJ":{"_id":"SJFsFfFhE6m2ThAYJ","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:SJFsFfFhE6m2ThAYJ_description"},"userId":"qxJ28GN72aiJu96iF","name":"Anticipated Experiences","slug":"anticipated-experiences","core":false,"postCount":39,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-13T16:19:09.687Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:DdgSyQoZXjj3KnF4N_description":{"_id":"DdgSyQoZXjj3KnF4N_description","__typename":"Revision","htmlHighlight":"<p><strong>Tribalism<\/strong> or <strong>Coalitional Instincts <\/strong>is closely connected to the concept of in/out-groups. Coalitional instincts drive humans to act in ways which cause them join, support, defend, and maintain their membership in various coalitions that are defined by sharing a common identity. An illustrative example can be found in <a href=\"https://www.lesswrong.com/posts/6hfGNLf4Hg5DXqJCF/a-fable-of-science-and-politics\">A Fable of Science and Politics<\/a>.<\/p><p>See also: <a href=\"https://www.lesswrong.com/tag/blues-and-greens\">Blues and Greens<\/a>, <a href=\"https://www.lesswrong.com/tag/groupthink\">Groupthink<\/a>, <a href=\"https://www.lesswrong.com/tag/motivated-reasoning\">Motivated Reasoning<\/a>, <a href=\"https://www.lesswrong.com/tag/social-and-cultural-dynamics\">Social and Cultural Dynamics<\/a>, <a href=\"https://www.lesswrong.com/tag/social-reality\">Social Reality<\/a>.<\/p><blockquote>The primary function that drove the evolution of coalitions is the amplification of the power of its members in conflicts with non-members. This function explains a number of otherwise puzzling phenomena. For example,  ancestrally, if you had no coalition you were nakedly at the mercy of everyone else, so the instinct to belong to a coalition has urgency, preexisting and superseding any policy-driven basis for membership. This is why group beliefs are free to be so weird. [...] <\/blockquote><blockquote>... to earn membership in a group you must send signals that clearly indicate that you differentially support it, compared to rival groups. Hence, optimal weighting of beliefs and communications in the individual mind will make it feel good to think and express content conforming to and flattering to one&#x2019;s group&#x2019;s shared beliefs and to attack and misrepresent rival groups. The more biased away from neutral truth, the better the communication functions to affirm coalitional identity, generating polarization in excess of actual policy disagreements. Communications of practical and functional truths are generally useless as differential signals, because any honest person might say them regardless of coalitional loyalty. In contrast, unusual, exaggerated beliefs [...] are unlikely to be said except as expressive of identity, because there is no external reality to motivate nonmembers to speak absurdities. <\/blockquote><blockquote>-- John Tooby, &quot;<a href=\"https://www.edge.org/conversation/john_tooby-coalitional-instincts\">Coalitional Instincts<\/a>&quot;<\/blockquote><br><blockquote>Humans interact in dense social networks, and this poses a problem for bystanders when conflicts arise: which side, if any, to support. Choosing sides is a difficult strategic problem because the outcome of a conflict critically depends on which side other bystanders support. One strategy is siding with the higher status disputant, which can allow bystanders to coordinate with one another to take the same side, reducing fighting costs. However, this strategy carries the cost of e<\/blockquote>..."},"Tag:DdgSyQoZXjj3KnF4N":{"_id":"DdgSyQoZXjj3KnF4N","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:DdgSyQoZXjj3KnF4N_description"},"userId":"qxJ28GN72aiJu96iF","name":"Tribalism","slug":"tribalism","core":false,"postCount":53,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-13T15:43:11.661Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Tag:gHCNhqxuJq2bZ2akb":{"_id":"gHCNhqxuJq2bZ2akb","__typename":"Tag","parentTag":null,"subTags":[],"description":null,"userId":"qxJ28GN72aiJu96iF","name":"Social & Cultural Dynamics","slug":"social-and-cultural-dynamics","core":false,"postCount":271,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-07-10T11:36:05.706Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:DsdbQhWAnPqfzo4Yw_description":{"_id":"DsdbQhWAnPqfzo4Yw_description","__typename":"Revision","htmlHighlight":"<p>The <strong>reversal test<\/strong> is a technique for fighting <a href=\"https://wiki.lesswrong.com/wiki/Status_quo_bias\"><u>status quo bias<\/u><\/a> in judgments about the preferred value of a continuous parameter. If one deems the change of the parameter in one direction to be undesirable, the reversal test is to check that either the change of that parameter in the opposite direction (away from status quo) is deemed desirable, or that there are strong reasons to expect that the current value of the parameter is (at least locally) the optimal one.<\/p><p>For example, if it became possible to increase the human lifespan, some would argue that it would be undesirable for people to live longer because, say, overpopulation would be difficult to manage. The reversal test is then to check that the same people accept that <i>shorter<\/i> lifespan is desirable, or that there are really strong reasons to believe that the current lifespan happens to be optimal.<\/p><blockquote><p>The rationale of the Reversal Test is simple: if a continuous parameter admits of a wide range of possible values, only a tiny subset of which can be local optima, then it is prima facie implausible that the actual value of that parameter should just happen to be at one of these rare local optima [...] the burden of proof shifts to those who maintain that some actual parameter is at such a local optimum: they need to provide some good reason for supposing that it is so.<\/p><p>Obviously, the Reversal Test does not show that preferring the status quo is always unjustified. In many cases, it is possible to meet the challenge posed by the Reversal Test<\/p><p>The reversal test: eliminating status quo bias in applied ethics<\/p><\/blockquote><h2>Main article<\/h2><ul><li>Nick Bostrom, Toby Ord (2006). \"The reversal test: eliminating status quo bias in applied ethics\". <i>Ethics<\/i> (University of Chicago Press) <strong>116<\/strong> (4): 656-679. (<a href=\"http://www.nickbostrom.com/ethics/statusquo.pdf\"><u>PDF<\/u><\/a>)<\/li><\/ul><h2>See also<\/h2><ul><li><a href=\"https://wiki.lesswrong.com/wiki/Status_quo_bias\"><u>Status quo bias<\/u><\/a>, <a href=\"https://wiki.lesswrong.com/wiki/Privileging_the_hypothesis\"><u>Privileging the hypothesis<\/u><\/a><\/li><li><a href=\"https://wiki.lesswrong.com/wiki/Shut_up_and_multiply\"><u>Shut up and multiply<\/u><\/a><\/li><li><a href=\"https://wiki.lesswrong.com/wiki/Absurdity_heuristic\"><u>Absurdity heuristic<\/u><\/a><\/li><\/ul><h2>External links<\/h2><ul><li><a href=\"http://philosophicaldisquisitions.blogspot.com/2012/11/the-reversal-test-and-status-quo-bias.html\"><u>\"The Reversal Test and Status Quo Bias\"<\/u><\/a> (John Danaher)<\/li><\/ul>"},"Tag:DsdbQhWAnPqfzo4Yw":{"_id":"DsdbQhWAnPqfzo4Yw","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:DsdbQhWAnPqfzo4Yw_description"},"userId":"r38pkCm7wF4M44MDQ","name":"Reversal Test","slug":"reversal-test","core":false,"postCount":5,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":false,"needsReview":false,"descriptionTruncationCount":0,"createdAt":"2020-08-20T01:21:41.056Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Revision:5f5c37ee1b5cdee568cfb26b_description":{"_id":"5f5c37ee1b5cdee568cfb26b_description","__typename":"Revision","htmlHighlight":"<p>An <strong>applause light<\/strong> is an empty statement which evokes positive affect without providing new information.<\/p><blockquote><p>It [was] not so much a <i>propositional<\/i> statement, as the equivalent of the \"Applause\" light that tells a studio audience when to clap.<\/p><p><a href=\"http://lesswrong.com/lw/jb/applause_lights/\"><u>Applause Lights<\/u><\/a><\/p><\/blockquote><h2>See also<\/h2><ul><li><a href=\"https://wiki.lesswrong.com/wiki/Guessing_the_teacher's_password\">Guessing the teacher's password<\/a>&nbsp;<\/li><li><a href=\"https://wiki.lesswrong.com/wiki/Belief_as_attire\">Belief as attire<\/a><\/li><li><a href=\"https://www.lesswrong.com/tag/cached-thoughts\">Cached Thoughts<\/a><\/li><\/ul>"},"Tag:5f5c37ee1b5cdee568cfb26b":{"_id":"5f5c37ee1b5cdee568cfb26b","__typename":"Tag","parentTag":null,"subTags":[],"description":{"__ref":"Revision:5f5c37ee1b5cdee568cfb26b_description"},"userId":"iRXwaeHoALf2AtqDZ","name":"Applause Light","slug":"applause-light","core":null,"postCount":4,"adminOnly":false,"canEditUserIds":null,"suggestedAsFilter":null,"needsReview":false,"descriptionTruncationCount":null,"createdAt":"2020-09-11T19:58:52.491Z","wikiOnly":false,"deleted":false,"isSubforum":null},"Post:dLbkrPu5STNCBLRjr":{"_id":"dLbkrPu5STNCBLRjr","__typename":"Post","deletedDraft":false,"contents":{"__ref":"Revision:dLbkrPu5STNCBLRjr_"},"fmCrosspost":null,"readTimeMinutes":3,"moderationGuidelines":null,"customHighlight":null,"lastPromotedComment":null,"bestAnswer":null,"tags":[{"__ref":"Tag:Ng8Gice9KNkncxqcj"},{"__ref":"Tag:SJFsFfFhE6m2ThAYJ"},{"__ref":"Tag:DdgSyQoZXjj3KnF4N"},{"__ref":"Tag:gHCNhqxuJq2bZ2akb"},{"__ref":"Tag:DsdbQhWAnPqfzo4Yw"},{"__ref":"Tag:5f5c37ee1b5cdee568cfb26b"}],"url":null,"postedAt":"2007-09-11T18:31:48.000Z","createdAt":null,"sticky":false,"metaSticky":false,"stickyPriority":2,"status":2,"frontpageDate":"2018-01-30T00:32:03.501Z","meta":false,"shareWithUsers":null,"sharingSettings":null,"coauthorStatuses":null,"hasCoauthorPermission":null,"commentCount":97,"voteCount":228,"baseScore":273,"extendedScore":null,"unlisted":false,"score":0.000344,"lastVisitedAt":null,"isFuture":false,"isRead":false,"lastCommentedAt":"2022-07-05T10:19:43.940Z","lastCommentPromotedAt":null,"canonicalCollectionSlug":"rationality","curatedDate":null,"commentsLocked":null,"commentsLockedToAccountsCreatedAfter":null,"question":false,"hiddenRelatedQuestion":false,"originalPostRelationSourceId":null,"userId":"nmk3nLpQE89dMRzzN","location":null,"googleLocation":null,"onlineEvent":null,"globalEvent":null,"startTime":null,"endTime":null,"localStartTime":null,"localEndTime":null,"eventRegistrationLink":null,"joinEventLink":null,"facebookLink":null,"meetupLink":null,"website":null,"contactInfo":null,"isEvent":false,"eventImageId":null,"eventType":null,"types":null,"groupId":null,"reviewedByUserId":"XtphY3uYHwruKqDyG","suggestForCuratedUserIds":null,"suggestForCuratedUsernames":null,"reviewForCuratedUserId":null,"authorIsUnreviewed":false,"afDate":null,"suggestForAlignmentUserIds":null,"reviewForAlignmentUserId":null,"afBaseScore":19,"afExtendedScore":null,"afCommentCount":null,"afLastCommentedAt":null,"afSticky":false,"hideAuthor":false,"moderationStyle":null,"submitToFrontpage":true,"shortform":false,"onlyVisibleToLoggedIn":null,"reviewCount":0,"reviewVoteCount":0,"positiveReviewVoteCount":0,"reviewVoteScoreAllKarma":null,"reviewVotesAllKarma":null,"reviewVoteScoreHighKarma":null,"reviewVotesHighKarma":null,"reviewVoteScoreAF":null,"reviewVotesAF":null,"finalReviewVoteScoreHighKarma":null,"finalReviewVotesHighKarma":null,"finalReviewVoteScoreAllKarma":null,"finalReviewVotesAllKarma":null,"finalReviewVoteScoreAF":null,"finalReviewVotesAF":null,"group":null,"nominationCount2018":null,"reviewCount2018":null,"nominationCount2019":0,"reviewCount2019":null,"user":{"__ref":"User:nmk3nLpQE89dMRzzN"},"coauthors":[],"slug":"applause-lights","title":"Applause Lights","draft":false,"hideCommentKarma":null,"af":false,"currentUserReviewVote":null},"TagRel:S4usZxE98xXRoyE6A":{"_id":"S4usZxE98xXRoyE6A","__typename":"TagRel","tag":{"__ref":"Tag:ZFrgTgzwEfStg26JL"},"currentUserVote":null,"currentUserExtendedVote":null,"currentUserCanVote":true,"score":6,"baseScore":6,"extendedScore":{"agreement":0,"agreementVoteCount":0},"afBaseScore":1,"voteCount":4,"userId":"r38pkCm7wF4M44MDQ","tagId":"ZFrgTgzwEfStg26JL","postId":"uMQ3cqWDPHhjtiesc","autoApplied":false},"TagRel:yiEmwuAf2spF2dJ7E":{"_id":"yiEmwuAf2spF2dJ7E","__typename":"TagRel","tag":{"__ref":"Tag:sYm3HiWcfZvrGu3ui"},"currentUserVote":null,"currentUserExtendedVote":null,"currentUserCanVote":true,"score":4,"baseScore":4,"extendedScore":{"agreement":0,"agreementVoteCount":0},"afBaseScore":1,"voteCount":3,"userId":"r38pkCm7wF4M44MDQ","tagId":"sYm3HiWcfZvrGu3ui","postId":"uMQ3cqWDPHhjtiesc","autoApplied":false},"TagRel:YMcE9gYDb6FgL5dZS":{"_id":"YMcE9gYDb6FgL5dZS","__typename":"TagRel","tag":{"__ref":"Tag:JX69nZB8tfxnx5nGH"},"currentUserVote":null,"currentUserExtendedVote":null,"currentUserCanVote":true,"score":1,"baseScore":1,"extendedScore":{"agreement":0,"agreementVoteCount":0},"afBaseScore":1,"voteCount":1,"userId":"yzpiNbwDKZeZAhvHw","tagId":"JX69nZB8tfxnx5nGH","postId":"uMQ3cqWDPHhjtiesc","autoApplied":false},"TagRel:z5EgToBnshBYnGKgy":{"_id":"z5EgToBnshBYnGKgy","__typename":"TagRel","tag":{"__ref":"Tag:sYm3HiWcfZvrGu3ui"},"currentUserVote":null,"currentUserExtendedVote":null,"currentUserCanVote":true,"score":3,"baseScore":3,"extendedScore":{"approvalVoteCount":2,"agreement":0,"agreementVoteCount":0},"afBaseScore":1,"voteCount":2,"userId":"quAoHT9X7qMDBmA3z","tagId":"sYm3HiWcfZvrGu3ui","postId":"2ew4NFZovxCLsvHKS","autoApplied":false},"TagRel:ja7PhYfzjJ25CeeCC":{"_id":"ja7PhYfzjJ25CeeCC","__typename":"TagRel","tag":{"__ref":"Tag:PvridmTCj2qsugQCH"},"currentUserVote":null,"currentUserExtendedVote":null,"currentUserCanVote":true,"score":2,"baseScore":2,"extendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"afBaseScore":1,"voteCount":1,"userId":"quAoHT9X7qMDBmA3z","tagId":"PvridmTCj2qsugQCH","postId":"2ew4NFZovxCLsvHKS","autoApplied":false},"TagRel:EYW2THTR66JtHdGKu":{"_id":"EYW2THTR66JtHdGKu","__typename":"TagRel","tag":{"__ref":"Tag:nvKzwpiranwy29HFJ"},"currentUserVote":null,"currentUserExtendedVote":null,"currentUserCanVote":true,"score":2,"baseScore":2,"extendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"afBaseScore":1,"voteCount":1,"userId":"quAoHT9X7qMDBmA3z","tagId":"nvKzwpiranwy29HFJ","postId":"2ew4NFZovxCLsvHKS","autoApplied":false},"TagRel:PHRdJtusNikm9bwnB":{"_id":"PHRdJtusNikm9bwnB","__typename":"TagRel","tag":{"__ref":"Tag:haiwnEEx3vhrkfmAP"},"currentUserVote":null,"currentUserExtendedVote":null,"currentUserCanVote":true,"score":2,"baseScore":2,"extendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"afBaseScore":1,"voteCount":1,"userId":"quAoHT9X7qMDBmA3z","tagId":"haiwnEEx3vhrkfmAP","postId":"2ew4NFZovxCLsvHKS","autoApplied":false},"TagRel:5yKizuAKnzY8ewcvH":{"_id":"5yKizuAKnzY8ewcvH","__typename":"TagRel","tag":{"__ref":"Tag:sYm3HiWcfZvrGu3ui"},"currentUserVote":null,"currentUserExtendedVote":null,"currentUserCanVote":true,"score":2,"baseScore":2,"extendedScore":{"approvalVoteCount":2,"agreement":0,"agreementVoteCount":0},"afBaseScore":1,"voteCount":2,"userId":"hdQn7FqtLu2PHCYQF","tagId":"sYm3HiWcfZvrGu3ui","postId":"rSiybWzeiG8agYtNr","autoApplied":false},"TagRel:dfbT6X5dTciA6Yrrf":{"_id":"dfbT6X5dTciA6Yrrf","__typename":"TagRel","tag":{"__ref":"Tag:etDohXtBrXd8WqCtR"},"currentUserVote":null,"currentUserExtendedVote":null,"currentUserCanVote":true,"score":1,"baseScore":1,"extendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"afBaseScore":1,"voteCount":1,"userId":"hdQn7FqtLu2PHCYQF","tagId":"etDohXtBrXd8WqCtR","postId":"rSiybWzeiG8agYtNr","autoApplied":false},"TagRel:Rkck9jWMhvnLJim5z":{"_id":"Rkck9jWMhvnLJim5z","__typename":"TagRel","tag":{"__ref":"Tag:Rz5jb3cYHTSRmqNnN"},"currentUserVote":null,"currentUserExtendedVote":null,"currentUserCanVote":true,"score":1,"baseScore":1,"extendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"afBaseScore":1,"voteCount":1,"userId":"hdQn7FqtLu2PHCYQF","tagId":"Rz5jb3cYHTSRmqNnN","postId":"rSiybWzeiG8agYtNr","autoApplied":false},"TagRel:TBSyZ7Y5TjJ57XKzP":{"_id":"TBSyZ7Y5TjJ57XKzP","__typename":"TagRel","tag":{"__ref":"Tag:xexCWMyds6QLWognu"},"currentUserVote":null,"currentUserExtendedVote":null,"currentUserCanVote":true,"score":6,"baseScore":6,"extendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"afBaseScore":0,"voteCount":1,"userId":"Sp5wM4aRAhNERd4oY","tagId":"xexCWMyds6QLWognu","postId":"Fu7bqAyCMjfcMzBah","autoApplied":false},"TagRel:EyqQzRtnku7FDFnY2":{"_id":"EyqQzRtnku7FDFnY2","__typename":"TagRel","tag":{"__ref":"Tag:KN9KEMgyBHjcAyc26"},"currentUserVote":null,"currentUserExtendedVote":null,"currentUserCanVote":true,"score":4,"baseScore":4,"extendedScore":{"approvalVoteCount":2,"agreement":0,"agreementVoteCount":0},"afBaseScore":1,"voteCount":2,"userId":"Sp5wM4aRAhNERd4oY","tagId":"KN9KEMgyBHjcAyc26","postId":"Fu7bqAyCMjfcMzBah","autoApplied":false},"TagRel:zJxPJrB8hjSm6PE98":{"_id":"zJxPJrB8hjSm6PE98","__typename":"TagRel","tag":{"__ref":"Tag:TkZ7MFwCi4D63LJ5n"},"currentUserVote":null,"currentUserExtendedVote":null,"currentUserCanVote":true,"score":2,"baseScore":2,"extendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"afBaseScore":0,"voteCount":1,"userId":"Sp5wM4aRAhNERd4oY","tagId":"TkZ7MFwCi4D63LJ5n","postId":"Fu7bqAyCMjfcMzBah","autoApplied":false},"TagRel:5obBsNirfvuLGGEJH":{"_id":"5obBsNirfvuLGGEJH","__typename":"TagRel","tag":{"__ref":"Tag:ipJwbLxhR83ZksN6Z"},"currentUserVote":null,"currentUserExtendedVote":null,"currentUserCanVote":true,"score":2,"baseScore":2,"extendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"afBaseScore":1,"voteCount":1,"userId":"sKAL2jzfkYkDbQmx9","tagId":"ipJwbLxhR83ZksN6Z","postId":"Fu7bqAyCMjfcMzBah","autoApplied":false},"TagRel:Xd9BGmoaQ9YjkCizY":{"_id":"Xd9BGmoaQ9YjkCizY","__typename":"TagRel","tag":{"__ref":"Tag:sYm3HiWcfZvrGu3ui"},"currentUserVote":null,"currentUserExtendedVote":null,"currentUserCanVote":true,"score":2,"baseScore":2,"extendedScore":{"approvalVoteCount":2,"agreement":0,"agreementVoteCount":0},"afBaseScore":0,"voteCount":2,"userId":"66rcHyj9vi4TpqHF5","tagId":"sYm3HiWcfZvrGu3ui","postId":"eywpzHRgXTCCAi8yt","autoApplied":false},"TagRel:i5srWBBcQkp3Mrpfa":{"_id":"i5srWBBcQkp3Mrpfa","__typename":"TagRel","tag":{"__ref":"Tag:YWzByWvtXunfrBu5b"},"currentUserVote":null,"currentUserExtendedVote":null,"currentUserCanVote":true,"score":1,"baseScore":1,"extendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"afBaseScore":0,"voteCount":1,"userId":"66rcHyj9vi4TpqHF5","tagId":"YWzByWvtXunfrBu5b","postId":"eywpzHRgXTCCAi8yt","autoApplied":false},"TagRel:3uvJq34vchRzGTFZM":{"_id":"3uvJq34vchRzGTFZM","__typename":"TagRel","tag":{"__ref":"Tag:c42eTtBCXyJmtpqwZ"},"currentUserVote":null,"currentUserExtendedVote":null,"currentUserCanVote":true,"score":3,"baseScore":3,"extendedScore":{"approvalVoteCount":2,"agreement":0,"agreementVoteCount":0},"afBaseScore":2,"voteCount":2,"userId":"pWHLps2yEJTSNNBLk","tagId":"c42eTtBCXyJmtpqwZ","postId":"bxt7uCiHam4QXrQAA","autoApplied":false},"TagRel:kbkvvJiSPHQEzC53q":{"_id":"kbkvvJiSPHQEzC53q","__typename":"TagRel","tag":{"__ref":"Tag:YWzByWvtXunfrBu5b"},"currentUserVote":null,"currentUserExtendedVote":null,"currentUserCanVote":true,"score":3,"baseScore":3,"extendedScore":{"approvalVoteCount":2,"agreement":0,"agreementVoteCount":0},"afBaseScore":2,"voteCount":2,"userId":"pWHLps2yEJTSNNBLk","tagId":"YWzByWvtXunfrBu5b","postId":"bxt7uCiHam4QXrQAA","autoApplied":false},"TagRel:DAbNaZMMvF4S5DHxq":{"_id":"DAbNaZMMvF4S5DHxq","__typename":"TagRel","tag":{"__ref":"Tag:xjNvvmvQ5BH3cfEBr"},"currentUserVote":null,"currentUserExtendedVote":null,"currentUserCanVote":true,"score":1,"baseScore":1,"extendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"afBaseScore":1,"voteCount":1,"userId":"oQ9hq3SWXQsCP2aiq","tagId":"xjNvvmvQ5BH3cfEBr","postId":"bxt7uCiHam4QXrQAA","autoApplied":false},"TagRel:AkStND2Lqo746Gq4y":{"_id":"AkStND2Lqo746Gq4y","__typename":"TagRel","tag":{"__ref":"Tag:sYm3HiWcfZvrGu3ui"},"currentUserVote":null,"currentUserExtendedVote":null,"currentUserCanVote":true,"score":1,"baseScore":1,"extendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"afBaseScore":1,"voteCount":1,"userId":"oQ9hq3SWXQsCP2aiq","tagId":"sYm3HiWcfZvrGu3ui","postId":"bxt7uCiHam4QXrQAA","autoApplied":false},"TagRel:3EPN9MjayeyJk6J39":{"_id":"3EPN9MjayeyJk6J39","__typename":"TagRel","tag":{"__ref":"Tag:GDGYkF29pxEQNWjYc"},"currentUserVote":null,"currentUserExtendedVote":null,"currentUserCanVote":true,"score":1,"baseScore":1,"extendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"afBaseScore":1,"voteCount":1,"userId":"oQ9hq3SWXQsCP2aiq","tagId":"GDGYkF29pxEQNWjYc","postId":"bxt7uCiHam4QXrQAA","autoApplied":false},"TagRel:q8x3GnZa7hhNSBxC3":{"_id":"q8x3GnZa7hhNSBxC3","__typename":"TagRel","tag":{"__ref":"Tag:LXk7bxNkYSjgatdAt"},"currentUserVote":null,"currentUserExtendedVote":null,"currentUserCanVote":true,"score":1,"baseScore":1,"extendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"afBaseScore":1,"voteCount":1,"userId":"oQ9hq3SWXQsCP2aiq","tagId":"LXk7bxNkYSjgatdAt","postId":"bxt7uCiHam4QXrQAA","autoApplied":false},"TagRel:kJjffNLFi5kE45cix":{"_id":"kJjffNLFi5kE45cix","__typename":"TagRel","tag":{"__ref":"Tag:sYm3HiWcfZvrGu3ui"},"currentUserVote":null,"currentUserExtendedVote":null,"currentUserCanVote":true,"score":3,"baseScore":3,"extendedScore":{"approvalVoteCount":2,"agreement":0,"agreementVoteCount":0},"afBaseScore":1,"voteCount":2,"userId":"pWHLps2yEJTSNNBLk","tagId":"sYm3HiWcfZvrGu3ui","postId":"LAxAmooK4uDfWmbep","autoApplied":false},"TagRel:AsibzeHrCziB9byK2":{"_id":"AsibzeHrCziB9byK2","__typename":"TagRel","tag":{"__ref":"Tag:YWzByWvtXunfrBu5b"},"currentUserVote":null,"currentUserExtendedVote":null,"currentUserCanVote":true,"score":2,"baseScore":2,"extendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"afBaseScore":1,"voteCount":1,"userId":"pWHLps2yEJTSNNBLk","tagId":"YWzByWvtXunfrBu5b","postId":"LAxAmooK4uDfWmbep","autoApplied":false},"TagRel:XbSDKNPwJnmjDcA3q":{"_id":"XbSDKNPwJnmjDcA3q","__typename":"TagRel","tag":{"__ref":"Tag:NZ67PZ8CkeS6xn27h"},"currentUserVote":null,"currentUserExtendedVote":null,"currentUserCanVote":true,"score":2,"baseScore":2,"extendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"afBaseScore":1,"voteCount":1,"userId":"pWHLps2yEJTSNNBLk","tagId":"NZ67PZ8CkeS6xn27h","postId":"LAxAmooK4uDfWmbep","autoApplied":false},"TagRel:shJtdt7mwe9qDzoJN":{"_id":"shJtdt7mwe9qDzoJN","__typename":"TagRel","tag":{"__ref":"Tag:Dw5Z6wtTgk4Fikz9f"},"currentUserVote":null,"currentUserExtendedVote":null,"currentUserCanVote":true,"score":2,"baseScore":2,"extendedScore":{"approvalVoteCount":1,"agreement":0,"agreementVoteCount":0},"afBaseScore":1,"voteCount":1,"userId":"pWHLps2yEJTSNNBLk","tagId":"Dw5Z6wtTgk4Fikz9f","postId":"LAxAmooK4uDfWmbep","autoApplied":false}}</script>
<script>window.__APOLLO_FOREIGN_STATE__ = {}</script>

<script src="./codex_files/api.js"></script><iframe id="intercom-frame" style="position: absolute !important; opacity: 0 !important; width: 1px !important; height: 1px !important; top: 0 !important; left: 0 !important; border: none !important; display: block !important; z-index: -1 !important; pointer-events: none;" aria-hidden="true" tabindex="-1" title="Intercom" src="./codex_files/saved_resource(1).html"></iframe><div><div class="grecaptcha-badge" data-style="bottomright" style="width: 256px; height: 60px; display: block; transition: right 0.3s ease 0s; position: fixed; bottom: 14px; right: -186px; box-shadow: gray 0px 0px 5px; border-radius: 2px; overflow: hidden;"><div class="grecaptcha-logo"><iframe title="reCAPTCHA" src="./codex_files/anchor.html" width="256" height="60" role="presentation" name="a-dasu5atbygv9" frameborder="0" scrolling="no" sandbox="allow-forms allow-popups allow-same-origin allow-scripts allow-top-navigation allow-modals allow-popups-to-escape-sandbox"></iframe></div><div class="grecaptcha-error"></div><textarea id="g-recaptcha-response-100000" name="g-recaptcha-response" class="g-recaptcha-response" style="width: 250px; height: 40px; border: 1px solid rgb(193, 193, 193); margin: 10px 25px; padding: 0px; resize: none; display: none;"></textarea></div><iframe style="display: none;" src="./codex_files/saved_resource(2).html"></iframe></div><div class="intercom-lightweight-app"><div class="intercom-lightweight-app-launcher intercom-launcher" role="button" tabindex="0" aria-label="Open Intercom Messenger" aria-live="polite"><div class="intercom-lightweight-app-launcher-icon intercom-lightweight-app-launcher-icon-open"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 28 32"><path d="M28 32s-4.714-1.855-8.527-3.34H3.437C1.54 28.66 0 27.026 0 25.013V3.644C0 1.633 1.54 0 3.437 0h21.125c1.898 0 3.437 1.632 3.437 3.645v18.404H28V32zm-4.139-11.982a.88.88 0 00-1.292-.105c-.03.026-3.015 2.681-8.57 2.681-5.486 0-8.517-2.636-8.571-2.684a.88.88 0 00-1.29.107 1.01 1.01 0 00-.219.708.992.992 0 00.318.664c.142.128 3.537 3.15 9.762 3.15 6.226 0 9.621-3.022 9.763-3.15a.992.992 0 00.317-.664 1.01 1.01 0 00-.218-.707z"></path></svg></div><div class="intercom-lightweight-app-launcher-icon intercom-lightweight-app-launcher-icon-minimize"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path fill-rule="evenodd" clip-rule="evenodd" d="M18.601 8.39897C18.269 8.06702 17.7309 8.06702 17.3989 8.39897L12 13.7979L6.60099 8.39897C6.26904 8.06702 5.73086 8.06702 5.39891 8.39897C5.06696 8.73091 5.06696 9.2691 5.39891 9.60105L11.3989 15.601C11.7309 15.933 12.269 15.933 12.601 15.601L18.601 9.60105C18.9329 9.2691 18.9329 8.73091 18.601 8.39897Z" fill="white"></path>
</svg>
</div></div><style id="intercom-lightweight-app-style" type="text/css">
  @keyframes intercom-lightweight-app-launcher {
    from {
      opacity: 0;
      transform: scale(0.5);
    }
    to {
      opacity: 1;
      transform: scale(1);
    }
  }

  @keyframes intercom-lightweight-app-gradient {
    from {
      opacity: 0;
    }
    to {
      opacity: 1;
    }
  }

  @keyframes intercom-lightweight-app-messenger {
    
        from {
          opacity: 0;
          transform: translateY(20px);
        }
        to {
          opacity: 1;
          transform: translateY(0);
        }
        
  }

  .intercom-lightweight-app {
    position: fixed;
    z-index: 2147483001;
    width: 0;
    height: 0;
    font-family: intercom-font, "Helvetica Neue", "Apple Color Emoji", Helvetica, Arial, sans-serif;
  }

  .intercom-lightweight-app-gradient {
    position: fixed;
    z-index: 2147483002;
    width: 500px;
    height: 500px;
    bottom: 0;
    right: 0;
    pointer-events: none;
    background: radial-gradient(
      ellipse at bottom right,
      rgba(29, 39, 54, 0.16) 0%,
      rgba(29, 39, 54, 0) 72%);
    animation: intercom-lightweight-app-gradient 200ms ease-out;
  }

  .intercom-lightweight-app-launcher {
    position: fixed;
    z-index: 2147483003;
    padding: 0 !important;
    margin: 0 !important;
    border: none;
    bottom: 20px;
    right: 20px;
    max-width: 60px;
    width: 60px;
    max-height: 60px;
    height: 60px;
    border-radius: 50%;
    background: #f5f5f5;
    cursor: pointer;
    box-shadow: 0 1px 6px 0 rgba(0, 0, 0, 0.06), 0 2px 32px 0 rgba(0, 0, 0, 0.16);
    transition: transform 167ms cubic-bezier(0.33, 0.00, 0.00, 1.00);
    box-sizing: content-box;
  }

  


  .intercom-lightweight-app-launcher:focus {
    outline: none;

    
  }

  .intercom-lightweight-app-launcher-icon {
    display: flex;
    align-items: center;
    justify-content: center;
    position: absolute;
    top: 0;
    left: 0;
    width: 60px;
    height: 60px;
    transition: transform 100ms linear, opacity 80ms linear;
  }

  .intercom-lightweight-app-launcher-icon-open {
    
        opacity: 1;
        transform: rotate(0deg) scale(1);
      
  }

  .intercom-lightweight-app-launcher-icon-open svg {
    width: 28px;
    height: 32px;
  }

  .intercom-lightweight-app-launcher-icon-open svg path {
    fill: rgba(0, 0, 0, 0.5);
  }

  .intercom-lightweight-app-launcher-icon-self-serve {
    
        opacity: 1;
        transform: rotate(0deg) scale(1);
      
  }

  .intercom-lightweight-app-launcher-icon-self-serve svg {
    height: 56px;
  }

  .intercom-lightweight-app-launcher-icon-self-serve svg path {
    fill: rgba(0, 0, 0, 0.5);
  }

  .intercom-lightweight-app-launcher-custom-icon-open {
    max-height: 36px;
    max-width: 36px;

    
        opacity: 1;
        transform: rotate(0deg) scale(1);
      
  }

  .intercom-lightweight-app-launcher-icon-minimize {
    
        opacity: 0;
        transform: rotate(-60deg) scale(0);
      
  }

  .intercom-lightweight-app-launcher-icon-minimize svg path {
    fill: rgba(0, 0, 0, 0.5);
  }

  .intercom-lightweight-app-messenger {
    position: fixed;
    z-index: 2147483003;
    overflow: hidden;
    background-color: white;
    animation: intercom-lightweight-app-messenger 250ms cubic-bezier(0, 1.2, 1, 1);
    transform-origin: bottom right;
    height: calc(100% - 120px);
    
        width: 376px;
        height: calc(100% - 120px);
        max-height: 704px;
        min-height: 250px;
        right: 20px;
        bottom: 100px;
        box-shadow: 0 5px 40px rgba(0,0,0,0.16);
      

    border-radius: 8px;
  }

  .intercom-lightweight-app-messenger-header {
    height: 75px;
    border-bottom: none;
    background: linear-gradient(
      135deg,
      rgb(245, 245, 245) 0%,
      rgb(194, 194, 194) 100%
    );
  }

  .intercom-lightweight-app-messenger-footer{
    position:absolute;
    bottom:0;
    width: 100%;
    min-height: 81px;
    background: #fff;
    font-size: 14px;
    line-height: 21px;
    border-top: 1px solid rgba(0, 0, 0, 0.05);
    box-shadow: 0px 0px 25px rgba(0, 0, 0, 0.05);
  }

  @media print {
    .intercom-lightweight-app {
      display: none;
    }
  }
</style></div></body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>